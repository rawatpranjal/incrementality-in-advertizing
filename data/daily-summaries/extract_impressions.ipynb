{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import snowflake.connector\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "conn = snowflake.connector.connect(\n",
    "    user=os.getenv('SNOWFLAKE_USER'),\n",
    "    password=os.getenv('SNOWFLAKE_PASSWORD'),\n",
    "    account=os.getenv('SNOWFLAKE_ACCOUNT'),\n",
    "    warehouse=os.getenv('SNOWFLAKE_WAREHOUSE', 'COMPUTE_WH'),\n",
    "    database='INCREMENTALITY',\n",
    "    schema='INCREMENTALITY_RESEARCH'\n",
    ")\n",
    "\n",
    "print(\"Connected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Configuration ---\n",
      "Analysis Period: 2025-03-14 to 2025-09-07\n",
      "Output Directory: /Users/pranjal/Code/marketplace-incrementality/daily_summaries/data/product_daily_impressions_dataset\n",
      "\n",
      "--- Starting Daily Product-Level Impressions Extraction ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffc4c7c19f5646dfad5de1d9f3364bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting Daily Impressions:   0%|          | 0/178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b7/1tvk5qmx0ds9c6gk2lrlhv380000gn/T/ipykernel_1161/2615827479.py:65: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_day = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Daily Impression Extraction Complete ---\n",
      "\n",
      "--- Verifying the Complete Impressions Dataset ---\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import date, timedelta\n",
    "from tqdm.notebook import tqdm\n",
    "from dotenv import load_dotenv\n",
    "import snowflake.connector\n",
    "\n",
    "# ==============================================================================\n",
    "# CELL: SETUP AND CONFIGURATION\n",
    "# ==============================================================================\n",
    "load_dotenv()\n",
    "# conn = snowflake.connector.connect(...) \n",
    "\n",
    "ANALYSIS_START = date(2025, 3, 14)\n",
    "ANALYSIS_END = date(2025, 9, 7)\n",
    "\n",
    "BASE_PATH = Path(\"/Users/pranjal/Code/marketplace-incrementality/daily_summaries/data\")\n",
    "OUTPUT_DIR = BASE_PATH / \"product_daily_impressions_dataset\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"--- Configuration ---\")\n",
    "print(f\"Analysis Period: {ANALYSIS_START} to {ANALYSIS_END}\")\n",
    "print(f\"Output Directory: {OUTPUT_DIR}\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# CELL: DAILY PRODUCT-LEVEL IMPRESSIONS EXTRACTION\n",
    "# ==============================================================================\n",
    "\n",
    "def get_impressions_query(date_str: str, next_date_str: str) -> str:\n",
    "    \"\"\"Returns a parameterized SQL query to get all product-level impression metrics for a single day.\"\"\"\n",
    "    return f\"\"\"\n",
    "    SELECT\n",
    "        PRODUCT_ID,\n",
    "        '{date_str}'::DATE AS date,\n",
    "        ANY_VALUE(VENDOR_ID) AS vendor_id,\n",
    "        ANY_VALUE(CAMPAIGN_ID) AS campaign_id,\n",
    "        COUNT(*) AS total_impressions,\n",
    "        COUNT(DISTINCT INTERACTION_ID) AS impressions,\n",
    "        APPROX_COUNT_DISTINCT(USER_ID) AS distinct_users_impressed\n",
    "    FROM\n",
    "        IMPRESSIONS\n",
    "    WHERE\n",
    "        OCCURRED_AT >= '{date_str}'::TIMESTAMP_NTZ AND OCCURRED_AT < '{next_date_str}'::TIMESTAMP_NTZ\n",
    "        AND PRODUCT_ID IS NOT NULL\n",
    "    GROUP BY\n",
    "        PRODUCT_ID;\n",
    "    \"\"\"\n",
    "\n",
    "# --- Main Extraction Loop ---\n",
    "print(\"\\n--- Starting Daily Product-Level Impressions Extraction ---\")\n",
    "date_list = pd.date_range(start=ANALYSIS_START, end=ANALYSIS_END, freq='D')\n",
    "\n",
    "for current_date in tqdm(date_list, desc=\"Extracting Daily Impressions\"):\n",
    "    date_str = current_date.strftime('%Y-%m-%d')\n",
    "    next_date_str = (current_date + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    \n",
    "    output_file = OUTPUT_DIR / f\"data_{date_str}.parquet\"\n",
    "\n",
    "    if output_file.exists():\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        query = get_impressions_query(date_str, next_date_str)\n",
    "        df_day = pd.read_sql(query, conn)\n",
    "\n",
    "        if not df_day.empty:\n",
    "            df_day.to_parquet(output_file, index=False, engine='pyarrow', compression='snappy')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nProcessing for {date_str} FAILED: {e}\")\n",
    "        \n",
    "print(\"\\n--- Daily Impression Extraction Complete ---\")\n",
    "\n",
    "# ==============================================================================\n",
    "# CELL: VERIFICATION\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n--- Verifying the Complete Impressions Dataset ---\")\n",
    "try:\n",
    "    df_full_impressions = pd.read_parquet(OUTPUT_DIR)\n",
    "    \n",
    "    print(f\"✅ Successfully loaded complete dataset with {len(df_full_impressions):,} rows.\")\n",
    "    \n",
    "    print(f\"\\n=== IMPRESSIONS EXTRACTION FINAL SUMMARY ===\")\n",
    "    print(f\"Date range: {df_full_impressions['DATE'].min().date()} to {df_full_impressions['DATE'].max().date()}\")\n",
    "    print(f\"Unique products with impressions: {df_full_impressions['PRODUCT_ID'].nunique():,}\")\n",
    "    \n",
    "    total_impressions = df_full_impressions['IMPRESSIONS'].sum()\n",
    "    print(f\"Total unique impressions extracted: {total_impressions:,}\")\n",
    "    \n",
    "    print(\"\\nSample of 5 rows:\")\n",
    "    print(df_full_impressions.head().to_markdown(index=False))\n",
    "    \n",
    "    print(\"\\nSchema and Memory Usage:\")\n",
    "    df_full_impressions.info(memory_usage='deep')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Could not load or verify the full dataset. Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
