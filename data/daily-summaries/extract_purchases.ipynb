{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import snowflake.connector\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "conn = snowflake.connector.connect(\n",
    "    user=os.getenv('SNOWFLAKE_USER'),\n",
    "    password=os.getenv('SNOWFLAKE_PASSWORD'),\n",
    "    account=os.getenv('SNOWFLAKE_ACCOUNT'),\n",
    "    warehouse=os.getenv('SNOWFLAKE_WAREHOUSE', 'COMPUTE_WH'),\n",
    "    database='INCREMENTALITY',\n",
    "    schema='INCREMENTALITY_RESEARCH'\n",
    ")\n",
    "\n",
    "print(\"Connected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 125952 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>purchases</th>\n",
       "      <th>units</th>\n",
       "      <th>revenue_cents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6861fe83850012da8905c1d8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64b44c338634cb9c8b5c26aa</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>660f7b17b635f8f5feb9d525</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66eef251ce706502c3f06e31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>630123ec253a8cba6646c89a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 product_id  purchases  units  revenue_cents\n",
       "0  6861fe83850012da8905c1d8          1      1           1200\n",
       "1  64b44c338634cb9c8b5c26aa          1      1          19900\n",
       "2  660f7b17b635f8f5feb9d525          1      1           2000\n",
       "3  66eef251ce706502c3f06e31          1      1           1000\n",
       "4  630123ec253a8cba6646c89a          1      1           3500"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "    PRODUCT_ID,\n",
    "    COUNT(*) AS purchases,\n",
    "    SUM(QUANTITY) AS units,\n",
    "    SUM(QUANTITY * UNIT_PRICE) AS revenue_cents\n",
    "FROM PURCHASES\n",
    "WHERE\n",
    "    PURCHASED_AT >= '2025-07-01'::TIMESTAMP_NTZ\n",
    "    AND PURCHASED_AT < '2025-07-02'::TIMESTAMP_NTZ\n",
    "GROUP BY PRODUCT_ID\n",
    "\"\"\"\n",
    "\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(query)\n",
    "results = cursor.fetchall()\n",
    "\n",
    "df = pd.DataFrame(results, columns=['product_id', 'purchases', 'units', 'revenue_cents'])\n",
    "print(f\"Got {len(df)} rows\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Configuration ---\n",
      "Analysis Period: 2025-03-14 to 2025-09-07\n",
      "Output Directory: /Users/pranjal/Code/marketplace-incrementality/daily_summaries/data/product_daily_purchases_dataset\n",
      "\n",
      "--- Starting Daily Product-Level Purchases Extraction ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab6a769c89f64dcb8d991bb86c32ca12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting Daily Purchases:   0%|          | 0/178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b7/1tvk5qmx0ds9c6gk2lrlhv380000gn/T/ipykernel_25586/3684528069.py:62: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_day = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Daily Purchase Extraction Complete ---\n",
      "\n",
      "--- Verifying the Complete Purchases Dataset ---\n",
      "✅ Successfully loaded complete dataset with 23,765,830 rows.\n",
      "\n",
      "=== PURCHASES EXTRACTION FINAL SUMMARY ===\n",
      "\n",
      "❌ Could not load or verify the full dataset. Error: 'datetime.date' object has no attribute 'date'\n",
      "Please check the contents of the output directory.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import date, timedelta\n",
    "from tqdm.notebook import tqdm\n",
    "from dotenv import load_dotenv\n",
    "import snowflake.connector\n",
    "\n",
    "# CELL 1: SETUP AND CONFIGURATION\n",
    "load_dotenv()\n",
    "# conn = snowflake.connector.connect(...) \n",
    "\n",
    "ANALYSIS_START = date(2025, 3, 14)\n",
    "ANALYSIS_END = date(2025, 9, 7)\n",
    "\n",
    "BASE_PATH = Path(\"/Users/pranjal/Code/marketplace-incrementality/daily_summaries/data\")\n",
    "OUTPUT_DIR = BASE_PATH / \"product_daily_purchases_dataset\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"--- Configuration ---\")\n",
    "print(f\"Analysis Period: {ANALYSIS_START} to {ANALYSIS_END}\")\n",
    "print(f\"Output Directory: {OUTPUT_DIR}\")\n",
    "\n",
    "# CELL 2: DAILY PRODUCT-LEVEL PURCHASES EXTRACTION\n",
    "\n",
    "def get_purchases_query(date_str: str, next_date_str: str) -> str:\n",
    "    return f\"\"\"\n",
    "    SELECT\n",
    "        PRODUCT_ID,\n",
    "        '{date_str}'::DATE AS date,\n",
    "        COUNT(DISTINCT PURCHASE_ID) AS purchases,\n",
    "        COUNT(*) AS lines_sold,\n",
    "        COALESCE(SUM(QUANTITY), 0) AS units_sold,\n",
    "        COALESCE(SUM(QUANTITY * UNIT_PRICE), 0) AS revenue_cents,\n",
    "        AVG(UNIT_PRICE) AS avg_unit_price_cents,\n",
    "        MIN(UNIT_PRICE) AS min_unit_price_cents,\n",
    "        MAX(UNIT_PRICE) AS max_unit_price_cents,\n",
    "        STDDEV(UNIT_PRICE) AS stddev_unit_price_cents,\n",
    "        APPROX_COUNT_DISTINCT(USER_ID) AS distinct_users_purchased\n",
    "    FROM\n",
    "        PURCHASES\n",
    "    WHERE\n",
    "        PURCHASED_AT >= '{date_str}'::TIMESTAMP_NTZ AND PURCHASED_AT < '{next_date_str}'::TIMESTAMP_NTZ\n",
    "        AND PRODUCT_ID IS NOT NULL\n",
    "    GROUP BY\n",
    "        PRODUCT_ID;\n",
    "    \"\"\"\n",
    "\n",
    "print(\"\\n--- Starting Daily Product-Level Purchases Extraction ---\")\n",
    "date_list = pd.date_range(start=ANALYSIS_START, end=ANALYSIS_END, freq='D')\n",
    "\n",
    "for current_date in tqdm(date_list, desc=\"Extracting Daily Purchases\"):\n",
    "    date_str = current_date.strftime('%Y-%m-%d')\n",
    "    next_date_str = (current_date + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    \n",
    "    output_file = OUTPUT_DIR / f\"data_{date_str}.parquet\"\n",
    "\n",
    "    if output_file.exists():\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        query = get_purchases_query(date_str, next_date_str)\n",
    "        df_day = pd.read_sql(query, conn)\n",
    "\n",
    "        if not df_day.empty:\n",
    "            df_day.to_parquet(output_file, index=False, engine='pyarrow', compression='snappy')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nProcessing for {date_str} FAILED: {e}\")\n",
    "        \n",
    "print(\"\\n--- Daily Purchase Extraction Complete ---\")\n",
    "\n",
    "\n",
    "# CELL 3: VERIFICATION\n",
    "\n",
    "print(\"\\n--- Verifying the Complete Purchases Dataset ---\")\n",
    "try:\n",
    "    df_full_purchases = pd.read_parquet(OUTPUT_DIR)\n",
    "    \n",
    "    print(f\"✅ Successfully loaded complete dataset with {len(df_full_purchases):,} rows.\")\n",
    "    \n",
    "    print(f\"\\n=== PURCHASES EXTRACTION FINAL SUMMARY ===\")\n",
    "    print(f\"Date range: {df_full_purchases['DATE'].min()} to {df_full_purchases['DATE'].max()}\")\n",
    "    print(f\"Unique products with purchases: {df_full_purchases['PRODUCT_ID'].nunique():,}\")\n",
    "    \n",
    "    total_revenue_dollars = df_full_purchases['REVENUE_CENTS'].sum() / 100.0\n",
    "    print(f\"Total revenue: ${total_revenue_dollars:,.2f}\")\n",
    "    \n",
    "    print(\"\\nSample of 5 rows:\")\n",
    "    print(df_full_purchases.head().to_markdown(index=False))\n",
    "    \n",
    "    print(\"\\nSchema and Memory Usage:\")\n",
    "    df_full_purchases.info(memory_usage='deep')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Could not load or verify the full dataset. Error: {e}\")\n",
    "    print(\"Please check the contents of the output directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
