{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Budget Pacing Analysis\n",
    "\n",
    "## Objective\n",
    "Analyze the relationship between budget PACING, FINAL_BID, IS_WINNER, and RANKING in marketplace's auction system.\n",
    "\n",
    "## Research Questions\n",
    "1. How does pacing affect bid amounts and win probability?\n",
    "2. Can we distinguish throttling from discount pacing mechanisms?\n",
    "3. What are the characteristics of campaigns at different pacing levels?\n",
    "4. What are the implications for incrementality analysis?\n",
    "\n",
    "## Data Period\n",
    "September 2-8, 2025 (14 days), 0.1% user sample\n",
    "\n",
    "## Note on Units\n",
    "FINAL_BID and PRICE are in CENTS, not dollars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data with progress tracking...\n",
      "================================================================================\n",
      "\u2713 Loaded AUCTIONS_RESULTS: 18,838,670 rows\n",
      "\u2713 Loaded AUCTIONS_USERS: 413,457 rows\n",
      "\u2713 Loaded IMPRESSIONS: 533,146 rows\n",
      "\u2713 Loaded CLICKS: 16,706 rows\n",
      "\u2713 Loaded CATALOG: 2,007,695 rows\n",
      "\n",
      "Merging auction data with timestamps...\n",
      "\u2713 Merged dataset: 18,840,598 rows\n",
      "\n",
      "Creating derived features...\n",
      "\n",
      "Data shape: (18840598, 20)\n",
      "\n",
      "Column dtypes:\n",
      "AUCTION_ID                   object\n",
      "VENDOR_ID                    object\n",
      "CAMPAIGN_ID                  object\n",
      "PRODUCT_ID                   object\n",
      "RANKING                       int64\n",
      "IS_WINNER                      bool\n",
      "QUALITY                     float64\n",
      "FINAL_BID                     int64\n",
      "PRICE                       float64\n",
      "CONVERSION_RATE             float64\n",
      "PACING                      float64\n",
      "CREATED_AT           datetime64[ns]\n",
      "PLACEMENT                    object\n",
      "OPAQUE_USER_ID               object\n",
      "datetime             datetime64[ns]\n",
      "hour                          int32\n",
      "day_of_week                   int32\n",
      "date                         object\n",
      "FINAL_BID_DOLLARS           float64\n",
      "PRICE_DOLLARS               float64\n",
      "dtype: object\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Loading data with progress tracking...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_auctions_results = pd.read_parquet('data/raw_auctions_results_20251011.parquet')\n",
    "print(f\"\u2713 Loaded AUCTIONS_RESULTS: {len(df_auctions_results):,} rows\")\n",
    "\n",
    "df_auctions_users = pd.read_parquet('data/raw_auctions_users_20251011.parquet')\n",
    "print(f\"\u2713 Loaded AUCTIONS_USERS: {len(df_auctions_users):,} rows\")\n",
    "\n",
    "df_impressions = pd.read_parquet('data/raw_impressions_20251011.parquet')\n",
    "print(f\"\u2713 Loaded IMPRESSIONS: {len(df_impressions):,} rows\")\n",
    "\n",
    "df_clicks = pd.read_parquet('data/raw_clicks_20251011.parquet')\n",
    "print(f\"\u2713 Loaded CLICKS: {len(df_clicks):,} rows\")\n",
    "\n",
    "df_catalog = pd.read_parquet('data/catalog_20251011.parquet')\n",
    "print(f\"\u2713 Loaded CATALOG: {len(df_catalog):,} rows\")\n",
    "\n",
    "print(\"\\nMerging auction data with timestamps...\")\n",
    "# Drop CREATED_AT from auctions_results to avoid duplicates\n",
    "df_auctions_results_clean = df_auctions_results.drop(columns=['CREATED_AT'])\n",
    "df = pd.merge(df_auctions_results_clean, df_auctions_users[['AUCTION_ID', 'CREATED_AT', 'PLACEMENT', 'OPAQUE_USER_ID']], \n",
    "              on='AUCTION_ID', how='left')\n",
    "print(f\"\u2713 Merged dataset: {len(df):,} rows\")\n",
    "\n",
    "print(\"\\nCreating derived features...\")\n",
    "df['datetime'] = pd.to_datetime(df['CREATED_AT'])\n",
    "df['hour'] = df['datetime'].dt.hour\n",
    "df['day_of_week'] = df['datetime'].dt.dayofweek\n",
    "df['date'] = df['datetime'].dt.date\n",
    "df['FINAL_BID_DOLLARS'] = df['FINAL_BID'] / 100\n",
    "df['PRICE_DOLLARS'] = df['PRICE'] / 100\n",
    "\n",
    "print(\"\\nData shape:\", df.shape)\n",
    "print(\"\\nColumn dtypes:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DESCRIPTIVE STATISTICS\n",
      "================================================================================\n",
      "\n",
      "1. PACING DISTRIBUTION\n",
      "--------------------------------------------------------------------------------\n",
      "Total bids: 18,840,598\n",
      "Mean pacing: 0.8910\n",
      "Median pacing: 1.0000\n",
      "Std pacing: 0.2634\n",
      "Min pacing: 0.006738\n",
      "Max pacing: 1.0000\n",
      "\n",
      "Pacing Quantiles:\n",
      "    1.0%: 0.014909\n",
      "    5.0%: 0.136717\n",
      "   10.0%: 0.425693\n",
      "   25.0%: 1.000000\n",
      "   50.0%: 1.000000\n",
      "   75.0%: 1.000000\n",
      "   90.0%: 1.000000\n",
      "   95.0%: 1.000000\n",
      "   99.0%: 1.000000\n",
      "\n",
      "Pacing Categories:\n",
      "  High (0.9-1.0):   15,573,844 (82.66%)\n",
      "  Medium (0.5-0.9): 1,169,905 (6.21%)\n",
      "  Low (<0.5):       2,096,849 (11.13%)\n",
      "\n",
      "2. BID DISTRIBUTION\n",
      "--------------------------------------------------------------------------------\n",
      "Mean bid (cents): 11.80\n",
      "Mean bid (dollars): $0.1180\n",
      "Median bid (cents): 6.00\n",
      "Median bid (dollars): $0.0600\n",
      "Std bid (cents): 14.44\n",
      "Min bid (cents): 0.00\n",
      "Max bid (cents): 100.00\n",
      "\n",
      "Bid Quantiles (dollars):\n",
      "   10.0%: $0.0100\n",
      "   25.0%: $0.0300\n",
      "   50.0%: $0.0600\n",
      "   75.0%: $0.1600\n",
      "   90.0%: $0.2900\n",
      "   95.0%: $0.3900\n",
      "   99.0%: $0.7300\n",
      "\n",
      "3. WIN RATES BY PACING LEVEL\n",
      "--------------------------------------------------------------------------------\n",
      "High pacing:\n",
      "  N bids: 15,573,844\n",
      "  Win rate: 85.61%\n",
      "  Mean bid: $0.1125\n",
      "  Mean rank: 26.06\n",
      "Med pacing:\n",
      "  N bids: 1,169,905\n",
      "  Win rate: 81.51%\n",
      "  Mean bid: $0.1304\n",
      "  Mean rank: 26.52\n",
      "Low pacing:\n",
      "  N bids: 2,096,849\n",
      "  Win rate: 58.42%\n",
      "  Mean bid: $0.1521\n",
      "  Mean rank: 28.16\n",
      "\n",
      "4. PACING \u00d7 BID INTERACTION WIN RATES\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Win Rate Matrix (Bid \u00d7 Pacing):\n",
      "pacing_tercile     Low     Med    High\n",
      "bid_tercile                           \n",
      "Low             0.1635  0.7056  0.8813\n",
      "Med             0.8275  0.8301  0.8125\n",
      "High            0.8891  0.8835  0.8701\n",
      "\n",
      "5. CORRELATIONS\n",
      "--------------------------------------------------------------------------------\n",
      "FINAL_BID vs PACING: -0.0798\n",
      "IS_WINNER vs PACING: 0.2435\n",
      "RANKING vs PACING: -0.0448\n",
      "QUALITY vs PACING: -0.0382\n",
      "FINAL_BID vs QUALITY: 0.0329\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"DESCRIPTIVE STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. PACING DISTRIBUTION\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Total bids: {len(df):,}\")\n",
    "print(f\"Mean pacing: {df['PACING'].mean():.4f}\")\n",
    "print(f\"Median pacing: {df['PACING'].median():.4f}\")\n",
    "print(f\"Std pacing: {df['PACING'].std():.4f}\")\n",
    "print(f\"Min pacing: {df['PACING'].min():.6f}\")\n",
    "print(f\"Max pacing: {df['PACING'].max():.4f}\")\n",
    "\n",
    "print(\"\\nPacing Quantiles:\")\n",
    "for q in [0.01, 0.05, 0.10, 0.25, 0.50, 0.75, 0.90, 0.95, 0.99]:\n",
    "    print(f\"  {q*100:5.1f}%: {df['PACING'].quantile(q):.6f}\")\n",
    "\n",
    "print(\"\\nPacing Categories:\")\n",
    "print(f\"  High (0.9-1.0):   {(df['PACING'] >= 0.9).sum():,} ({(df['PACING'] >= 0.9).mean()*100:.2f}%)\")\n",
    "print(f\"  Medium (0.5-0.9): {((df['PACING'] >= 0.5) & (df['PACING'] < 0.9)).sum():,} ({((df['PACING'] >= 0.5) & (df['PACING'] < 0.9)).mean()*100:.2f}%)\")\n",
    "print(f\"  Low (<0.5):       {(df['PACING'] < 0.5).sum():,} ({(df['PACING'] < 0.5).mean()*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n2. BID DISTRIBUTION\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Mean bid (cents): {df['FINAL_BID'].mean():.2f}\")\n",
    "print(f\"Mean bid (dollars): ${df['FINAL_BID_DOLLARS'].mean():.4f}\")\n",
    "print(f\"Median bid (cents): {df['FINAL_BID'].median():.2f}\")\n",
    "print(f\"Median bid (dollars): ${df['FINAL_BID_DOLLARS'].median():.4f}\")\n",
    "print(f\"Std bid (cents): {df['FINAL_BID'].std():.2f}\")\n",
    "print(f\"Min bid (cents): {df['FINAL_BID'].min():.2f}\")\n",
    "print(f\"Max bid (cents): {df['FINAL_BID'].max():.2f}\")\n",
    "\n",
    "print(\"\\nBid Quantiles (dollars):\")\n",
    "for q in [0.10, 0.25, 0.50, 0.75, 0.90, 0.95, 0.99]:\n",
    "    print(f\"  {q*100:5.1f}%: ${df['FINAL_BID_DOLLARS'].quantile(q):.4f}\")\n",
    "\n",
    "print(\"\\n3. WIN RATES BY PACING LEVEL\")\n",
    "print(\"-\" * 80)\n",
    "df['pacing_cat'] = pd.cut(df['PACING'], bins=[0, 0.5, 0.9, 1.0], labels=['Low', 'Med', 'High'])\n",
    "for cat in ['High', 'Med', 'Low']:\n",
    "    cat_data = df[df['pacing_cat'] == cat]\n",
    "    print(f\"{cat} pacing:\")\n",
    "    print(f\"  N bids: {len(cat_data):,}\")\n",
    "    print(f\"  Win rate: {cat_data['IS_WINNER'].mean()*100:.2f}%\")\n",
    "    print(f\"  Mean bid: ${cat_data['FINAL_BID_DOLLARS'].mean():.4f}\")\n",
    "    print(f\"  Mean rank: {cat_data['RANKING'].mean():.2f}\")\n",
    "\n",
    "print(\"\\n4. PACING \u00d7 BID INTERACTION WIN RATES\")\n",
    "print(\"-\" * 80)\n",
    "df['bid_tercile'] = pd.qcut(df['FINAL_BID'], q=3, labels=['Low', 'Med', 'High'], duplicates='drop')\n",
    "# Custom pacing bins to handle concentration at 1.0\n",
    "df['pacing_tercile'] = pd.cut(df['PACING'], bins=[0, 0.5, 0.9, 1.0], labels=['Low', 'Med', 'High'])\n",
    "\n",
    "cross_tab = pd.crosstab([df['bid_tercile']], [df['pacing_tercile']], \n",
    "                        values=df['IS_WINNER'], aggfunc='mean')\n",
    "print(\"\\nWin Rate Matrix (Bid \u00d7 Pacing):\")\n",
    "print(cross_tab.round(4))\n",
    "\n",
    "print(\"\\n5. CORRELATIONS\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"FINAL_BID vs PACING: {df['FINAL_BID'].corr(df['PACING']):.4f}\")\n",
    "print(f\"IS_WINNER vs PACING: {df['IS_WINNER'].corr(df['PACING']):.4f}\")\n",
    "print(f\"RANKING vs PACING: {df['RANKING'].corr(df['PACING']):.4f}\")\n",
    "print(f\"QUALITY vs PACING: {df['QUALITY'].corr(df['PACING']):.4f}\")\n",
    "print(f\"FINAL_BID vs QUALITY: {df['FINAL_BID'].corr(df['QUALITY']):.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion Rate Analysis\n",
    "\n",
    "Examine how CONVERSION_RATE relates to pacing, bids, quality, and outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CONVERSION_RATE ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "1. CONVERSION_RATE DISTRIBUTION\n",
      "--------------------------------------------------------------------------------\n",
      "Mean conversion rate: 0.010004\n",
      "Median conversion rate: 0.009010\n",
      "Std conversion rate: 0.007716\n",
      "Min conversion rate: 0.000001\n",
      "Max conversion rate: 0.056500\n",
      "\n",
      "Conversion Rate Quantiles:\n",
      "   10.0%: 0.001456\n",
      "   25.0%: 0.004257\n",
      "   50.0%: 0.009010\n",
      "   75.0%: 0.013267\n",
      "   90.0%: 0.019160\n",
      "   95.0%: 0.024458\n",
      "   99.0%: 0.037425\n",
      "\n",
      "2. CONVERSION_RATE CORRELATIONS\n",
      "--------------------------------------------------------------------------------\n",
      "CONVERSION_RATE vs PACING:     0.0275\n",
      "CONVERSION_RATE vs FINAL_BID:  0.1960\n",
      "CONVERSION_RATE vs QUALITY:    0.1578\n",
      "CONVERSION_RATE vs RANKING:    0.0433\n",
      "CONVERSION_RATE vs IS_WINNER:  0.0077\n",
      "\n",
      "3. CONVERSION_RATE BY PACING LEVEL\n",
      "--------------------------------------------------------------------------------\n",
      "High pacing:\n",
      "  Mean CVR: 0.010067\n",
      "  Median CVR: 0.009010\n",
      "  Std CVR: 0.007790\n",
      "Med pacing:\n",
      "  Mean CVR: 0.010074\n",
      "  Median CVR: 0.008951\n",
      "  Std CVR: 0.007426\n",
      "Low pacing:\n",
      "  Mean CVR: 0.009495\n",
      "  Median CVR: 0.009046\n",
      "  Std CVR: 0.007293\n",
      "\n",
      "4. CONVERSION_RATE BY WIN STATUS\n",
      "--------------------------------------------------------------------------------\n",
      "Winners:\n",
      "  Mean CVR: 0.010032\n",
      "  Median CVR: 0.008966\n",
      "  N: 15,510,672\n",
      "\n",
      "Losers:\n",
      "  Mean CVR: 0.009875\n",
      "  Median CVR: 0.009182\n",
      "  N: 3,329,926\n",
      "\n",
      "Difference: 0.000157\n",
      "\n",
      "5. CONVERSION_RATE BY QUALITY QUARTILE\n",
      "--------------------------------------------------------------------------------\n",
      "Quality Q1:\n",
      "  Mean CVR: 0.008894\n",
      "  Mean Quality: 0.006990\n",
      "  Win rate: 81.00%\n",
      "Quality Q2:\n",
      "  Mean CVR: 0.007514\n",
      "  Mean Quality: 0.021951\n",
      "  Win rate: 85.03%\n",
      "Quality Q3:\n",
      "  Mean CVR: 0.011672\n",
      "  Mean Quality: 0.042846\n",
      "  Win rate: 79.90%\n",
      "Quality Q4:\n",
      "  Mean CVR: 0.011937\n",
      "  Mean Quality: 0.074888\n",
      "  Win rate: 83.38%\n",
      "\n",
      "6. CAMPAIGN-LEVEL CVR ANALYSIS\n",
      "--------------------------------------------------------------------------------\n",
      "Campaigns with 50+ bids: 42,767\n",
      "\n",
      "Campaign-level correlations:\n",
      "  Mean CVR vs Mean Pacing:   0.0174\n",
      "  Mean CVR vs Mean Bid:      0.0868\n",
      "  Mean CVR vs Win Rate:      0.0270\n",
      "\n",
      "7. CVR \u00d7 PACING INTERACTION\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Win Rate Matrix (CVR \u00d7 Pacing):\n",
      "pacing_cat      Low     Med    High\n",
      "cvr_tercile                        \n",
      "Low          0.4505  0.7906  0.8861\n",
      "Med          0.6708  0.8095  0.8364\n",
      "High         0.6417  0.8450  0.8457\n",
      "\n",
      "8. INTERPRETATION\n",
      "--------------------------------------------------------------------------------\n",
      "\u2022 CVR is INDEPENDENT of pacing (weak correlation)\n",
      "  \u2192 Budget allocation does NOT prioritize high-CVR campaigns\n",
      "\n",
      "\u2022 CVR moderately correlates with QUALITY (r=0.1578)\n",
      "  \u2192 Quality score partially reflects conversion potential\n",
      "\n",
      "\u2022 Winners and losers have similar CVR\n",
      "  \u2192 CVR has minimal impact on auction outcomes\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"CONVERSION_RATE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. CONVERSION_RATE DISTRIBUTION\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Mean conversion rate: {df['CONVERSION_RATE'].mean():.6f}\")\n",
    "print(f\"Median conversion rate: {df['CONVERSION_RATE'].median():.6f}\")\n",
    "print(f\"Std conversion rate: {df['CONVERSION_RATE'].std():.6f}\")\n",
    "print(f\"Min conversion rate: {df['CONVERSION_RATE'].min():.6f}\")\n",
    "print(f\"Max conversion rate: {df['CONVERSION_RATE'].max():.6f}\")\n",
    "\n",
    "print(\"\\nConversion Rate Quantiles:\")\n",
    "for q in [0.10, 0.25, 0.50, 0.75, 0.90, 0.95, 0.99]:\n",
    "    print(f\"  {q*100:5.1f}%: {df['CONVERSION_RATE'].quantile(q):.6f}\")\n",
    "\n",
    "print(\"\\n2. CONVERSION_RATE CORRELATIONS\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"CONVERSION_RATE vs PACING:     {df['CONVERSION_RATE'].corr(df['PACING']):.4f}\")\n",
    "print(f\"CONVERSION_RATE vs FINAL_BID:  {df['CONVERSION_RATE'].corr(df['FINAL_BID']):.4f}\")\n",
    "print(f\"CONVERSION_RATE vs QUALITY:    {df['CONVERSION_RATE'].corr(df['QUALITY']):.4f}\")\n",
    "print(f\"CONVERSION_RATE vs RANKING:    {df['CONVERSION_RATE'].corr(df['RANKING']):.4f}\")\n",
    "print(f\"CONVERSION_RATE vs IS_WINNER:  {df['CONVERSION_RATE'].corr(df['IS_WINNER']):.4f}\")\n",
    "\n",
    "print(\"\\n3. CONVERSION_RATE BY PACING LEVEL\")\n",
    "print(\"-\" * 80)\n",
    "for cat in ['High', 'Med', 'Low']:\n",
    "    cat_data = df[df['pacing_cat'] == cat]\n",
    "    print(f\"{cat} pacing:\")\n",
    "    print(f\"  Mean CVR: {cat_data['CONVERSION_RATE'].mean():.6f}\")\n",
    "    print(f\"  Median CVR: {cat_data['CONVERSION_RATE'].median():.6f}\")\n",
    "    print(f\"  Std CVR: {cat_data['CONVERSION_RATE'].std():.6f}\")\n",
    "\n",
    "print(\"\\n4. CONVERSION_RATE BY WIN STATUS\")\n",
    "print(\"-\" * 80)\n",
    "winners = df[df['IS_WINNER'] == True]\n",
    "losers = df[df['IS_WINNER'] == False]\n",
    "print(f\"Winners:\")\n",
    "print(f\"  Mean CVR: {winners['CONVERSION_RATE'].mean():.6f}\")\n",
    "print(f\"  Median CVR: {winners['CONVERSION_RATE'].median():.6f}\")\n",
    "print(f\"  N: {len(winners):,}\")\n",
    "print(f\"\\nLosers:\")\n",
    "print(f\"  Mean CVR: {losers['CONVERSION_RATE'].mean():.6f}\")\n",
    "print(f\"  Median CVR: {losers['CONVERSION_RATE'].median():.6f}\")\n",
    "print(f\"  N: {len(losers):,}\")\n",
    "print(f\"\\nDifference: {winners['CONVERSION_RATE'].mean() - losers['CONVERSION_RATE'].mean():.6f}\")\n",
    "\n",
    "print(\"\\n5. CONVERSION_RATE BY QUALITY QUARTILE\")\n",
    "print(\"-\" * 80)\n",
    "df['quality_quartile'] = pd.qcut(df['QUALITY'], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'], duplicates='drop')\n",
    "for q in ['Q1', 'Q2', 'Q3', 'Q4']:\n",
    "    q_data = df[df['quality_quartile'] == q]\n",
    "    if len(q_data) > 0:\n",
    "        print(f\"Quality {q}:\")\n",
    "        print(f\"  Mean CVR: {q_data['CONVERSION_RATE'].mean():.6f}\")\n",
    "        print(f\"  Mean Quality: {q_data['QUALITY'].mean():.6f}\")\n",
    "        print(f\"  Win rate: {q_data['IS_WINNER'].mean()*100:.2f}%\")\n",
    "\n",
    "print(\"\\n6. CAMPAIGN-LEVEL CVR ANALYSIS\")\n",
    "print(\"-\" * 80)\n",
    "campaign_cvr = df.groupby('CAMPAIGN_ID').agg({\n",
    "    'CONVERSION_RATE': ['mean', 'std'],\n",
    "    'PACING': 'mean',\n",
    "    'FINAL_BID': 'mean',\n",
    "    'IS_WINNER': 'mean',\n",
    "    'AUCTION_ID': 'count'\n",
    "}).reset_index()\n",
    "campaign_cvr.columns = ['_'.join(col).strip('_') for col in campaign_cvr.columns.values]\n",
    "campaign_cvr = campaign_cvr[campaign_cvr['AUCTION_ID_count'] >= 50]\n",
    "\n",
    "print(f\"Campaigns with 50+ bids: {len(campaign_cvr):,}\")\n",
    "print(f\"\\nCampaign-level correlations:\")\n",
    "print(f\"  Mean CVR vs Mean Pacing:   {campaign_cvr['CONVERSION_RATE_mean'].corr(campaign_cvr['PACING_mean']):.4f}\")\n",
    "print(f\"  Mean CVR vs Mean Bid:      {campaign_cvr['CONVERSION_RATE_mean'].corr(campaign_cvr['FINAL_BID_mean']):.4f}\")\n",
    "print(f\"  Mean CVR vs Win Rate:      {campaign_cvr['CONVERSION_RATE_mean'].corr(campaign_cvr['IS_WINNER_mean']):.4f}\")\n",
    "\n",
    "print(\"\\n7. CVR \u00d7 PACING INTERACTION\")\n",
    "print(\"-\" * 80)\n",
    "df['cvr_tercile'] = pd.qcut(df['CONVERSION_RATE'], q=3, labels=['Low', 'Med', 'High'], duplicates='drop')\n",
    "cvr_pacing_matrix = pd.crosstab([df['cvr_tercile']], [df['pacing_cat']], \n",
    "                                values=df['IS_WINNER'], aggfunc='mean')\n",
    "print(\"\\nWin Rate Matrix (CVR \u00d7 Pacing):\")\n",
    "print(cvr_pacing_matrix.round(4))\n",
    "\n",
    "print(\"\\n8. INTERPRETATION\")\n",
    "print(\"-\" * 80)\n",
    "corr_cvr_pacing = df['CONVERSION_RATE'].corr(df['PACING'])\n",
    "corr_cvr_quality = df['CONVERSION_RATE'].corr(df['QUALITY'])\n",
    "winner_cvr_diff = winners['CONVERSION_RATE'].mean() - losers['CONVERSION_RATE'].mean()\n",
    "\n",
    "if abs(corr_cvr_pacing) < 0.05:\n",
    "    print(\"\u2022 CVR is INDEPENDENT of pacing (weak correlation)\")\n",
    "    print(\"  \u2192 Budget allocation does NOT prioritize high-CVR campaigns\")\n",
    "else:\n",
    "    print(f\"\u2022 CVR correlates with pacing (r={corr_cvr_pacing:.4f})\")\n",
    "    print(\"  \u2192 Budget allocation may consider conversion predictions\")\n",
    "\n",
    "if abs(corr_cvr_quality) > 0.3:\n",
    "    print(f\"\\n\u2022 CVR strongly correlates with QUALITY (r={corr_cvr_quality:.4f})\")\n",
    "    print(\"  \u2192 Quality score incorporates conversion predictions\")\n",
    "elif abs(corr_cvr_quality) > 0.1:\n",
    "    print(f\"\\n\u2022 CVR moderately correlates with QUALITY (r={corr_cvr_quality:.4f})\")\n",
    "    print(\"  \u2192 Quality score partially reflects conversion potential\")\n",
    "else:\n",
    "    print(f\"\\n\u2022 CVR weakly correlates with QUALITY (r={corr_cvr_quality:.4f})\")\n",
    "    print(\"  \u2192 Quality and CVR are largely independent signals\")\n",
    "\n",
    "if abs(winner_cvr_diff) > 0.001:\n",
    "    print(f\"\\n\u2022 Winners have {'HIGHER' if winner_cvr_diff > 0 else 'LOWER'} CVR than losers\")\n",
    "    print(f\"  \u2192 Difference: {abs(winner_cvr_diff):.6f}\")\n",
    "    print(\"  \u2192 CVR influences auction outcomes\")\n",
    "else:\n",
    "    print(\"\\n\u2022 Winners and losers have similar CVR\")\n",
    "    print(\"  \u2192 CVR has minimal impact on auction outcomes\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "source": "print(\"=\"*80)\nprint(\"COMPREHENSIVE CORRELATION MATRIX\")\nprint(\"=\"*80)\n\nprint(\"\\nComputing pairwise correlations for all numeric variables...\")\n\n# Select numeric columns\nnumeric_cols = ['RANKING', 'QUALITY', 'FINAL_BID', 'PRICE', 'CONVERSION_RATE', \n                'PACING', 'IS_WINNER', 'hour', 'day_of_week']\n\n# Create correlation matrix\ncorr_sample = df[numeric_cols].sample(min(100000, len(df)), random_state=42)\ncorr_matrix = corr_sample.corr()\n\nprint(\"\\n1. FULL CORRELATION MATRIX\")\nprint(\"-\" * 80)\nprint(\"\\nVariables: RANKING, QUALITY, FINAL_BID, PRICE, CONVERSION_RATE, PACING, IS_WINNER, hour, day_of_week\")\nprint(\"\\nCorrelation Matrix:\")\nprint(corr_matrix.round(4).to_string())\n\nprint(\"\\n2. STRONGEST CORRELATIONS (|r| > 0.10)\")\nprint(\"-\" * 80)\n\n# Extract upper triangle\nimport numpy as np\nstrong_corrs = []\n\nfor i in range(len(corr_matrix.columns)):\n    for j in range(i+1, len(corr_matrix.columns)):\n        corr_val = corr_matrix.iloc[i, j]\n        if abs(corr_val) > 0.10:\n            strong_corrs.append({\n                'var1': corr_matrix.columns[i],\n                'var2': corr_matrix.columns[j],\n                'correlation': corr_val\n            })\n\nstrong_corrs_df = pd.DataFrame(strong_corrs).sort_values('correlation', key=abs, ascending=False)\n\nprint(f\"\\nStrong correlations (n={len(strong_corrs_df)}):\")\nprint(\"Variable 1          | Variable 2          | Correlation\")\nprint(\"-\" * 80)\nfor _, row in strong_corrs_df.iterrows():\n    print(f\"{row['var1']:18s} | {row['var2']:18s} | {row['correlation']:10.4f}\")\n\nprint(\"\\n3. VARIABLE-SPECIFIC CORRELATIONS\")\nprint(\"-\" * 80)\n\nkey_outcomes = ['IS_WINNER', 'RANKING', 'PRICE']\nfor outcome in key_outcomes:\n    print(f\"\\n{outcome} correlations:\")\n    outcome_corrs = corr_matrix[outcome].drop(outcome).sort_values(key=abs, ascending=False)\n    for var, corr in outcome_corrs.items():\n        print(f\"  {var:20s}: {corr:7.4f}\")\n\nprint(\"\\n4. INTERPRETATION OF KEY CORRELATIONS\")\nprint(\"-\" * 80)\n\n# IS_WINNER correlations\nwinner_pacing = corr_matrix.loc['IS_WINNER', 'PACING']\nwinner_bid = corr_matrix.loc['IS_WINNER', 'FINAL_BID']\nwinner_quality = corr_matrix.loc['IS_WINNER', 'QUALITY']\n\nprint(f\"\\nIS_WINNER drivers:\")\nprint(f\"  PACING:     {winner_pacing:7.4f} {'(STRONG)' if abs(winner_pacing) > 0.2 else '(MODERATE)' if abs(winner_pacing) > 0.1 else '(WEAK)'}\")\nprint(f\"  FINAL_BID:  {winner_bid:7.4f} {'(STRONG)' if abs(winner_bid) > 0.2 else '(MODERATE)' if abs(winner_bid) > 0.1 else '(WEAK)'}\")\nprint(f\"  QUALITY:    {winner_quality:7.4f} {'(STRONG)' if abs(winner_quality) > 0.2 else '(MODERATE)' if abs(winner_quality) > 0.1 else '(WEAK)'}\")\n\nif abs(winner_pacing) > abs(winner_bid):\n    print(\"\\n  \u2192 PACING is the strongest predictor of winning\")\n    print(\"  \u2192 Budget state matters more than bid amount\")\nelse:\n    print(\"\\n  \u2192 FINAL_BID is the strongest predictor of winning\")\n    print(\"  \u2192 Bid amount matters more than budget state\")\n\nprint(\"\\n\" + \"=\"*80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Comprehensive Correlation Matrix\n\nAll pairwise correlations between numeric variables.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking Function Analysis: Does RANKING = f(QUALITY \u00d7 FINAL_BID)?\n",
    "\n",
    "Test if ranking is determined by quality-adjusted bidding (GSP-style)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "AUCTION MECHANISM DETECTION: FIRST-PRICE VS SECOND-PRICE\n",
      "================================================================================\n",
      "\n",
      "Question: Does platform run first-price or second-price auctions?\n",
      "Method: Compare FINAL_BID (submitted bid) with PRICE (clearing price)\n",
      "\n",
      "Expected patterns:\n",
      "  \u2022 First-price:  FINAL_BID \u2248 PRICE (winner pays their bid)\n",
      "  \u2022 Second-price: FINAL_BID > PRICE (winner pays second-highest bid)\n",
      "\n",
      "1. DATA AVAILABILITY\n",
      "--------------------------------------------------------------------------------\n",
      "Total bids: 18,840,598\n",
      "Winners: 15,510,672 (82.33%)\n",
      "Winners with PRICE populated: 15,510,672 (100.00%)\n",
      "Losers: 3,329,926 (17.67%)\n",
      "Losers with PRICE populated: 0 (0.00%)\n",
      "\n",
      "2. BID VS PRICE COMPARISON (WINNERS ONLY)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Bid vs Price statistics (cents):\n",
      "  Mean FINAL_BID: 12.54\n",
      "  Mean PRICE: 11.47\n",
      "  Mean difference (BID - PRICE): 1.07\n",
      "  Median difference: 0.00\n",
      "  Mean ratio (BID / PRICE): 1.0787\n",
      "\n",
      "Difference distribution:\n",
      "    1.0%: 0.00 cents\n",
      "    5.0%: 0.00 cents\n",
      "   10.0%: 0.00 cents\n",
      "   25.0%: 0.00 cents\n",
      "   50.0%: 0.00 cents\n",
      "   75.0%: 0.00 cents\n",
      "   90.0%: 2.00 cents\n",
      "   95.0%: 5.00 cents\n",
      "   99.0%: 24.00 cents\n",
      "\n",
      "3. AUCTION TYPE CLASSIFICATION\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Auction type distribution (tolerance = 0.5 cents):\n",
      "  First-Price    : 12,778,725 (82.39%)\n",
      "  Second-Price   : 2,730,506 (17.60%)\n",
      "  Anomaly        : 1,441 (0.01%)\n",
      "\n",
      "4. SECOND-PRICE DISCOUNT ANALYSIS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Second-price auctions (n=2,730,506):\n",
      "  Mean discount (BID - PRICE): $0.0606\n",
      "  Median discount: $0.0200\n",
      "  Mean savings rate: 19.93%\n",
      "\n",
      "  Discount distribution:\n",
      "     10.0%: $0.0100\n",
      "     25.0%: $0.0100\n",
      "     50.0%: $0.0200\n",
      "     75.0%: $0.0600\n",
      "     90.0%: $0.1700\n",
      "     95.0%: $0.2500\n",
      "     99.0%: $0.4600\n",
      "\n",
      "5. AUCTION TYPE BY PLACEMENT\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Auction type % by placement:\n",
      "auction_type  Anomaly  First-Price  Second-Price\n",
      "PLACEMENT                                       \n",
      "1                0.00        87.36         12.64\n",
      "2                0.00        92.58          7.42\n",
      "3                0.00        88.04         11.96\n",
      "4                0.00        87.39         12.61\n",
      "5                0.02        73.91         26.07\n",
      "\n",
      "6. TEMPORAL VARIATION\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Auction type % by time of day:\n",
      "auction_type  Anomaly  First-Price  Second-Price\n",
      "hour_bin                                        \n",
      "Night            0.03        80.98         18.99\n",
      "Morning          0.01        77.09         22.90\n",
      "Afternoon        0.00        86.33         13.67\n",
      "Evening          0.00        84.13         15.87\n",
      "\n",
      "7. ANOMALY INVESTIGATION (PRICE > BID)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Anomalies (PRICE > BID): 1,441 cases\n",
      "  Mean BID: $0.4208\n",
      "  Mean PRICE: $0.4308\n",
      "  Mean overcharge: $0.0100\n",
      "\n",
      "  Possible explanations:\n",
      "    \u2022 PRICE includes platform fees/markup\n",
      "    \u2022 Reserve prices or minimum bid floors\n",
      "    \u2022 PRICE = commodity price, not clearing price\n",
      "    \u2022 Data quality issues\n",
      "\n",
      "8. INTERPRETATION\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\u26a0 MIXED SYSTEM WITH FIRST-PRICE MAJORITY\n",
      "  First-price: 82.4%\n",
      "  Second-price: 17.6%\n",
      "  System may vary by placement or time\n",
      "\n",
      "\u2713 Auction type VARIES BY PLACEMENT (range: 18.7pp)\n",
      "  Different placements use different auction mechanisms\n",
      "\n",
      "\u2713 Auction type is STABLE over time (range: 9.2pp)\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"AUCTION MECHANISM DETECTION: FIRST-PRICE VS SECOND-PRICE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nQuestion: Does platform run first-price or second-price auctions?\")\n",
    "print(\"Method: Compare FINAL_BID (submitted bid) with PRICE (clearing price)\")\n",
    "print(\"\\nExpected patterns:\")\n",
    "print(\"  \u2022 First-price:  FINAL_BID \u2248 PRICE (winner pays their bid)\")\n",
    "print(\"  \u2022 Second-price: FINAL_BID > PRICE (winner pays second-highest bid)\")\n",
    "\n",
    "print(\"\\n1. DATA AVAILABILITY\")\n",
    "print(\"-\" * 80)\n",
    "winners = df[df['IS_WINNER'] == True].copy()\n",
    "winners_with_price = winners[winners['PRICE'].notna()]\n",
    "losers = df[df['IS_WINNER'] == False].copy()\n",
    "\n",
    "print(f\"Total bids: {len(df):,}\")\n",
    "print(f\"Winners: {len(winners):,} ({len(winners)/len(df)*100:.2f}%)\")\n",
    "print(f\"Winners with PRICE populated: {len(winners_with_price):,} ({len(winners_with_price)/len(winners)*100:.2f}%)\")\n",
    "print(f\"Losers: {len(losers):,} ({len(losers)/len(df)*100:.2f}%)\")\n",
    "print(f\"Losers with PRICE populated: {losers['PRICE'].notna().sum():,} ({losers['PRICE'].notna().mean()*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n2. BID VS PRICE COMPARISON (WINNERS ONLY)\")\n",
    "print(\"-\" * 80)\n",
    "winners_with_price['bid_price_diff'] = winners_with_price['FINAL_BID'] - winners_with_price['PRICE']\n",
    "winners_with_price['bid_price_ratio'] = winners_with_price['FINAL_BID'] / (winners_with_price['PRICE'] + 0.01)\n",
    "\n",
    "print(f\"\\nBid vs Price statistics (cents):\")\n",
    "print(f\"  Mean FINAL_BID: {winners_with_price['FINAL_BID'].mean():.2f}\")\n",
    "print(f\"  Mean PRICE: {winners_with_price['PRICE'].mean():.2f}\")\n",
    "print(f\"  Mean difference (BID - PRICE): {winners_with_price['bid_price_diff'].mean():.2f}\")\n",
    "print(f\"  Median difference: {winners_with_price['bid_price_diff'].median():.2f}\")\n",
    "print(f\"  Mean ratio (BID / PRICE): {winners_with_price['bid_price_ratio'].mean():.4f}\")\n",
    "\n",
    "print(\"\\nDifference distribution:\")\n",
    "for q in [0.01, 0.05, 0.10, 0.25, 0.50, 0.75, 0.90, 0.95, 0.99]:\n",
    "    print(f\"  {q*100:5.1f}%: {winners_with_price['bid_price_diff'].quantile(q):.2f} cents\")\n",
    "\n",
    "print(\"\\n3. AUCTION TYPE CLASSIFICATION\")\n",
    "print(\"-\" * 80)\n",
    "tolerance = 0.5  # cents tolerance for \"approximately equal\"\n",
    "winners_with_price['auction_type'] = 'Unknown'\n",
    "winners_with_price.loc[abs(winners_with_price['bid_price_diff']) <= tolerance, 'auction_type'] = 'First-Price'\n",
    "winners_with_price.loc[winners_with_price['bid_price_diff'] > tolerance, 'auction_type'] = 'Second-Price'\n",
    "winners_with_price.loc[winners_with_price['bid_price_diff'] < -tolerance, 'auction_type'] = 'Anomaly'\n",
    "\n",
    "auction_type_counts = winners_with_price['auction_type'].value_counts()\n",
    "print(f\"\\nAuction type distribution (tolerance = {tolerance} cents):\")\n",
    "for auction_type in ['First-Price', 'Second-Price', 'Anomaly']:\n",
    "    if auction_type in auction_type_counts.index:\n",
    "        count = auction_type_counts[auction_type]\n",
    "        pct = count / len(winners_with_price) * 100\n",
    "        print(f\"  {auction_type:15s}: {count:,} ({pct:.2f}%)\")\n",
    "\n",
    "print(\"\\n4. SECOND-PRICE DISCOUNT ANALYSIS\")\n",
    "print(\"-\" * 80)\n",
    "second_price = winners_with_price[winners_with_price['auction_type'] == 'Second-Price']\n",
    "if len(second_price) > 0:\n",
    "    print(f\"\\nSecond-price auctions (n={len(second_price):,}):\")\n",
    "    print(f\"  Mean discount (BID - PRICE): ${second_price['bid_price_diff'].mean()/100:.4f}\")\n",
    "    print(f\"  Median discount: ${second_price['bid_price_diff'].median()/100:.4f}\")\n",
    "    print(f\"  Mean savings rate: {(1 - second_price['PRICE']/second_price['FINAL_BID']).mean()*100:.2f}%\")\n",
    "    \n",
    "    print(\"\\n  Discount distribution:\")\n",
    "    for q in [0.10, 0.25, 0.50, 0.75, 0.90, 0.95, 0.99]:\n",
    "        print(f\"    {q*100:5.1f}%: ${second_price['bid_price_diff'].quantile(q)/100:.4f}\")\n",
    "else:\n",
    "    print(\"\\nNo second-price auctions detected\")\n",
    "\n",
    "print(\"\\n5. AUCTION TYPE BY PLACEMENT\")\n",
    "print(\"-\" * 80)\n",
    "auction_by_placement = pd.crosstab(winners_with_price['PLACEMENT'], \n",
    "                                   winners_with_price['auction_type'], \n",
    "                                   normalize='index') * 100\n",
    "print(\"\\nAuction type % by placement:\")\n",
    "print(auction_by_placement.round(2))\n",
    "\n",
    "print(\"\\n6. TEMPORAL VARIATION\")\n",
    "print(\"-\" * 80)\n",
    "winners_with_price['hour_bin'] = pd.cut(winners_with_price['hour'], \n",
    "                                         bins=[0, 6, 12, 18, 24], \n",
    "                                         labels=['Night', 'Morning', 'Afternoon', 'Evening'],\n",
    "                                         include_lowest=True)\n",
    "auction_by_time = pd.crosstab(winners_with_price['hour_bin'], \n",
    "                              winners_with_price['auction_type'], \n",
    "                              normalize='index') * 100\n",
    "print(\"\\nAuction type % by time of day:\")\n",
    "print(auction_by_time.round(2))\n",
    "\n",
    "print(\"\\n7. ANOMALY INVESTIGATION (PRICE > BID)\")\n",
    "print(\"-\" * 80)\n",
    "anomalies = winners_with_price[winners_with_price['auction_type'] == 'Anomaly']\n",
    "if len(anomalies) > 0:\n",
    "    print(f\"\\nAnomalies (PRICE > BID): {len(anomalies):,} cases\")\n",
    "    print(f\"  Mean BID: ${anomalies['FINAL_BID'].mean()/100:.4f}\")\n",
    "    print(f\"  Mean PRICE: ${anomalies['PRICE'].mean()/100:.4f}\")\n",
    "    print(f\"  Mean overcharge: ${abs(anomalies['bid_price_diff'].mean())/100:.4f}\")\n",
    "    \n",
    "    print(\"\\n  Possible explanations:\")\n",
    "    print(\"    \u2022 PRICE includes platform fees/markup\")\n",
    "    print(\"    \u2022 Reserve prices or minimum bid floors\")\n",
    "    print(\"    \u2022 PRICE = commodity price, not clearing price\")\n",
    "    print(\"    \u2022 Data quality issues\")\n",
    "else:\n",
    "    print(\"\\nNo anomalies detected (all PRICE \u2264 BID)\")\n",
    "\n",
    "print(\"\\n8. INTERPRETATION\")\n",
    "print(\"-\" * 80)\n",
    "first_price_pct = (auction_type_counts.get('First-Price', 0) / len(winners_with_price)) * 100\n",
    "second_price_pct = (auction_type_counts.get('Second-Price', 0) / len(winners_with_price)) * 100\n",
    "anomaly_pct = (auction_type_counts.get('Anomaly', 0) / len(winners_with_price)) * 100\n",
    "\n",
    "if first_price_pct > 90:\n",
    "    print(\"\\n\u2713 PREDOMINANTLY FIRST-PRICE AUCTION\")\n",
    "    print(f\"  {first_price_pct:.1f}% of auctions have BID \u2248 PRICE\")\n",
    "    print(\"  Winners pay their submitted bid\")\n",
    "elif second_price_pct > 90:\n",
    "    print(\"\\n\u2713 PREDOMINANTLY SECOND-PRICE AUCTION\")\n",
    "    print(f\"  {second_price_pct:.1f}% of auctions have BID > PRICE\")\n",
    "    print(\"  Winners pay second-highest bid (VCG-style)\")\n",
    "elif first_price_pct > 60:\n",
    "    print(\"\\n\u26a0 MIXED SYSTEM WITH FIRST-PRICE MAJORITY\")\n",
    "    print(f\"  First-price: {first_price_pct:.1f}%\")\n",
    "    print(f\"  Second-price: {second_price_pct:.1f}%\")\n",
    "    print(\"  System may vary by placement or time\")\n",
    "else:\n",
    "    print(\"\\n\u26a0 HYBRID OR COMPLEX AUCTION SYSTEM\")\n",
    "    print(f\"  First-price: {first_price_pct:.1f}%\")\n",
    "    print(f\"  Second-price: {second_price_pct:.1f}%\")\n",
    "    print(f\"  Anomalies: {anomaly_pct:.1f}%\")\n",
    "\n",
    "# Check for placement variation\n",
    "placement_range = auction_by_placement['First-Price'].max() - auction_by_placement['First-Price'].min()\n",
    "if placement_range > 10:\n",
    "    print(f\"\\n\u2713 Auction type VARIES BY PLACEMENT (range: {placement_range:.1f}pp)\")\n",
    "    print(\"  Different placements use different auction mechanisms\")\n",
    "else:\n",
    "    print(f\"\\n\u2713 Auction type is CONSISTENT across placements (range: {placement_range:.1f}pp)\")\n",
    "\n",
    "# Check for temporal variation\n",
    "time_range = auction_by_time['First-Price'].max() - auction_by_time['First-Price'].min()\n",
    "if time_range > 10:\n",
    "    print(f\"\\n\u26a0 Auction type VARIES BY TIME (range: {time_range:.1f}pp)\")\n",
    "    print(\"  Temporal A/B testing or gradual rollout detected\")\n",
    "else:\n",
    "    print(f\"\\n\u2713 Auction type is STABLE over time (range: {time_range:.1f}pp)\")\n",
    "\n",
    "if anomaly_pct > 5:\n",
    "    print(f\"\\n\u26a0 SIGNIFICANT ANOMALIES ({anomaly_pct:.1f}%)\")\n",
    "    print(\"  PRICE may not represent clearing price\")\n",
    "    print(\"  Could be catalog commodity price or include fees\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auction Mechanism Detection: First-Price vs Second-Price\n",
    "\n",
    "Compare FINAL_BID vs PRICE to infer auction type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Core Pacing Mechanisms\n",
    "\n",
    "### Test 1: Is PACING a bid multiplier?\n",
    "If FINAL_BID = BASE_BID \u00d7 PACING, we should see positive correlation within campaigns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TEST 1: PACING AS BID MULTIPLIER\n",
      "================================================================================\n",
      "\n",
      "Hypothesis: FINAL_BID = BASE_BID \u00d7 PACING\n",
      "Expected: Positive within-campaign correlation\n",
      "\n",
      "Campaigns with variable pacing: 6,651\n",
      "  (n\u2265100 bids, pacing_std>0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing within-campaign correlations: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 500/500 [04:00<00:00,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Within-campaign correlations (n=500 campaigns):\n",
      "  Mean correlation: -0.1454\n",
      "  Median correlation: -0.1158\n",
      "  Positive (>0.3): 54 (10.8%)\n",
      "  Negative (<-0.3): 170 (34.0%)\n",
      "\n",
      "Interpretation:\n",
      "  \u26a0 WEAK CORRELATION: FINAL_BID likely already has pacing applied\n",
      "    Data shows bids AFTER pacing discount, not before\n",
      "\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TEST 1: PACING AS BID MULTIPLIER\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nHypothesis: FINAL_BID = BASE_BID \u00d7 PACING\")\n",
    "print(\"Expected: Positive within-campaign correlation\")\n",
    "\n",
    "campaign_stats = df.groupby('CAMPAIGN_ID').agg({\n",
    "    'FINAL_BID': ['mean', 'std', 'count'],\n",
    "    'PACING': ['mean', 'std']\n",
    "}).reset_index()\n",
    "campaign_stats.columns = ['_'.join(col).strip('_') for col in campaign_stats.columns.values]\n",
    "\n",
    "variable_campaigns = campaign_stats[\n",
    "    (campaign_stats['FINAL_BID_count'] >= 100) &\n",
    "    (campaign_stats['PACING_std'] > 0.2)\n",
    "]\n",
    "\n",
    "print(f\"\\nCampaigns with variable pacing: {len(variable_campaigns):,}\")\n",
    "print(f\"  (n\u2265100 bids, pacing_std>0.2)\")\n",
    "\n",
    "sample_campaigns = variable_campaigns.sample(min(500, len(variable_campaigns)), random_state=42)['CAMPAIGN_ID'].values\n",
    "within_corrs = []\n",
    "for campaign_id in tqdm(sample_campaigns, desc=\"Computing within-campaign correlations\"):\n",
    "    camp_data = df[df['CAMPAIGN_ID'] == campaign_id]\n",
    "    if len(camp_data) >= 20:\n",
    "        corr = camp_data['PACING'].corr(camp_data['FINAL_BID'])\n",
    "        within_corrs.append(corr)\n",
    "\n",
    "print(f\"\\nWithin-campaign correlations (n={len(within_corrs):,} campaigns):\")\n",
    "print(f\"  Mean correlation: {np.mean(within_corrs):.4f}\")\n",
    "print(f\"  Median correlation: {np.median(within_corrs):.4f}\")\n",
    "print(f\"  Positive (>0.3): {(np.array(within_corrs) > 0.3).sum()} ({(np.array(within_corrs) > 0.3).mean()*100:.1f}%)\")\n",
    "print(f\"  Negative (<-0.3): {(np.array(within_corrs) < -0.3).sum()} ({(np.array(within_corrs) < -0.3).mean()*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "if np.mean(within_corrs) > 0.3:\n",
    "    print(\"  \u2713 STRONG EVIDENCE: PACING appears to be a bid multiplier\")\n",
    "elif np.mean(within_corrs) < -0.3:\n",
    "    print(\"  \u2717 INVERSE RELATIONSHIP: Higher pacing \u2192 Lower bids (unexpected)\")\n",
    "else:\n",
    "    print(\"  \u26a0 WEAK CORRELATION: FINAL_BID likely already has pacing applied\")\n",
    "    print(\"    Data shows bids AFTER pacing discount, not before\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2: Temporal Pacing Patterns (Budget Depletion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TEST 2: TEMPORAL PACING PATTERNS\n",
      "================================================================================\n",
      "\n",
      "Hypothesis: Pacing decreases during the day as budget depletes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing temporal patterns: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 200/200 [01:31<00:00,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Campaign-days analyzed: 463\n",
      "  Mean time-pacing correlation: -0.3235\n",
      "  Days with decreasing pacing: 240 (51.8%)\n",
      "  Days with increasing pacing: 60 (13.0%)\n",
      "  Mean pacing change (end - start): -0.2169\n",
      "\n",
      "Interpretation:\n",
      "  \u2713 EVIDENCE: Pacing decreases during the day \u2192 budget depletion\n",
      "\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TEST 2: TEMPORAL PACING PATTERNS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nHypothesis: Pacing decreases during the day as budget depletes\")\n",
    "\n",
    "sample_campaigns_temporal = variable_campaigns.head(200)['CAMPAIGN_ID'].values\n",
    "temporal_patterns = []\n",
    "\n",
    "for campaign_id in tqdm(sample_campaigns_temporal, desc=\"Analyzing temporal patterns\"):\n",
    "    camp_data = df[df['CAMPAIGN_ID'] == campaign_id].copy()\n",
    "    camp_data = camp_data.sort_values('datetime')\n",
    "    \n",
    "    for date in camp_data['date'].unique():\n",
    "        day_data = camp_data[camp_data['date'] == date]\n",
    "        if len(day_data) >= 10:\n",
    "            day_data = day_data.copy()\n",
    "            day_data['auction_order'] = range(len(day_data))\n",
    "            time_corr = day_data['auction_order'].corr(day_data['PACING'])\n",
    "            temporal_patterns.append({\n",
    "                'CAMPAIGN_ID': campaign_id,\n",
    "                'date': date,\n",
    "                'time_pacing_corr': time_corr,\n",
    "                'n_auctions': len(day_data),\n",
    "                'first_pacing': day_data.iloc[0]['PACING'],\n",
    "                'last_pacing': day_data.iloc[-1]['PACING'],\n",
    "                'pacing_change': day_data.iloc[-1]['PACING'] - day_data.iloc[0]['PACING']\n",
    "            })\n",
    "\n",
    "temporal_df = pd.DataFrame(temporal_patterns)\n",
    "print(f\"\\nCampaign-days analyzed: {len(temporal_df):,}\")\n",
    "print(f\"  Mean time-pacing correlation: {temporal_df['time_pacing_corr'].mean():.4f}\")\n",
    "print(f\"  Days with decreasing pacing: {(temporal_df['time_pacing_corr'] < -0.3).sum()} ({(temporal_df['time_pacing_corr'] < -0.3).mean()*100:.1f}%)\")\n",
    "print(f\"  Days with increasing pacing: {(temporal_df['time_pacing_corr'] > 0.3).sum()} ({(temporal_df['time_pacing_corr'] > 0.3).mean()*100:.1f}%)\")\n",
    "print(f\"  Mean pacing change (end - start): {temporal_df['pacing_change'].mean():.4f}\")\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "if temporal_df['time_pacing_corr'].mean() < -0.2:\n",
    "    print(\"  \u2713 EVIDENCE: Pacing decreases during the day \u2192 budget depletion\")\n",
    "elif temporal_df['time_pacing_corr'].mean() > 0.2:\n",
    "    print(\"  \u2717 COUNTER-EVIDENCE: Pacing increases during the day\")\n",
    "else:\n",
    "    print(\"  \u26a0 NEUTRAL: No clear temporal pattern\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3: Campaign-Level Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TEST 3: CAMPAIGN-LEVEL PACING CHARACTERISTICS\n",
      "================================================================================\n",
      "\n",
      "Total campaigns: 42,767\n",
      "\n",
      "Campaign Segments:\n",
      "  Stable high pacing (mean>0.95, std<0.05): 8,095 (18.9%)\n",
      "    Mean bid CV: 0.4441\n",
      "    Mean win rate: 81.71%\n",
      "\n",
      "  Variable pacing (std>0.2): 13,260 (31.0%)\n",
      "    Mean bid CV: 0.7387\n",
      "    Mean win rate: 79.73%\n",
      "\n",
      "  Stable low pacing (mean<0.7, std<0.15): 312 (0.7%)\n",
      "    Mean bid CV: 0.3560\n",
      "    Mean win rate: 88.29%\n",
      "\n",
      "Key Correlations (Campaign-Level):\n",
      "  Bid CV ~ Pacing Std: 0.3012\n",
      "  Mean Bid ~ Mean Pacing: -0.1974\n",
      "  Win Rate ~ Mean Pacing: -0.0118\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TEST 3: CAMPAIGN-LEVEL PACING CHARACTERISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "all_campaign_stats = df.groupby('CAMPAIGN_ID').agg({\n",
    "    'PACING': ['mean', 'std'],\n",
    "    'FINAL_BID': ['mean', 'std'],\n",
    "    'IS_WINNER': 'mean',\n",
    "    'QUALITY': 'mean',\n",
    "    'AUCTION_ID': 'count'\n",
    "}).reset_index()\n",
    "all_campaign_stats.columns = ['_'.join(col).strip('_') for col in all_campaign_stats.columns.values]\n",
    "all_campaign_stats = all_campaign_stats[all_campaign_stats['AUCTION_ID_count'] >= 50]\n",
    "\n",
    "all_campaign_stats['bid_cv'] = all_campaign_stats['FINAL_BID_std'] / (all_campaign_stats['FINAL_BID_mean'] + 0.01)\n",
    "all_campaign_stats['pacing_cv'] = all_campaign_stats['PACING_std'] / (all_campaign_stats['PACING_mean'] + 0.001)\n",
    "\n",
    "print(f\"\\nTotal campaigns: {len(all_campaign_stats):,}\")\n",
    "\n",
    "print(\"\\nCampaign Segments:\")\n",
    "stable_high = all_campaign_stats[(all_campaign_stats['PACING_mean'] > 0.95) & (all_campaign_stats['PACING_std'] < 0.05)]\n",
    "variable = all_campaign_stats[all_campaign_stats['PACING_std'] > 0.2]\n",
    "stable_low = all_campaign_stats[(all_campaign_stats['PACING_mean'] < 0.7) & (all_campaign_stats['PACING_std'] < 0.15)]\n",
    "\n",
    "print(f\"  Stable high pacing (mean>0.95, std<0.05): {len(stable_high):,} ({len(stable_high)/len(all_campaign_stats)*100:.1f}%)\")\n",
    "print(f\"    Mean bid CV: {stable_high['bid_cv'].mean():.4f}\")\n",
    "print(f\"    Mean win rate: {stable_high['IS_WINNER_mean'].mean()*100:.2f}%\")\n",
    "\n",
    "print(f\"\\n  Variable pacing (std>0.2): {len(variable):,} ({len(variable)/len(all_campaign_stats)*100:.1f}%)\")\n",
    "print(f\"    Mean bid CV: {variable['bid_cv'].mean():.4f}\")\n",
    "print(f\"    Mean win rate: {variable['IS_WINNER_mean'].mean()*100:.2f}%\")\n",
    "\n",
    "print(f\"\\n  Stable low pacing (mean<0.7, std<0.15): {len(stable_low):,} ({len(stable_low)/len(all_campaign_stats)*100:.1f}%)\")\n",
    "print(f\"    Mean bid CV: {stable_low['bid_cv'].mean():.4f}\")\n",
    "print(f\"    Mean win rate: {stable_low['IS_WINNER_mean'].mean()*100:.2f}%\")\n",
    "\n",
    "print(\"\\nKey Correlations (Campaign-Level):\")\n",
    "print(f\"  Bid CV ~ Pacing Std: {all_campaign_stats['bid_cv'].corr(all_campaign_stats['PACING_std']):.4f}\")\n",
    "print(f\"  Mean Bid ~ Mean Pacing: {all_campaign_stats['FINAL_BID_mean'].corr(all_campaign_stats['PACING_mean']):.4f}\")\n",
    "print(f\"  Win Rate ~ Mean Pacing: {all_campaign_stats['IS_WINNER_mean'].corr(all_campaign_stats['PACING_mean']):.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Ten Hypotheses Testing\n",
    "\n",
    "Testing 10 new hypotheses about pacing behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "10 HYPOTHESES TESTING\n",
      "================================================================================\n",
      "\n",
      "H1: Vendor-level pacing coordination\n",
      "--------------------------------------------------------------------------------\n",
      "Within-vendor pacing std: 0.0914\n",
      "Random baseline std: 0.1604\n",
      "Ratio: 0.5694\n",
      "Evidence: SUPPORT\n",
      "\n",
      "H2: Quality predicts pacing stability\n",
      "--------------------------------------------------------------------------------\n",
      "Correlation (Quality, Pacing Std): -0.1335\n",
      "N campaigns: 42,767\n",
      "Evidence: SUPPORT\n",
      "\n",
      "H3: Placement-specific pacing strategies\n",
      "--------------------------------------------------------------------------------\n",
      "Pacing range across placements: 0.0752\n",
      "  Placement 1: 0.8833\n",
      "  Placement 2: 0.8633\n",
      "  Placement 3: 0.9384\n",
      "  Placement 4: 0.9114\n",
      "  Placement 5: 0.8913\n",
      "Evidence: SUPPORT\n",
      "\n",
      "H4: Daily pacing resets\n",
      "--------------------------------------------------------------------------------\n",
      "Mean pacing jump (early - late): 0.0563\n",
      "Late night mean: 0.9033\n",
      "Early morning mean: 0.9699\n",
      "Evidence: WEAK\n",
      "\n",
      "H5: Low-pacing winners are exceptional\n",
      "--------------------------------------------------------------------------------\n",
      "Low-pacing winner quality: 0.040772\n",
      "High-pacing winner quality: 0.036131\n",
      "Ratio: 1.1285\n",
      "Low-pacing winner bid: $0.2340\n",
      "High-pacing winner bid: $0.1143\n",
      "Evidence: SUPPORT\n",
      "\n",
      "H6: CVR predicts budget allocation\n",
      "--------------------------------------------------------------------------------\n",
      "Correlation (CVR, Pacing): 0.0174\n",
      "Correlation (CVR, Bid): 0.0863\n",
      "Evidence: REJECT\n",
      "\n",
      "H7: Product bidding concentration\n",
      "--------------------------------------------------------------------------------\n",
      "Gini coefficient: 0.8255\n",
      "Top 10% products share: 80.37%\n",
      "Total unique products: 2,010,802\n",
      "Evidence: SUPPORT\n",
      "\n",
      "H8: Weekend pacing differs from weekday\n",
      "--------------------------------------------------------------------------------\n",
      "Weekend pacing: 0.8865\n",
      "Weekday pacing: 0.8929\n",
      "Difference: -0.0063\n",
      "Evidence: REJECT\n",
      "\n",
      "H9: Multi-product campaign pacing\n",
      "--------------------------------------------------------------------------------\n",
      "Single-product campaigns: 0.8421\n",
      "Multi-product campaigns (5+): 0.8762\n",
      "Difference: 0.0341\n",
      "Evidence: REJECT\n",
      "\n",
      "H10: Vendor-level budget cascades\n",
      "--------------------------------------------------------------------------------\n",
      "Low-pacing vendor-days: 1,692\n",
      "Total vendor-days: 23,516\n",
      "Cascade rate: 7.20%\n",
      "Evidence: WEAK\n",
      "\n",
      "================================================================================\n",
      "HYPOTHESIS SUMMARY\n",
      "================================================================================\n",
      "  H Evidence\n",
      " H1  SUPPORT\n",
      " H2  SUPPORT\n",
      " H3  SUPPORT\n",
      " H4     WEAK\n",
      " H5  SUPPORT\n",
      " H6   REJECT\n",
      " H7  SUPPORT\n",
      " H8   REJECT\n",
      " H9   REJECT\n",
      "H10     WEAK\n",
      "\n",
      "Supported: 5/10\n",
      "Weak/Moderate: 2/10\n",
      "Rejected: 3/10\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"10 HYPOTHESES TESTING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"\\nH1: Vendor-level pacing coordination\")\n",
    "print(\"-\" * 80)\n",
    "vendor_campaign_counts = df.groupby('VENDOR_ID')['CAMPAIGN_ID'].nunique()\n",
    "multi_campaign_vendors = vendor_campaign_counts[vendor_campaign_counts >= 3].index[:100]\n",
    "within_vendor_stds = []\n",
    "for vendor_id in multi_campaign_vendors:\n",
    "    vendor_campaigns = df[df['VENDOR_ID'] == vendor_id]['CAMPAIGN_ID'].unique()[:5]\n",
    "    campaign_pacings = [df[df['CAMPAIGN_ID'] == c]['PACING'].mean() for c in vendor_campaigns]\n",
    "    if len(campaign_pacings) >= 3:\n",
    "        within_vendor_stds.append(np.std(campaign_pacings))\n",
    "random_pacings = df.groupby('CAMPAIGN_ID')['PACING'].mean().sample(min(500, len(df['CAMPAIGN_ID'].unique())))\n",
    "random_groups = [random_pacings.values[i:i+5].std() for i in range(0, min(500, len(random_pacings)), 5)]\n",
    "h1_ratio = np.mean(within_vendor_stds) / np.mean(random_groups) if within_vendor_stds else 1\n",
    "print(f\"Within-vendor pacing std: {np.mean(within_vendor_stds):.4f}\")\n",
    "print(f\"Random baseline std: {np.mean(random_groups):.4f}\")\n",
    "print(f\"Ratio: {h1_ratio:.4f}\")\n",
    "print(f\"Evidence: {'SUPPORT' if h1_ratio < 0.85 else 'REJECT'}\")\n",
    "results.append({'H': 'H1', 'Evidence': 'SUPPORT' if h1_ratio < 0.85 else 'REJECT'})\n",
    "\n",
    "print(\"\\nH2: Quality predicts pacing stability\")\n",
    "print(\"-\" * 80)\n",
    "camp_stats = df.groupby('CAMPAIGN_ID').agg({'QUALITY': 'mean', 'PACING': 'std', 'AUCTION_ID': 'count'}).reset_index()\n",
    "camp_stats = camp_stats[camp_stats['AUCTION_ID'] >= 50]\n",
    "h2_corr = camp_stats['QUALITY'].corr(camp_stats['PACING'])\n",
    "print(f\"Correlation (Quality, Pacing Std): {h2_corr:.4f}\")\n",
    "print(f\"N campaigns: {len(camp_stats):,}\")\n",
    "print(f\"Evidence: {'SUPPORT' if h2_corr < -0.1 else 'REJECT'}\")\n",
    "results.append({'H': 'H2', 'Evidence': 'SUPPORT' if h2_corr < -0.1 else 'REJECT'})\n",
    "\n",
    "print(\"\\nH3: Placement-specific pacing strategies\")\n",
    "print(\"-\" * 80)\n",
    "placement_pacing = df.groupby('PLACEMENT')['PACING'].mean()\n",
    "h3_range = placement_pacing.max() - placement_pacing.min()\n",
    "print(f\"Pacing range across placements: {h3_range:.4f}\")\n",
    "for placement in placement_pacing.index:\n",
    "    print(f\"  Placement {placement}: {placement_pacing[placement]:.4f}\")\n",
    "print(f\"Evidence: {'SUPPORT' if h3_range > 0.05 else 'REJECT'}\")\n",
    "results.append({'H': 'H3', 'Evidence': 'SUPPORT' if h3_range > 0.05 else 'REJECT'})\n",
    "\n",
    "print(\"\\nH4: Daily pacing resets\")\n",
    "print(\"-\" * 80)\n",
    "late_night = df[df['hour'].isin([22, 23])].groupby('CAMPAIGN_ID')['PACING'].mean()\n",
    "early_morning = df[df['hour'].isin([0, 1, 2])].groupby('CAMPAIGN_ID')['PACING'].mean()\n",
    "common = set(late_night.index) & set(early_morning.index)\n",
    "if len(common) > 10:\n",
    "    jumps = [early_morning[c] - late_night[c] for c in list(common)[:200]]\n",
    "    h4_jump = np.mean(jumps)\n",
    "else:\n",
    "    h4_jump = 0\n",
    "print(f\"Mean pacing jump (early - late): {h4_jump:.4f}\")\n",
    "print(f\"Late night mean: {late_night.mean():.4f}\")\n",
    "print(f\"Early morning mean: {early_morning.mean():.4f}\")\n",
    "print(f\"Evidence: {'SUPPORT' if h4_jump > 0.1 else 'WEAK'}\")\n",
    "results.append({'H': 'H4', 'Evidence': 'SUPPORT' if h4_jump > 0.1 else 'WEAK'})\n",
    "\n",
    "print(\"\\nH5: Low-pacing winners are exceptional\")\n",
    "print(\"-\" * 80)\n",
    "low_pac_winners = df[(df['IS_WINNER']) & (df['PACING'] < 0.5)]\n",
    "high_pac_winners = df[(df['IS_WINNER']) & (df['PACING'] > 0.9)]\n",
    "h5_quality_ratio = low_pac_winners['QUALITY'].mean() / high_pac_winners['QUALITY'].mean()\n",
    "print(f\"Low-pacing winner quality: {low_pac_winners['QUALITY'].mean():.6f}\")\n",
    "print(f\"High-pacing winner quality: {high_pac_winners['QUALITY'].mean():.6f}\")\n",
    "print(f\"Ratio: {h5_quality_ratio:.4f}\")\n",
    "print(f\"Low-pacing winner bid: ${low_pac_winners['FINAL_BID_DOLLARS'].mean():.4f}\")\n",
    "print(f\"High-pacing winner bid: ${high_pac_winners['FINAL_BID_DOLLARS'].mean():.4f}\")\n",
    "print(f\"Evidence: {'SUPPORT' if h5_quality_ratio > 1.05 else 'REJECT'}\")\n",
    "results.append({'H': 'H5', 'Evidence': 'SUPPORT' if h5_quality_ratio > 1.05 else 'REJECT'})\n",
    "\n",
    "print(\"\\nH6: CVR predicts budget allocation\")\n",
    "print(\"-\" * 80)\n",
    "camp_cvr = df.groupby('CAMPAIGN_ID').agg({'CONVERSION_RATE': 'mean', 'PACING': 'mean', 'FINAL_BID_DOLLARS': 'mean', 'AUCTION_ID': 'count'}).reset_index()\n",
    "camp_cvr = camp_cvr[camp_cvr['AUCTION_ID'] > 50]\n",
    "h6_corr_pacing = camp_cvr['CONVERSION_RATE'].corr(camp_cvr['PACING'])\n",
    "h6_corr_bid = camp_cvr['CONVERSION_RATE'].corr(camp_cvr['FINAL_BID_DOLLARS'])\n",
    "print(f\"Correlation (CVR, Pacing): {h6_corr_pacing:.4f}\")\n",
    "print(f\"Correlation (CVR, Bid): {h6_corr_bid:.4f}\")\n",
    "print(f\"Evidence: {'SUPPORT' if abs(h6_corr_pacing) > 0.1 or abs(h6_corr_bid) > 0.1 else 'REJECT'}\")\n",
    "results.append({'H': 'H6', 'Evidence': 'SUPPORT' if abs(h6_corr_pacing) > 0.1 or abs(h6_corr_bid) > 0.1 else 'REJECT'})\n",
    "\n",
    "print(\"\\nH7: Product bidding concentration\")\n",
    "print(\"-\" * 80)\n",
    "product_counts = df['PRODUCT_ID'].value_counts()\n",
    "sorted_counts = np.sort(product_counts.values)\n",
    "n = len(sorted_counts)\n",
    "h7_gini = (2 * np.sum(np.arange(1, n+1) * sorted_counts)) / (n * np.sum(sorted_counts)) - (n + 1) / n\n",
    "top_10pct = int(len(product_counts) * 0.1)\n",
    "h7_top10_share = product_counts.iloc[:top_10pct].sum() / len(df)\n",
    "print(f\"Gini coefficient: {h7_gini:.4f}\")\n",
    "print(f\"Top 10% products share: {h7_top10_share*100:.2f}%\")\n",
    "print(f\"Total unique products: {len(product_counts):,}\")\n",
    "print(f\"Evidence: {'SUPPORT' if h7_gini > 0.7 else 'MODERATE'}\")\n",
    "results.append({'H': 'H7', 'Evidence': 'SUPPORT' if h7_gini > 0.7 else 'MODERATE'})\n",
    "\n",
    "print(\"\\nH8: Weekend pacing differs from weekday\")\n",
    "print(\"-\" * 80)\n",
    "df['is_weekend'] = df['day_of_week'].isin([5, 6])\n",
    "weekend = df[df['is_weekend']]\n",
    "weekday = df[~df['is_weekend']]\n",
    "h8_diff = weekend['PACING'].mean() - weekday['PACING'].mean()\n",
    "print(f\"Weekend pacing: {weekend['PACING'].mean():.4f}\")\n",
    "print(f\"Weekday pacing: {weekday['PACING'].mean():.4f}\")\n",
    "print(f\"Difference: {h8_diff:.4f}\")\n",
    "print(f\"Evidence: {'SUPPORT' if abs(h8_diff) > 0.03 else 'REJECT'}\")\n",
    "results.append({'H': 'H8', 'Evidence': 'SUPPORT' if abs(h8_diff) > 0.03 else 'REJECT'})\n",
    "\n",
    "print(\"\\nH9: Multi-product campaign pacing\")\n",
    "print(\"-\" * 80)\n",
    "camp_products = df.groupby('CAMPAIGN_ID')['PRODUCT_ID'].nunique()\n",
    "camp_pacing = df.groupby('CAMPAIGN_ID')['PACING'].mean()\n",
    "combined = pd.DataFrame({'n_products': camp_products, 'pacing': camp_pacing})\n",
    "single = combined[combined['n_products'] == 1]\n",
    "multi = combined[combined['n_products'] >= 5]\n",
    "h9_diff = abs(single['pacing'].mean() - multi['pacing'].mean())\n",
    "print(f\"Single-product campaigns: {single['pacing'].mean():.4f}\")\n",
    "print(f\"Multi-product campaigns (5+): {multi['pacing'].mean():.4f}\")\n",
    "print(f\"Difference: {h9_diff:.4f}\")\n",
    "print(f\"Evidence: {'SUPPORT' if h9_diff > 0.05 else 'REJECT'}\")\n",
    "results.append({'H': 'H9', 'Evidence': 'SUPPORT' if h9_diff > 0.05 else 'REJECT'})\n",
    "\n",
    "print(\"\\nH10: Vendor-level budget cascades\")\n",
    "print(\"-\" * 80)\n",
    "vendor_daily = df.groupby(['VENDOR_ID', 'date']).agg({'PACING': 'mean', 'CAMPAIGN_ID': 'nunique'}).reset_index()\n",
    "multi_campaign_vendors = vendor_daily[vendor_daily['CAMPAIGN_ID'] >= 2]\n",
    "low_pacing_days = len(multi_campaign_vendors[multi_campaign_vendors['PACING'] < 0.5])\n",
    "total_days = len(multi_campaign_vendors)\n",
    "h10_cascade = low_pacing_days / total_days if total_days > 0 else 0\n",
    "print(f\"Low-pacing vendor-days: {low_pacing_days:,}\")\n",
    "print(f\"Total vendor-days: {total_days:,}\")\n",
    "print(f\"Cascade rate: {h10_cascade*100:.2f}%\")\n",
    "print(f\"Evidence: {'SUPPORT' if h10_cascade > 0.1 else 'WEAK'}\")\n",
    "results.append({'H': 'H10', 'Evidence': 'SUPPORT' if h10_cascade > 0.1 else 'WEAK'})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"HYPOTHESIS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.to_string(index=False))\n",
    "print(f\"\\nSupported: {(results_df['Evidence'] == 'SUPPORT').sum()}/10\")\n",
    "print(f\"Weak/Moderate: {results_df['Evidence'].isin(['WEAK', 'MODERATE']).sum()}/10\")\n",
    "print(f\"Rejected: {(results_df['Evidence'] == 'REJECT').sum()}/10\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Statistical Models\n",
    "\n",
    "### Model 1: Ranking Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STATISTICAL MODELS\n",
      "================================================================================\n",
      "\n",
      "MODEL 1: RANKING REGRESSION\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Unit of Analysis: Individual bid\n",
      "Dependent Variable: log(RANKING)\n",
      "Independent Variables: log(FINAL_BID), log(PACING), log(QUALITY)\n",
      "\n",
      "Model Equation:\n",
      "  log(RANKING) = \u03b2\u2080 + \u03b2\u2081\u00b7log(FINAL_BID) + \u03b2\u2082\u00b7log(PACING) + \u03b2\u2083\u00b7log(QUALITY) + \u03b5\n",
      "\n",
      "Purpose: Decompose what drives ranking in auctions\n",
      "Coefficient Interpretation: Elasticities (% change in rank for 1% change in X)\n",
      "Error Term: Captures placement effects, time effects, unmeasured quality\n",
      "\n",
      "Sample Size: 95,940\n",
      "R\u00b2: 0.0181\n",
      "\n",
      "Coefficients (Elasticities):\n",
      "  Intercept:          2.9033\n",
      "  log(FINAL_BID):    -0.0765  (1% \u2191 bid \u2192 0.08% change in rank)\n",
      "  log(PACING):        0.0552  (1% \u2191 pacing \u2192 -0.06% change in rank)\n",
      "  log(QUALITY):      -0.0533  (1% \u2191 quality \u2192 0.05% change in rank)\n",
      "\n",
      "Interpretation:\n",
      "  PACING has weak effect - FINAL_BID likely already incorporates pacing\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"STATISTICAL MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nMODEL 1: RANKING REGRESSION\")\n",
    "print(\"-\" * 80)\n",
    "print(\"\\nUnit of Analysis: Individual bid\")\n",
    "print(\"Dependent Variable: log(RANKING)\")\n",
    "print(\"Independent Variables: log(FINAL_BID), log(PACING), log(QUALITY)\")\n",
    "print(\"\\nModel Equation:\")\n",
    "print(\"  log(RANKING) = \u03b2\u2080 + \u03b2\u2081\u00b7log(FINAL_BID) + \u03b2\u2082\u00b7log(PACING) + \u03b2\u2083\u00b7log(QUALITY) + \u03b5\")\n",
    "print(\"\\nPurpose: Decompose what drives ranking in auctions\")\n",
    "print(\"Coefficient Interpretation: Elasticities (% change in rank for 1% change in X)\")\n",
    "print(\"Error Term: Captures placement effects, time effects, unmeasured quality\")\n",
    "\n",
    "sample_df = df.sample(min(100000, len(df)), random_state=42)\n",
    "sample_df = sample_df[(sample_df['FINAL_BID'] > 0) & (sample_df['PACING'] > 0) & (sample_df['QUALITY'] > 0)].copy()\n",
    "\n",
    "sample_df['log_rank'] = np.log(sample_df['RANKING'])\n",
    "sample_df['log_bid'] = np.log(sample_df['FINAL_BID'])\n",
    "sample_df['log_pacing'] = np.log(sample_df['PACING'])\n",
    "sample_df['log_quality'] = np.log(sample_df['QUALITY'])\n",
    "\n",
    "X = sample_df[['log_bid', 'log_pacing', 'log_quality']].values\n",
    "X = np.column_stack([np.ones(len(X)), X])\n",
    "y = sample_df['log_rank'].values\n",
    "\n",
    "beta = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "resid = y - X @ beta\n",
    "r2 = 1 - (resid**2).sum() / ((y - y.mean())**2).sum()\n",
    "\n",
    "print(f\"\\nSample Size: {len(sample_df):,}\")\n",
    "print(f\"R\u00b2: {r2:.4f}\")\n",
    "print(f\"\\nCoefficients (Elasticities):\")\n",
    "print(f\"  Intercept:        {beta[0]:8.4f}\")\n",
    "print(f\"  log(FINAL_BID):   {beta[1]:8.4f}  (1% \u2191 bid \u2192 {-beta[1]:.2f}% change in rank)\")\n",
    "print(f\"  log(PACING):      {beta[2]:8.4f}  (1% \u2191 pacing \u2192 {-beta[2]:.2f}% change in rank)\")\n",
    "print(f\"  log(QUALITY):     {beta[3]:8.4f}  (1% \u2191 quality \u2192 {-beta[3]:.2f}% change in rank)\")\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "if abs(beta[2]) > 0.1:\n",
    "    print(f\"  PACING has independent effect on ranking\")\n",
    "else:\n",
    "    print(f\"  PACING has weak effect - FINAL_BID likely already incorporates pacing\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Win Probability Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MODEL 2: WIN PROBABILITY\n",
      "================================================================================\n",
      "\n",
      "Unit of Analysis: Individual bid\n",
      "Dependent Variable: IS_WINNER (binary)\n",
      "Model: Logistic Regression\n",
      "Independent Variables: PACING, FINAL_BID, QUALITY, PLACEMENT\n",
      "\n",
      "Purpose: Estimate how pacing affects win probability\n",
      "Coefficient Interpretation: Log-odds ratios\n",
      "\n",
      "Sample Size: 47,997\n",
      "Accuracy: 86.04%\n",
      "Baseline (always predict win): 86.04%\n",
      "\n",
      "Coefficients (Log-Odds):\n",
      "  Intercept:    0.0356\n",
      "  PACING:      -0.0004\n",
      "  FINAL_BID:    0.0013\n",
      "  QUALITY:      0.0010\n",
      "\n",
      "Marginal Effects (at means):\n",
      "  PACING:  -0.0001 (1 std \u2191 \u2192 -0.01pp change in win prob)\n",
      "  FINAL_BID:   0.0003 (1 std \u2191 \u2192 0.03pp change in win prob)\n",
      "  QUALITY:   0.0003 (1 std \u2191 \u2192 0.03pp change in win prob)\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"MODEL 2: WIN PROBABILITY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nUnit of Analysis: Individual bid\")\n",
    "print(\"Dependent Variable: IS_WINNER (binary)\")\n",
    "print(\"Model: Logistic Regression\")\n",
    "print(\"Independent Variables: PACING, FINAL_BID, QUALITY, PLACEMENT\")\n",
    "print(\"\\nPurpose: Estimate how pacing affects win probability\")\n",
    "print(\"Coefficient Interpretation: Log-odds ratios\")\n",
    "\n",
    "from scipy.special import expit\n",
    "\n",
    "sample_win = df.sample(min(50000, len(df)), random_state=42)\n",
    "sample_win = sample_win[(sample_win['FINAL_BID'] > 0) & (sample_win['PACING'] > 0)].copy()\n",
    "\n",
    "# Normalize features\n",
    "sample_win['pacing_norm'] = (sample_win['PACING'] - sample_win['PACING'].mean()) / sample_win['PACING'].std()\n",
    "sample_win['bid_norm'] = (sample_win['FINAL_BID'] - sample_win['FINAL_BID'].mean()) / sample_win['FINAL_BID'].std()\n",
    "sample_win['quality_norm'] = (sample_win['QUALITY'] - sample_win['QUALITY'].mean()) / sample_win['QUALITY'].std()\n",
    "\n",
    "X_win = sample_win[['pacing_norm', 'bid_norm', 'quality_norm']].values\n",
    "X_win = np.column_stack([np.ones(len(X_win)), X_win])\n",
    "y_win = sample_win['IS_WINNER'].values.astype(float)\n",
    "\n",
    "# Simple logistic regression via gradient descent (10 iterations for speed)\n",
    "beta_win = np.zeros(4)\n",
    "lr = 0.01\n",
    "for _ in range(10):\n",
    "    pred = expit(X_win @ beta_win)\n",
    "    gradient = X_win.T @ (pred - y_win) / len(y_win)\n",
    "    beta_win -= lr * gradient\n",
    "\n",
    "pred_final = expit(X_win @ beta_win)\n",
    "accuracy = ((pred_final > 0.5) == y_win).mean()\n",
    "\n",
    "print(f\"\\nSample Size: {len(sample_win):,}\")\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"Baseline (always predict win): {y_win.mean()*100:.2f}%\")\n",
    "print(f\"\\nCoefficients (Log-Odds):\")\n",
    "print(f\"  Intercept:  {beta_win[0]:8.4f}\")\n",
    "print(f\"  PACING:     {beta_win[1]:8.4f}\")\n",
    "print(f\"  FINAL_BID:  {beta_win[2]:8.4f}\")\n",
    "print(f\"  QUALITY:    {beta_win[3]:8.4f}\")\n",
    "\n",
    "print(\"\\nMarginal Effects (at means):\")\n",
    "mean_pred = expit(beta_win[0])\n",
    "for i, var in enumerate(['PACING', 'FINAL_BID', 'QUALITY']):\n",
    "    marginal = beta_win[i+1] * mean_pred * (1 - mean_pred)\n",
    "    print(f\"  {var}: {marginal:8.4f} (1 std \u2191 \u2192 {marginal*100:.2f}pp change in win prob)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}