{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA Analysis - Ad Platform Incrementality\n",
    "\n",
    "This notebook performs comprehensive exploratory data analysis on the sessionized data generated by `eda_browsing_session.ipynb`.\n",
    "\n",
    "**Output**: All results are displayed in the notebook AND saved to `eda_analysis_report.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting EDA Analysis...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# --- SETUP ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "DATA_DIR = Path('./data')\n",
    "REPORT_FILE = 'reports/eda_analysis_report.txt'  # Save to reports directory\n",
    "\n",
    "# Report logger\n",
    "class ReportLogger:\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.content = []\n",
    "        self.content.append(f\"=\"*80)\n",
    "        self.content.append(f\"EDA ANALYSIS REPORT\")\n",
    "        self.content.append(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        self.content.append(f\"=\"*80)\n",
    "        self.content.append(\"\\n\")\n",
    "    \n",
    "    def log(self, text):\n",
    "        \"\"\"Log text to both console and report buffer\"\"\"\n",
    "        print(text)\n",
    "        self.content.append(text)\n",
    "    \n",
    "    def save(self):\n",
    "        \"\"\"Save accumulated content to file\"\"\"\n",
    "        with open(self.filename, 'w') as f:\n",
    "            f.write('\\n'.join(str(line) for line in self.content))\n",
    "        print(f\"\\n[SUCCESS] Report saved to {self.filename}\")\n",
    "\n",
    "# Initialize report logger\n",
    "report = ReportLogger(REPORT_FILE)\n",
    "report.log(\"Starting EDA Analysis...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SECTION 1: DATA LOADING AND VALIDATION\n",
      "================================================================================\n",
      "\n",
      "Loading datasets:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - shopping_sessions: 790 rows, 18 columns\n",
      "  - browsing_sessions: 3,614 rows, 15 columns\n",
      "  - auctions_users: 19,173 rows, 3 columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data:  50%|█████     | 4/8 [00:00<00:00, 12.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - auctions_results: 719,751 rows, 7 columns\n",
      "  - impressions: 81,119 rows, 7 columns\n",
      "  - clicks: 2,105 rows, 7 columns\n",
      "  - purchases: 342 rows, 7 columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 100%|██████████| 8/8 [00:00<00:00, 10.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - catalog: 366,458 rows, 13 columns\n",
      "\n",
      "Data Validation:\n",
      "  Total datasets loaded: 8\n",
      "  Total raw events: 822,490\n",
      "\n",
      "  Note: Catalog prices are in dollars\n",
      "  Note: Purchase unit prices converted from cents to dollars\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# --- DATA LOADING ---\n",
    "report.log(\"=\"*80)\n",
    "report.log(\"SECTION 1: DATA LOADING AND VALIDATION\")\n",
    "report.log(\"=\"*80)\n",
    "\n",
    "# Define expected files\n",
    "data_files = {\n",
    "    'shopping_sessions': 'shopping_sessions.parquet',\n",
    "    'browsing_sessions': 'browsing_sessions.parquet',\n",
    "    'auctions_users': 'raw_sample_auctions_users.parquet',\n",
    "    'auctions_results': 'raw_sample_auctions_results.parquet',\n",
    "    'impressions': 'raw_sample_impressions.parquet',\n",
    "    'clicks': 'raw_sample_clicks.parquet',\n",
    "    'purchases': 'raw_sample_purchases.parquet',\n",
    "    'catalog': 'processed_sample_catalog.parquet'\n",
    "}\n",
    "\n",
    "# Load all datasets\n",
    "datasets = {}\n",
    "report.log(\"\\nLoading datasets:\")\n",
    "for name, filename in tqdm(data_files.items(), desc=\"Loading data\"):\n",
    "    filepath = DATA_DIR / filename\n",
    "    if filepath.exists():\n",
    "        datasets[name] = pd.read_csv(filepath) if filepath.suffix == '.csv' else pd.read_parquet(filepath)\n",
    "        shape = datasets[name].shape\n",
    "        report.log(f\"  - {name}: {shape[0]:,} rows, {shape[1]} columns\")\n",
    "    else:\n",
    "        report.log(f\"  - {name}: FILE NOT FOUND\")\n",
    "\n",
    "# Data validation\n",
    "report.log(\"\\nData Validation:\")\n",
    "report.log(f\"  Total datasets loaded: {len(datasets)}\")\n",
    "raw_event_count = sum(len(df) for name, df in datasets.items() if 'raw' in data_files.get(name, ''))\n",
    "report.log(f\"  Total raw events: {raw_event_count:,}\")\n",
    "\n",
    "# Extract dataframes for easier access\n",
    "df_shopping = datasets.get('shopping_sessions', pd.DataFrame())\n",
    "df_browsing = datasets.get('browsing_sessions', pd.DataFrame())\n",
    "df_auctions = datasets.get('auctions_users', pd.DataFrame())\n",
    "df_bids = datasets.get('auctions_results', pd.DataFrame())\n",
    "df_impressions = datasets.get('impressions', pd.DataFrame())\n",
    "df_clicks = datasets.get('clicks', pd.DataFrame())\n",
    "df_purchases = datasets.get('purchases', pd.DataFrame())\n",
    "df_catalog = datasets.get('catalog', pd.DataFrame())\n",
    "\n",
    "# Note: Prices are already in dollars (not cents) in the enhanced catalog\n",
    "# The catalog preprocessing already handled the conversion\n",
    "if 'PRICE' in df_catalog.columns:\n",
    "    report.log(\"\\n  Note: Catalog prices are in dollars\")\n",
    "\n",
    "if 'UNIT_PRICE' in df_purchases.columns:\n",
    "    # Purchase prices still need conversion from cents\n",
    "    df_purchases['UNIT_PRICE'] = df_purchases['UNIT_PRICE'] / 100\n",
    "    report.log(\"  Note: Purchase unit prices converted from cents to dollars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SECTION 2: BASIC STATISTICS\n",
      "================================================================================\n",
      "\n",
      "User Statistics:\n",
      "  Total unique users: 773\n",
      "  Users with shopping sessions: 773\n",
      "  Users who purchased: 137\n",
      "  Overall conversion rate: 17.72%\n",
      "\n",
      "Session Statistics:\n",
      "  Total shopping sessions: 790\n",
      "  Total browsing sessions: 3,614\n",
      "  Avg browsing sessions per shopping session: 4.57\n",
      "\n",
      "Auction Statistics:\n",
      "  Total auctions: 19,173\n",
      "  Total bids: 719,751\n",
      "  Avg bids per auction: 37.54\n",
      "\n",
      "Product Statistics:\n",
      "  Unique products in catalog: 366,458\n",
      "  Unique vendors bidding: 40,252\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# --- BASIC STATISTICS ---\n",
    "report.log(\"\\n\" + \"=\"*80)\n",
    "report.log(\"SECTION 2: BASIC STATISTICS\")\n",
    "report.log(\"=\"*80)\n",
    "\n",
    "# User statistics\n",
    "report.log(\"\\nUser Statistics:\")\n",
    "n_users_total = df_auctions['OPAQUE_USER_ID'].nunique() if 'OPAQUE_USER_ID' in df_auctions.columns else 0\n",
    "n_users_shopping = df_shopping['user_id'].nunique() if 'user_id' in df_shopping.columns else 0\n",
    "n_users_purchased = df_purchases['USER_ID'].nunique() if 'USER_ID' in df_purchases.columns else 0\n",
    "\n",
    "report.log(f\"  Total unique users: {n_users_total:,}\")\n",
    "report.log(f\"  Users with shopping sessions: {n_users_shopping:,}\")\n",
    "report.log(f\"  Users who purchased: {n_users_purchased:,}\")\n",
    "report.log(f\"  Overall conversion rate: {n_users_purchased/n_users_total:.2%}\" if n_users_total > 0 else \"  Overall conversion rate: N/A\")\n",
    "\n",
    "# Session statistics\n",
    "report.log(\"\\nSession Statistics:\")\n",
    "report.log(f\"  Total shopping sessions: {len(df_shopping):,}\")\n",
    "report.log(f\"  Total browsing sessions: {len(df_browsing):,}\")\n",
    "if 'num_browsing_sessions' in df_shopping.columns:\n",
    "    report.log(f\"  Avg browsing sessions per shopping session: {df_shopping['num_browsing_sessions'].mean():.2f}\")\n",
    "\n",
    "# Auction statistics\n",
    "report.log(\"\\nAuction Statistics:\")\n",
    "report.log(f\"  Total auctions: {len(df_auctions):,}\")\n",
    "report.log(f\"  Total bids: {len(df_bids):,}\")\n",
    "if len(df_auctions) > 0:\n",
    "    report.log(f\"  Avg bids per auction: {len(df_bids)/len(df_auctions):.2f}\")\n",
    "\n",
    "# Product statistics\n",
    "report.log(\"\\nProduct Statistics:\")\n",
    "n_products = df_catalog['PRODUCT_ID'].nunique() if 'PRODUCT_ID' in df_catalog.columns else 0\n",
    "n_vendors = df_bids['VENDOR_ID'].nunique() if 'VENDOR_ID' in df_bids.columns else 0\n",
    "report.log(f\"  Unique products in catalog: {n_products:,}\")\n",
    "report.log(f\"  Unique vendors bidding: {n_vendors:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SECTION 3: SESSION-LEVEL ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Shopping Session Conversion Analysis:\n",
      "  Shopping session conversion rate: 17.34%\n",
      "\n",
      "  Conversion by browsing session count:\n",
      "    1 browsing session(s): 1.62% (n=371.0)\n",
      "    2 browsing session(s): 14.91% (n=114.0)\n",
      "    3 browsing session(s): 17.86% (n=56.0)\n",
      "    4 browsing session(s): 22.45% (n=49.0)\n",
      "    5 browsing session(s): 28.57% (n=35.0)\n",
      "    6 browsing session(s): 25.00% (n=24.0)\n",
      "    7 browsing session(s): 44.44% (n=18.0)\n",
      "    8 browsing session(s): 29.41% (n=17.0)\n",
      "    9 browsing session(s): 62.50% (n=16.0)\n",
      "    10 browsing session(s): 42.86% (n=14.0)\n",
      "\n",
      "Browsing Session Duration Analysis:\n",
      "  Mean duration: 8.35 minutes\n",
      "  Median duration: 1.49 minutes\n",
      "  95th percentile: 39.71 minutes\n",
      "\n",
      "Event Distribution in Shopping Sessions:\n",
      "  Avg auctions per session: 24.27\n",
      "  Avg impressions per session: 102.68\n",
      "  Avg clicks per session: 2.66\n",
      "  Avg CTR per session: 2.63%\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# --- SESSION-LEVEL ANALYSIS ---\n",
    "report.log(\"\\n\" + \"=\"*80)\n",
    "report.log(\"SECTION 3: SESSION-LEVEL ANALYSIS\")\n",
    "report.log(\"=\"*80)\n",
    "\n",
    "# Shopping session conversion analysis\n",
    "if 'did_purchase' in df_shopping.columns:\n",
    "    report.log(\"\\nShopping Session Conversion Analysis:\")\n",
    "    conversion_rate = df_shopping['did_purchase'].mean()\n",
    "    report.log(f\"  Shopping session conversion rate: {conversion_rate:.2%}\")\n",
    "    \n",
    "    # Conversion by number of browsing sessions\n",
    "    if 'num_browsing_sessions' in df_shopping.columns:\n",
    "        report.log(\"\\n  Conversion by browsing session count:\")\n",
    "        conv_by_sessions = df_shopping.groupby('num_browsing_sessions')['did_purchase'].agg(['mean', 'count'])\n",
    "        for idx, row in conv_by_sessions.head(10).iterrows():\n",
    "            report.log(f\"    {idx} browsing session(s): {row['mean']:.2%} (n={row['count']:,})\")\n",
    "\n",
    "# Browsing session duration analysis\n",
    "if 'duration_minutes' in df_browsing.columns:\n",
    "    report.log(\"\\nBrowsing Session Duration Analysis:\")\n",
    "    duration_stats = df_browsing['duration_minutes'].describe()\n",
    "    report.log(f\"  Mean duration: {duration_stats['mean']:.2f} minutes\")\n",
    "    report.log(f\"  Median duration: {duration_stats['50%']:.2f} minutes\")\n",
    "    report.log(f\"  95th percentile: {df_browsing['duration_minutes'].quantile(0.95):.2f} minutes\")\n",
    "\n",
    "# Event distribution within sessions\n",
    "if all(col in df_shopping.columns for col in ['total_auctions', 'total_impressions', 'total_clicks']):\n",
    "    report.log(\"\\nEvent Distribution in Shopping Sessions:\")\n",
    "    report.log(f\"  Avg auctions per session: {df_shopping['total_auctions'].mean():.2f}\")\n",
    "    report.log(f\"  Avg impressions per session: {df_shopping['total_impressions'].mean():.2f}\")\n",
    "    report.log(f\"  Avg clicks per session: {df_shopping['total_clicks'].mean():.2f}\")\n",
    "    \n",
    "    # CTR calculation\n",
    "    sessions_with_impressions = df_shopping[df_shopping['total_impressions'] > 0]\n",
    "    if len(sessions_with_impressions) > 0:\n",
    "        avg_ctr = (sessions_with_impressions['total_clicks'] / sessions_with_impressions['total_impressions']).mean()\n",
    "        report.log(f\"  Avg CTR per session: {avg_ctr:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SECTION 4: MARKETPLACE DYNAMICS (AUCTION ANALYSIS)\n",
      "================================================================================\n",
      "\n",
      "Auction Competition Metrics:\n",
      "  Avg bids per auction: 37.81\n",
      "  Median bids per auction: 34\n",
      "  Max bids per auction: 74\n",
      "\n",
      "Win Rate by Rank Position:\n",
      "  Rank 1: 98.84% win rate (n=19,038.0)\n",
      "  Rank 2: 98.11% win rate (n=18,857.0)\n",
      "  Rank 3: 97.40% win rate (n=18,731.0)\n",
      "  Rank 4: 96.67% win rate (n=18,640.0)\n",
      "  Rank 5: 96.09% win rate (n=18,553.0)\n",
      "  Rank 6: 95.75% win rate (n=18,479.0)\n",
      "  Rank 7: 95.31% win rate (n=18,415.0)\n",
      "  Rank 8: 94.86% win rate (n=18,364.0)\n",
      "  Rank 9: 94.45% win rate (n=18,313.0)\n",
      "  Rank 10: 94.05% win rate (n=18,250.0)\n",
      "\n",
      "Vendor Participation:\n",
      "  Total vendors: 40,252\n",
      "  Top 5 vendors by bid volume:\n",
      "    064d8351...: 1,165 bids (0.2% of total)\n",
      "    018e9bee...: 1,117 bids (0.2% of total)\n",
      "    064df69b...: 884 bids (0.1% of total)\n",
      "    0198b16c...: 711 bids (0.1% of total)\n",
      "    06567cbe...: 689 bids (0.1% of total)\n",
      "\n",
      "Impression to Click Funnel:\n",
      "  Total impressions: 81,119\n",
      "  Total clicks: 2,105\n",
      "  Overall CTR: 2.59%\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# --- MARKETPLACE DYNAMICS ---\n",
    "report.log(\"\\n\" + \"=\"*80)\n",
    "report.log(\"SECTION 4: MARKETPLACE DYNAMICS (AUCTION ANALYSIS)\")\n",
    "report.log(\"=\"*80)\n",
    "\n",
    "# Auction competition analysis\n",
    "if not df_bids.empty and 'AUCTION_ID' in df_bids.columns:\n",
    "    report.log(\"\\nAuction Competition Metrics:\")\n",
    "    \n",
    "    # Bids per auction distribution\n",
    "    bids_per_auction = df_bids.groupby('AUCTION_ID').size()\n",
    "    report.log(f\"  Avg bids per auction: {bids_per_auction.mean():.2f}\")\n",
    "    report.log(f\"  Median bids per auction: {bids_per_auction.median():.0f}\")\n",
    "    report.log(f\"  Max bids per auction: {bids_per_auction.max():.0f}\")\n",
    "    \n",
    "    # Win rate by rank position\n",
    "    if 'RANKING' in df_bids.columns and 'IS_WINNER' in df_bids.columns:\n",
    "        report.log(\"\\nWin Rate by Rank Position:\")\n",
    "        win_by_rank = df_bids.groupby('RANKING')['IS_WINNER'].agg(['mean', 'count'])\n",
    "        for rank in range(1, min(11, len(win_by_rank) + 1)):\n",
    "            if rank in win_by_rank.index:\n",
    "                row = win_by_rank.loc[rank]\n",
    "                report.log(f\"  Rank {rank}: {row['mean']:.2%} win rate (n={row['count']:,})\")\n",
    "    \n",
    "    # Vendor participation\n",
    "    if 'VENDOR_ID' in df_bids.columns:\n",
    "        report.log(\"\\nVendor Participation:\")\n",
    "        vendor_bids = df_bids.groupby('VENDOR_ID').size().sort_values(ascending=False)\n",
    "        report.log(f\"  Total vendors: {len(vendor_bids):,}\")\n",
    "        report.log(f\"  Top 5 vendors by bid volume:\")\n",
    "        for vendor_id, count in vendor_bids.head(5).items():\n",
    "            pct = count / len(df_bids) * 100\n",
    "            report.log(f\"    {vendor_id[:8]}...: {count:,} bids ({pct:.1f}% of total)\")\n",
    "\n",
    "# Impression to click analysis\n",
    "if not df_impressions.empty and not df_clicks.empty:\n",
    "    report.log(\"\\nImpression to Click Funnel:\")\n",
    "    n_impressions = len(df_impressions)\n",
    "    n_clicks = len(df_clicks)\n",
    "    overall_ctr = n_clicks / n_impressions if n_impressions > 0 else 0\n",
    "    report.log(f\"  Total impressions: {n_impressions:,}\")\n",
    "    report.log(f\"  Total clicks: {n_clicks:,}\")\n",
    "    report.log(f\"  Overall CTR: {overall_ctr:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SECTION 5: USER BEHAVIOR PATTERNS\n",
      "================================================================================\n",
      "\n",
      "User Activity Segmentation:\n",
      "  Browsers: 636 users\n",
      "  Single purchasers: 137 users\n",
      "  Repeat purchasers: 0 users\n",
      "\n",
      "  Revenue Concentration:\n",
      "    Top 10% of users generate 86.8% of revenue\n",
      "\n",
      "Purchase Timing Patterns:\n",
      "  Peak purchase hour: 21:00 (69 purchases)\n",
      "  Peak purchase day: Thursday (67 purchases)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# --- USER BEHAVIOR PATTERNS ---\n",
    "report.log(\"\\n\" + \"=\"*80)\n",
    "report.log(\"SECTION 5: USER BEHAVIOR PATTERNS\")\n",
    "report.log(\"=\"*80)\n",
    "\n",
    "# User activity segmentation\n",
    "if 'user_id' in df_shopping.columns:\n",
    "    report.log(\"\\nUser Activity Segmentation:\")\n",
    "    user_sessions = df_shopping.groupby('user_id').agg({\n",
    "        'shopping_session_id': 'count',\n",
    "        'did_purchase': 'sum',\n",
    "        'total_revenue_usd': 'sum' if 'total_revenue_usd' in df_shopping.columns else 'first'\n",
    "    }).rename(columns={'shopping_session_id': 'n_sessions', 'did_purchase': 'n_purchases'})\n",
    "    \n",
    "    # Classify users\n",
    "    user_sessions['user_type'] = 'browser'\n",
    "    user_sessions.loc[user_sessions['n_purchases'] == 1, 'user_type'] = 'single_purchaser'\n",
    "    user_sessions.loc[user_sessions['n_purchases'] > 1, 'user_type'] = 'repeat_purchaser'\n",
    "    \n",
    "    user_type_dist = user_sessions['user_type'].value_counts()\n",
    "    report.log(f\"  Browsers: {user_type_dist.get('browser', 0):,} users\")\n",
    "    report.log(f\"  Single purchasers: {user_type_dist.get('single_purchaser', 0):,} users\")\n",
    "    report.log(f\"  Repeat purchasers: {user_type_dist.get('repeat_purchaser', 0):,} users\")\n",
    "    \n",
    "    # Revenue concentration\n",
    "    if 'total_revenue_usd' in df_shopping.columns:\n",
    "        total_revenue = user_sessions['total_revenue_usd'].sum()\n",
    "        if total_revenue > 0:\n",
    "            top_10pct_users = int(len(user_sessions) * 0.1)\n",
    "            top_users_revenue = user_sessions.nlargest(top_10pct_users, 'total_revenue_usd')['total_revenue_usd'].sum()\n",
    "            report.log(f\"\\n  Revenue Concentration:\")\n",
    "            report.log(f\"    Top 10% of users generate {top_users_revenue/total_revenue:.1%} of revenue\")\n",
    "\n",
    "# Purchase patterns\n",
    "if not df_purchases.empty and 'PURCHASED_AT' in df_purchases.columns:\n",
    "    report.log(\"\\nPurchase Timing Patterns:\")\n",
    "    df_purchases['PURCHASED_AT'] = pd.to_datetime(df_purchases['PURCHASED_AT'])\n",
    "    df_purchases['hour'] = df_purchases['PURCHASED_AT'].dt.hour\n",
    "    df_purchases['day_of_week'] = df_purchases['PURCHASED_AT'].dt.dayofweek\n",
    "    \n",
    "    # Hourly distribution\n",
    "    hourly_purchases = df_purchases['hour'].value_counts().sort_index()\n",
    "    peak_hour = hourly_purchases.idxmax()\n",
    "    report.log(f\"  Peak purchase hour: {peak_hour}:00 ({hourly_purchases[peak_hour]:,} purchases)\")\n",
    "    \n",
    "    # Day of week distribution (0=Monday, 6=Sunday)\n",
    "    day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    daily_purchases = df_purchases['day_of_week'].value_counts().sort_index()\n",
    "    peak_day = daily_purchases.idxmax()\n",
    "    report.log(f\"  Peak purchase day: {day_names[peak_day]} ({daily_purchases[peak_day]:,} purchases)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SECTION 6: PRODUCT & CATEGORY ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Top Products by Purchase Frequency:\n",
      "  1. 643d659974cb47c4f0cc...: 28 purchases\n",
      "  2. 6703e2b89b37c7b6b662...: 17 purchases\n",
      "  3. 64401cbfb2780c1796da...: 11 purchases\n",
      "  4. 63efbcadddab402df594...: 4 purchases\n",
      "  5. 68afb9f495538318707e...: 3 purchases\n",
      "  6. 670fda75013d2a47a068...: 3 purchases\n",
      "  7. 652560cc34d156f6ca9d...: 2 purchases\n",
      "  8. 68b212a1a0dc2b8bf606...: 1 purchases\n",
      "  9. 67f86f199f034caddc3f...: 1 purchases\n",
      "  10. 68b987fb2c9e441b412c...: 1 purchases\n",
      "\n",
      "Catalog Price Analysis:\n",
      "  Mean price: $61.71\n",
      "  Median price: $33.00\n",
      "  Price range: $3.00 - $999.00\n",
      "  Note: Excluded 1,695 products with unrealistic prices (>$1000)\n",
      "\n",
      "  Products by price range:\n",
      "    $10-25: 118,607 products (32.5%)\n",
      "    $25-50: 114,592 products (31.4%)\n",
      "    $50-100: 61,850 products (17.0%)\n",
      "    $100+: 45,562 products (12.5%)\n",
      "    $0-10: 24,152 products (6.6%)\n",
      "\n",
      "Enhanced Catalog Analysis:\n",
      "\n",
      "  Brand Distribution:\n",
      "    Total unique brands: 29,846\n",
      "    Products with brand info: 366,458 (100.0%)\n",
      "    Top 5 brands by product count:\n",
      "      : 39,638 products\n",
      "      lululemon athletica: 12,987 products\n",
      "      nike: 5,472 products\n",
      "      coach: 4,700 products\n",
      "      free people: 4,365 products\n",
      "\n",
      "  Department Distribution:\n",
      "    Total unique departments: 6\n",
      "    Products with department: 366,458 (100.0%)\n",
      "\n",
      "  Category Distribution:\n",
      "    Total unique categories: 95\n",
      "    Products with category: 366,458 (100.0%)\n",
      "\n",
      "  Color Distribution:\n",
      "    Total unique colors: 31\n",
      "    Products with color: 366,458 (100.0%)\n",
      "    Top 5 colors:\n",
      "      black: 46,043 products\n",
      "      : 36,630 products\n",
      "      blue: 32,730 products\n",
      "      blackcolor: 27,928 products\n",
      "      bluecolor: 20,350 products\n",
      "\n",
      "  Style Tags:\n",
      "    Products with style tags: 155,156 (42.3%)\n",
      "\n",
      "Product Performance Metrics:\n",
      "  Products with CTR data: 11\n",
      "  Mean product CTR: 9.15%\n",
      "  Median product CTR: 7.69%\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# --- PRODUCT & CATEGORY ANALYSIS ---\n",
    "report.log(\"\\n\" + \"=\"*80)\n",
    "report.log(\"SECTION 6: PRODUCT & CATEGORY ANALYSIS\")\n",
    "report.log(\"=\"*80)\n",
    "\n",
    "# Top products by different metrics\n",
    "if not df_purchases.empty and 'PRODUCT_ID' in df_purchases.columns:\n",
    "    report.log(\"\\nTop Products by Purchase Frequency:\")\n",
    "    product_purchases = df_purchases['PRODUCT_ID'].value_counts().head(10)\n",
    "    for i, (product_id, count) in enumerate(product_purchases.items(), 1):\n",
    "        report.log(f\"  {i}. {product_id[:20]}...: {count:,} purchases\")\n",
    "\n",
    "# Product catalog analysis\n",
    "if not df_catalog.empty:\n",
    "    report.log(\"\\nCatalog Price Analysis:\")\n",
    "    if 'PRICE' in df_catalog.columns:\n",
    "        # Filter out unrealistic prices (likely data errors)\n",
    "        reasonable_prices = df_catalog[df_catalog['PRICE'] < 1000]['PRICE']\n",
    "        price_stats = reasonable_prices.describe()\n",
    "        report.log(f\"  Mean price: ${price_stats['mean']:.2f}\")\n",
    "        report.log(f\"  Median price: ${price_stats['50%']:.2f}\")\n",
    "        report.log(f\"  Price range: ${price_stats['min']:.2f} - ${price_stats['max']:.2f}\")\n",
    "        report.log(f\"  Note: Excluded {len(df_catalog) - len(reasonable_prices):,} products with unrealistic prices (>$1000)\")\n",
    "\n",
    "        # Price distribution\n",
    "        price_bins = [0, 10, 25, 50, 100, 1000]\n",
    "        price_labels = ['$0-10', '$10-25', '$25-50', '$50-100', '$100+']\n",
    "        df_catalog_filtered = df_catalog[df_catalog['PRICE'] < 1000].copy()\n",
    "        df_catalog_filtered['price_range'] = pd.cut(df_catalog_filtered['PRICE'], bins=price_bins, labels=price_labels)\n",
    "        price_dist = df_catalog_filtered['price_range'].value_counts()\n",
    "        report.log(\"\\n  Products by price range:\")\n",
    "        for range_label, count in price_dist.items():\n",
    "            report.log(f\"    {range_label}: {count:,} products ({count/len(df_catalog_filtered):.1%})\")\n",
    "\n",
    "    # Enhanced catalog field analysis\n",
    "    report.log(\"\\nEnhanced Catalog Analysis:\")\n",
    "\n",
    "    # Brand analysis\n",
    "    if 'BRAND' in df_catalog.columns:\n",
    "        n_brands = df_catalog['BRAND'].nunique()\n",
    "        non_null_brands = df_catalog['BRAND'].notna().sum()\n",
    "        report.log(f\"\\n  Brand Distribution:\")\n",
    "        report.log(f\"    Total unique brands: {n_brands:,}\")\n",
    "        report.log(f\"    Products with brand info: {non_null_brands:,} ({non_null_brands/len(df_catalog):.1%})\")\n",
    "        top_brands = df_catalog['BRAND'].value_counts().head(5)\n",
    "        report.log(\"    Top 5 brands by product count:\")\n",
    "        for brand, count in top_brands.items():\n",
    "            if pd.notna(brand):\n",
    "                report.log(f\"      {brand}: {count:,} products\")\n",
    "\n",
    "    # Department analysis\n",
    "    if 'DEPARTMENT_ID' in df_catalog.columns:\n",
    "        n_departments = df_catalog['DEPARTMENT_ID'].nunique()\n",
    "        non_null_depts = df_catalog['DEPARTMENT_ID'].notna().sum()\n",
    "        report.log(f\"\\n  Department Distribution:\")\n",
    "        report.log(f\"    Total unique departments: {n_departments:,}\")\n",
    "        report.log(f\"    Products with department: {non_null_depts:,} ({non_null_depts/len(df_catalog):.1%})\")\n",
    "\n",
    "    # Category analysis\n",
    "    if 'CATEGORY_ID' in df_catalog.columns:\n",
    "        n_categories = df_catalog['CATEGORY_ID'].nunique()\n",
    "        non_null_cats = df_catalog['CATEGORY_ID'].notna().sum()\n",
    "        report.log(f\"\\n  Category Distribution:\")\n",
    "        report.log(f\"    Total unique categories: {n_categories:,}\")\n",
    "        report.log(f\"    Products with category: {non_null_cats:,} ({non_null_cats/len(df_catalog):.1%})\")\n",
    "\n",
    "    # Color analysis\n",
    "    if 'PRIMARY_COLOR' in df_catalog.columns:\n",
    "        n_colors = df_catalog['PRIMARY_COLOR'].nunique()\n",
    "        non_null_colors = df_catalog['PRIMARY_COLOR'].notna().sum()\n",
    "        report.log(f\"\\n  Color Distribution:\")\n",
    "        report.log(f\"    Total unique colors: {n_colors:,}\")\n",
    "        report.log(f\"    Products with color: {non_null_colors:,} ({non_null_colors/len(df_catalog):.1%})\")\n",
    "        top_colors = df_catalog['PRIMARY_COLOR'].value_counts().head(5)\n",
    "        report.log(\"    Top 5 colors:\")\n",
    "        for color, count in top_colors.items():\n",
    "            if pd.notna(color):\n",
    "                report.log(f\"      {color}: {count:,} products\")\n",
    "\n",
    "    # Style tags analysis\n",
    "    if 'STYLE_TAGS' in df_catalog.columns:\n",
    "        non_null_styles = df_catalog['STYLE_TAGS'].notna().sum()\n",
    "        non_empty_styles = (df_catalog['STYLE_TAGS'].notna() & (df_catalog['STYLE_TAGS'] != '')).sum()\n",
    "        report.log(f\"\\n  Style Tags:\")\n",
    "        report.log(f\"    Products with style tags: {non_empty_styles:,} ({non_empty_styles/len(df_catalog):.1%})\")\n",
    "\n",
    "# Click-through rate by product attributes\n",
    "if not df_clicks.empty and not df_impressions.empty:\n",
    "    report.log(\"\\nProduct Performance Metrics:\")\n",
    "    if 'PRODUCT_ID' in df_clicks.columns and 'PRODUCT_ID' in df_impressions.columns:\n",
    "        product_impressions = df_impressions['PRODUCT_ID'].value_counts()\n",
    "        product_clicks = df_clicks['PRODUCT_ID'].value_counts()\n",
    "        \n",
    "        # CTR by product (for products with >10 impressions)\n",
    "        product_ctr = (product_clicks / product_impressions).dropna()\n",
    "        qualified_products = product_impressions[product_impressions > 10].index\n",
    "        product_ctr = product_ctr[product_ctr.index.isin(qualified_products)]\n",
    "        \n",
    "        if len(product_ctr) > 0:\n",
    "            report.log(f\"  Products with CTR data: {len(product_ctr):,}\")\n",
    "            report.log(f\"  Mean product CTR: {product_ctr.mean():.2%}\")\n",
    "            report.log(f\"  Median product CTR: {product_ctr.median():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SECTION 7: CONVERSION FUNNEL ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Overall Funnel Metrics:\n",
      "  Auctions: 19,173\n",
      "  Bids: 719,751 (3753.98% of previous stage)\n",
      "  Impressions: 81,119 (100.00% of previous stage)\n",
      "  Clicks: 2,105 (2.59% of previous stage)\n",
      "  Purchases: 342 (16.25% of previous stage)\n",
      "\n",
      "Session-Level Funnel (Shopping Sessions):\n",
      "  Sessions with auctions: 790 (100.00%)\n",
      "  Sessions with impressions: 679 (85.95%)\n",
      "  Sessions with clicks: 307 (38.86%)\n",
      "  Sessions with purchases: 137 (17.34%)\n",
      "\n",
      "Revenue Metrics:\n",
      "  Total revenue: $9,150.00\n",
      "  Average order value: $66.79\n",
      "  Revenue per shopping session: $11.58\n",
      "\n",
      "  Revenue by browsing session count:\n",
      "    1 session(s): $0.40 avg, $148.00 total (n=371.0)\n",
      "    2 session(s): $9.07 avg, $1,034.00 total (n=114.0)\n",
      "    3 session(s): $5.79 avg, $324.00 total (n=56.0)\n",
      "    4 session(s): $10.33 avg, $506.00 total (n=49.0)\n",
      "    5 session(s): $12.14 avg, $425.00 total (n=35.0)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# --- CONVERSION FUNNEL ANALYSIS ---\n",
    "report.log(\"\\n\" + \"=\"*80)\n",
    "report.log(\"SECTION 7: CONVERSION FUNNEL ANALYSIS\")\n",
    "report.log(\"=\"*80)\n",
    "\n",
    "# Overall funnel metrics\n",
    "report.log(\"\\nOverall Funnel Metrics:\")\n",
    "funnel_metrics = {\n",
    "    'Auctions': len(df_auctions),\n",
    "    'Bids': len(df_bids),\n",
    "    'Impressions': len(df_impressions),\n",
    "    'Clicks': len(df_clicks),\n",
    "    'Purchases': len(df_purchases)\n",
    "}\n",
    "\n",
    "prev_count = None\n",
    "for stage, count in funnel_metrics.items():\n",
    "    if prev_count is not None and prev_count > 0:\n",
    "        conversion = count / prev_count\n",
    "        report.log(f\"  {stage}: {count:,} ({conversion:.2%} of previous stage)\")\n",
    "    else:\n",
    "        report.log(f\"  {stage}: {count:,}\")\n",
    "    prev_count = count if stage != 'Bids' else funnel_metrics['Impressions']  # Skip bids for funnel\n",
    "\n",
    "# Session-level funnel\n",
    "if all(col in df_shopping.columns for col in ['total_auctions', 'total_impressions', 'total_clicks', 'did_purchase']):\n",
    "    report.log(\"\\nSession-Level Funnel (Shopping Sessions):\")\n",
    "    \n",
    "    sessions_with_auctions = (df_shopping['total_auctions'] > 0).sum()\n",
    "    sessions_with_impressions = (df_shopping['total_impressions'] > 0).sum()\n",
    "    sessions_with_clicks = (df_shopping['total_clicks'] > 0).sum()\n",
    "    sessions_with_purchases = df_shopping['did_purchase'].sum()\n",
    "    \n",
    "    total_sessions = len(df_shopping)\n",
    "    report.log(f\"  Sessions with auctions: {sessions_with_auctions:,} ({sessions_with_auctions/total_sessions:.2%})\")\n",
    "    report.log(f\"  Sessions with impressions: {sessions_with_impressions:,} ({sessions_with_impressions/total_sessions:.2%})\")\n",
    "    report.log(f\"  Sessions with clicks: {sessions_with_clicks:,} ({sessions_with_clicks/total_sessions:.2%})\")\n",
    "    report.log(f\"  Sessions with purchases: {sessions_with_purchases:,} ({sessions_with_purchases/total_sessions:.2%})\")\n",
    "\n",
    "# Revenue analysis\n",
    "if 'total_revenue_usd' in df_shopping.columns:\n",
    "    report.log(\"\\nRevenue Metrics:\")\n",
    "    total_revenue = df_shopping['total_revenue_usd'].sum()\n",
    "    converting_sessions = df_shopping[df_shopping['did_purchase'] == 1]\n",
    "    \n",
    "    report.log(f\"  Total revenue: ${total_revenue:,.2f}\")\n",
    "    report.log(f\"  Average order value: ${converting_sessions['total_revenue_usd'].mean():.2f}\")\n",
    "    report.log(f\"  Revenue per shopping session: ${total_revenue/len(df_shopping):.2f}\")\n",
    "    \n",
    "    # Revenue by session characteristics\n",
    "    if 'num_browsing_sessions' in df_shopping.columns:\n",
    "        report.log(\"\\n  Revenue by browsing session count:\")\n",
    "        rev_by_browsing = df_shopping.groupby('num_browsing_sessions')['total_revenue_usd'].agg(['mean', 'sum', 'count'])\n",
    "        for idx, row in rev_by_browsing.head(5).iterrows():\n",
    "            report.log(f\"    {idx} session(s): ${row['mean']:.2f} avg, ${row['sum']:,.2f} total (n={row['count']:,})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SECTION 8: ADVANCED METRICS AND PATTERNS\n",
      "================================================================================\n",
      "\n",
      "Auction Efficiency Metrics:\n",
      "  Total bids: 719,751\n",
      "  Winning bids: 540,469\n",
      "  Overall win rate: 75.09%\n",
      "  Average bidders per auction: 37.81\n",
      "\n",
      "Click Concentration:\n",
      "  Top 10 products: 38 clicks (1.8% of total)\n",
      "  Top 100 products: 240 clicks (11.4% of total)\n",
      "\n",
      "Session Complexity and Conversion:\n",
      "  Conversion by click complexity:\n",
      "    0 clicks: 7.04% conversion (n=483.0)\n",
      "    1 click: 20.75% conversion (n=106.0)\n",
      "    2-5 clicks: 33.64% conversion (n=107.0)\n",
      "    6-10 clicks: 29.27% conversion (n=41.0)\n",
      "    10+ clicks: 62.26% conversion (n=53.0)\n",
      "\n",
      "Vendor Performance:\n",
      "  Top 5 vendors by win rate (min 10 bids):\n",
      "    018e71f7...: 100.00% (14/14)\n",
      "    018e7699...: 100.00% (12/12)\n",
      "    018e9f74...: 100.00% (21/21)\n",
      "    018ea0f2...: 100.00% (12/12)\n",
      "    018ea16f...: 100.00% (11/11)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# --- ADVANCED METRICS ---\n",
    "report.log(\"\\n\" + \"=\"*80)\n",
    "report.log(\"SECTION 8: ADVANCED METRICS AND PATTERNS\")\n",
    "report.log(\"=\"*80)\n",
    "\n",
    "# Auction efficiency metrics\n",
    "if not df_bids.empty and 'IS_WINNER' in df_bids.columns:\n",
    "    report.log(\"\\nAuction Efficiency Metrics:\")\n",
    "    total_bids = len(df_bids)\n",
    "    winning_bids = df_bids['IS_WINNER'].sum()\n",
    "    win_rate = winning_bids / total_bids if total_bids > 0 else 0\n",
    "    \n",
    "    report.log(f\"  Total bids: {total_bids:,}\")\n",
    "    report.log(f\"  Winning bids: {winning_bids:,}\")\n",
    "    report.log(f\"  Overall win rate: {win_rate:.2%}\")\n",
    "    \n",
    "    # Average competition per auction\n",
    "    if 'AUCTION_ID' in df_bids.columns:\n",
    "        avg_competition = df_bids.groupby('AUCTION_ID').size().mean()\n",
    "        report.log(f\"  Average bidders per auction: {avg_competition:.2f}\")\n",
    "\n",
    "# Click concentration analysis\n",
    "if not df_clicks.empty and 'PRODUCT_ID' in df_clicks.columns:\n",
    "    report.log(\"\\nClick Concentration:\")\n",
    "    product_clicks = df_clicks['PRODUCT_ID'].value_counts()\n",
    "    total_clicks = len(df_clicks)\n",
    "    top_10_products = product_clicks.head(10).sum()\n",
    "    top_100_products = product_clicks.head(100).sum()\n",
    "    \n",
    "    report.log(f\"  Top 10 products: {top_10_products:,} clicks ({top_10_products/total_clicks:.1%} of total)\")\n",
    "    report.log(f\"  Top 100 products: {top_100_products:,} clicks ({top_100_products/total_clicks:.1%} of total)\")\n",
    "\n",
    "# Session complexity and conversion\n",
    "if 'total_clicks' in df_shopping.columns and 'did_purchase' in df_shopping.columns:\n",
    "    report.log(\"\\nSession Complexity and Conversion:\")\n",
    "    \n",
    "    # Define complexity bins\n",
    "    df_shopping['click_bins'] = pd.cut(df_shopping['total_clicks'], \n",
    "                                        bins=[-0.1, 0, 1, 5, 10, float('inf')],\n",
    "                                        labels=['0 clicks', '1 click', '2-5 clicks', '6-10 clicks', '10+ clicks'])\n",
    "    \n",
    "    complexity_conv = df_shopping.groupby('click_bins', observed=True)['did_purchase'].agg(['mean', 'count'])\n",
    "    report.log(\"  Conversion by click complexity:\")\n",
    "    for idx, row in complexity_conv.iterrows():\n",
    "        report.log(f\"    {idx}: {row['mean']:.2%} conversion (n={row['count']:,})\")\n",
    "\n",
    "# Vendor performance metrics\n",
    "if not df_bids.empty and 'VENDOR_ID' in df_bids.columns and 'IS_WINNER' in df_bids.columns:\n",
    "    report.log(\"\\nVendor Performance:\")\n",
    "    vendor_metrics = df_bids.groupby('VENDOR_ID').agg({\n",
    "        'IS_WINNER': ['sum', 'mean'],\n",
    "        'AUCTION_ID': 'count'\n",
    "    })\n",
    "    vendor_metrics.columns = ['wins', 'win_rate', 'total_bids']\n",
    "    \n",
    "    # Top performers by win rate (min 10 bids)\n",
    "    qualified_vendors = vendor_metrics[vendor_metrics['total_bids'] >= 10]\n",
    "    if len(qualified_vendors) > 0:\n",
    "        top_win_rate = qualified_vendors.nlargest(5, 'win_rate')\n",
    "        report.log(\"  Top 5 vendors by win rate (min 10 bids):\")\n",
    "        for vendor_id, row in top_win_rate.iterrows():\n",
    "            report.log(f\"    {str(vendor_id)[:8]}...: {row['win_rate']:.2%} ({row['wins']:.0f}/{row['total_bids']:.0f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SECTION 9: DATA QUALITY ASSESSMENT\n",
      "================================================================================\n",
      "\n",
      "Data Completeness:\n",
      "  Shopping Sessions - user_id: 0 missing (0.00%)\n",
      "  Browsing Sessions - user_id: 0 missing (0.00%)\n",
      "  Bids - AUCTION_ID: 0 missing (0.00%)\n",
      "  Impressions - USER_ID: 0 missing (0.00%)\n",
      "  Clicks - USER_ID: 0 missing (0.00%)\n",
      "  Purchases - USER_ID: 0 missing (0.00%)\n",
      "\n",
      "Date Range Coverage:\n",
      "  Auctions: 2025-08-28 to 2025-09-06 (9 days)\n",
      "  Impressions: 2025-08-28 to 2025-09-06 (9 days)\n",
      "  Clicks: 2025-08-28 to 2025-09-06 (9 days)\n",
      "  Purchases: 2025-08-28 to 2025-09-06 (9 days)\n",
      "\n",
      "Join Key Availability:\n",
      "  Auction IDs in both bids and impressions: 9,904\n",
      "  Bids with matching impressions: 52.02%\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# --- DATA QUALITY ASSESSMENT ---\n",
    "report.log(\"\\n\" + \"=\"*80)\n",
    "report.log(\"SECTION 9: DATA QUALITY ASSESSMENT\")\n",
    "report.log(\"=\"*80)\n",
    "\n",
    "report.log(\"\\nData Completeness:\")\n",
    "\n",
    "# Check for missing values in key columns\n",
    "key_checks = [\n",
    "    (df_shopping, 'user_id', 'Shopping Sessions'),\n",
    "    (df_browsing, 'user_id', 'Browsing Sessions'),\n",
    "    (df_bids, 'AUCTION_ID', 'Bids'),\n",
    "    (df_impressions, 'USER_ID', 'Impressions'),\n",
    "    (df_clicks, 'USER_ID', 'Clicks'),\n",
    "    (df_purchases, 'USER_ID', 'Purchases')\n",
    "]\n",
    "\n",
    "for df, col, name in key_checks:\n",
    "    if not df.empty and col in df.columns:\n",
    "        missing = df[col].isna().sum()\n",
    "        pct_missing = missing / len(df) * 100\n",
    "        report.log(f\"  {name} - {col}: {missing:,} missing ({pct_missing:.2f}%)\")\n",
    "\n",
    "# Date range validation\n",
    "report.log(\"\\nDate Range Coverage:\")\n",
    "date_columns = [\n",
    "    (df_auctions, 'CREATED_AT', 'Auctions'),\n",
    "    (df_impressions, 'OCCURRED_AT', 'Impressions'),\n",
    "    (df_clicks, 'OCCURRED_AT', 'Clicks'),\n",
    "    (df_purchases, 'PURCHASED_AT', 'Purchases')\n",
    "]\n",
    "\n",
    "for df, col, name in date_columns:\n",
    "    if not df.empty and col in df.columns:\n",
    "        try:\n",
    "            dates = pd.to_datetime(df[col])\n",
    "            date_range = (dates.max() - dates.min()).days\n",
    "            report.log(f\"  {name}: {dates.min().date()} to {dates.max().date()} ({date_range} days)\")\n",
    "        except:\n",
    "            report.log(f\"  {name}: Unable to parse dates\")\n",
    "\n",
    "# Join key availability\n",
    "report.log(\"\\nJoin Key Availability:\")\n",
    "if not df_bids.empty and not df_impressions.empty:\n",
    "    # Check auction ID overlap\n",
    "    if 'AUCTION_ID' in df_bids.columns and 'AUCTION_ID' in df_impressions.columns:\n",
    "        bid_auctions = set(df_bids['AUCTION_ID'].dropna())\n",
    "        impression_auctions = set(df_impressions['AUCTION_ID'].dropna())\n",
    "        overlap = len(bid_auctions & impression_auctions)\n",
    "        report.log(f\"  Auction IDs in both bids and impressions: {overlap:,}\")\n",
    "        report.log(f\"  Bids with matching impressions: {overlap/len(bid_auctions):.2%}\" if bid_auctions else \"N/A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SECTION 10: EXECUTIVE SUMMARY STATISTICS\n",
      "================================================================================\n",
      "\n",
      "Key Performance Indicators:\n",
      "  Total Users: 773\n",
      "  User Conversion Rate: 17.72%\n",
      "  Shopping Sessions: 790\n",
      "  Session Conversion Rate: 17.34%\n",
      "  Total Revenue: $9,150.00\n",
      "  Average Order Value: $66.79\n",
      "  Overall CTR: 2.59%\n",
      "  Total Bids: 719,751\n",
      "  Bid Win Rate: 75.09%\n",
      "\n",
      "Data Volume Summary:\n",
      "  Users: 773\n",
      "  Shopping Sessions: 790\n",
      "  Browsing Sessions: 3,614\n",
      "  Auctions: 19,173\n",
      "  Bids: 719,751\n",
      "  Impressions: 81,119\n",
      "  Clicks: 2,105\n",
      "  Purchases: 342\n",
      "  Products: 366,458\n",
      "\n",
      "================================================================================\n",
      "END OF REPORT\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# --- SUMMARY STATISTICS ---\n",
    "report.log(\"\\n\" + \"=\"*80)\n",
    "report.log(\"SECTION 10: EXECUTIVE SUMMARY STATISTICS\")\n",
    "report.log(\"=\"*80)\n",
    "\n",
    "# Key performance indicators\n",
    "report.log(\"\\nKey Performance Indicators:\")\n",
    "\n",
    "# Calculate KPIs\n",
    "kpis = {}\n",
    "\n",
    "# User metrics\n",
    "if n_users_total > 0:\n",
    "    kpis['Total Users'] = f\"{n_users_total:,}\"\n",
    "    kpis['User Conversion Rate'] = f\"{n_users_purchased/n_users_total:.2%}\"\n",
    "\n",
    "# Session metrics\n",
    "if 'did_purchase' in df_shopping.columns:\n",
    "    kpis['Shopping Sessions'] = f\"{len(df_shopping):,}\"\n",
    "    kpis['Session Conversion Rate'] = f\"{df_shopping['did_purchase'].mean():.2%}\"\n",
    "\n",
    "# Revenue metrics\n",
    "if 'total_revenue_usd' in df_shopping.columns:\n",
    "    total_rev = df_shopping['total_revenue_usd'].sum()\n",
    "    kpis['Total Revenue'] = f\"${total_rev:,.2f}\"\n",
    "    if df_shopping['did_purchase'].sum() > 0:\n",
    "        aov = df_shopping[df_shopping['did_purchase']==1]['total_revenue_usd'].mean()\n",
    "        kpis['Average Order Value'] = f\"${aov:.2f}\"\n",
    "\n",
    "# Engagement metrics\n",
    "if not df_clicks.empty and not df_impressions.empty:\n",
    "    kpis['Overall CTR'] = f\"{len(df_clicks)/len(df_impressions):.2%}\"\n",
    "\n",
    "# Marketplace metrics\n",
    "if not df_bids.empty:\n",
    "    kpis['Total Bids'] = f\"{len(df_bids):,}\"\n",
    "    if 'IS_WINNER' in df_bids.columns:\n",
    "        kpis['Bid Win Rate'] = f\"{df_bids['IS_WINNER'].mean():.2%}\"\n",
    "\n",
    "# Print KPIs\n",
    "for metric, value in kpis.items():\n",
    "    report.log(f\"  {metric}: {value}\")\n",
    "\n",
    "# Data volume summary\n",
    "report.log(\"\\nData Volume Summary:\")\n",
    "volumes = [\n",
    "    ('Users', n_users_total),\n",
    "    ('Shopping Sessions', len(df_shopping)),\n",
    "    ('Browsing Sessions', len(df_browsing)),\n",
    "    ('Auctions', len(df_auctions)),\n",
    "    ('Bids', len(df_bids)),\n",
    "    ('Impressions', len(df_impressions)),\n",
    "    ('Clicks', len(df_clicks)),\n",
    "    ('Purchases', len(df_purchases)),\n",
    "    ('Products', len(df_catalog))\n",
    "]\n",
    "\n",
    "for name, count in volumes:\n",
    "    report.log(f\"  {name}: {count:,}\")\n",
    "\n",
    "report.log(\"\\n\" + \"=\"*80)\n",
    "report.log(\"END OF REPORT\")\n",
    "report.log(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[SUCCESS] Report saved to reports/eda_analysis_report.txt\n",
      "\n",
      "================================================================================\n",
      "EDA Analysis Complete!\n",
      "Report saved to: reports/eda_analysis_report.txt\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# --- SAVE REPORT ---\n",
    "report.save()\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EDA Analysis Complete!\")\n",
    "print(f\"Report saved to: {REPORT_FILE}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SECTION 11: BROWSING & SHOPPING SESSION DEEP DIVE\n",
      "================================================================================\n",
      "\n",
      "Browsing Session Characteristics:\n",
      "  Total browsing sessions: 3,614\n",
      "  Unique users: 773\n",
      "  Avg sessions per user: 4.68\n",
      "\n",
      "  Session Duration Distribution:\n",
      "    <1 min: 867 sessions (24.0%)\n",
      "    1-5 min: 794 sessions (22.0%)\n",
      "    5-15 min: 558 sessions (15.4%)\n",
      "    15-30 min: 357 sessions (9.9%)\n",
      "    30+ min: 276 sessions (7.6%)\n",
      "\n",
      "  Event Density per Browsing Session:\n",
      "    Avg auctions: 5.31\n",
      "    Avg impressions: 22.45\n",
      "    Avg clicks: 0.58\n",
      "    Sessions with no ads: 1,021 (28.3%)\n",
      "\n",
      "Shopping Session Patterns:\n",
      "\n",
      "  Multi-Session User Behavior:\n",
      "    Single-session users: 756\n",
      "    Multi-session users: 17\n",
      "    Max sessions per user: 2\n",
      "\n",
      "  Engagement to Conversion:\n",
      "    1 browse: 1.62% conversion (n=371.0)\n",
      "    2-3 browse: 15.88% conversion (n=170.0)\n",
      "    4-5 browse: 25.00% conversion (n=84.0)\n",
      "    6-10 browse: 39.33% conversion (n=89.0)\n",
      "    10+ browse: 63.16% conversion (n=76.0)\n",
      "\n",
      "  Ad Exposure Impact:\n",
      "    Sessions without ads: 111 (4.50% conversion)\n",
      "    Sessions with ads: 679 (19.44% conversion)\n",
      "    Estimated lift from ads: 331.6%\n",
      "\n",
      "Cross-Session Insights:\n",
      "  Browsing to shopping funnel:\n",
      "    Users who browsed: 773\n",
      "    Users who shopped: 773\n",
      "    Browse-to-shop rate: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# --- BROWSING & SHOPPING SESSION DEEP DIVE ---\n",
    "report.log(\"\\n\" + \"=\"*80)\n",
    "report.log(\"SECTION 11: BROWSING & SHOPPING SESSION DEEP DIVE\")\n",
    "report.log(\"=\"*80)\n",
    "\n",
    "# Browsing Session Analysis\n",
    "if not df_browsing.empty:\n",
    "    report.log(\"\\nBrowsing Session Characteristics:\")\n",
    "    \n",
    "    # Basic statistics\n",
    "    report.log(f\"  Total browsing sessions: {len(df_browsing):,}\")\n",
    "    report.log(f\"  Unique users: {df_browsing['user_id'].nunique():,}\")\n",
    "    report.log(f\"  Avg sessions per user: {len(df_browsing)/df_browsing['user_id'].nunique():.2f}\")\n",
    "    \n",
    "    # Duration analysis\n",
    "    if 'duration_minutes' in df_browsing.columns:\n",
    "        # Categorize session lengths\n",
    "        df_browsing['duration_category'] = pd.cut(\n",
    "            df_browsing['duration_minutes'], \n",
    "            bins=[0, 1, 5, 15, 30, float('inf')],\n",
    "            labels=['<1 min', '1-5 min', '5-15 min', '15-30 min', '30+ min']\n",
    "        )\n",
    "        duration_dist = df_browsing['duration_category'].value_counts()\n",
    "        report.log(\"\\n  Session Duration Distribution:\")\n",
    "        for cat, count in duration_dist.items():\n",
    "            report.log(f\"    {cat}: {count:,} sessions ({count/len(df_browsing):.1%})\")\n",
    "    \n",
    "    # Event density analysis\n",
    "    if all(col in df_browsing.columns for col in ['num_auctions', 'num_impressions', 'num_clicks']):\n",
    "        report.log(\"\\n  Event Density per Browsing Session:\")\n",
    "        report.log(f\"    Avg auctions: {df_browsing['num_auctions'].mean():.2f}\")\n",
    "        report.log(f\"    Avg impressions: {df_browsing['num_impressions'].mean():.2f}\")\n",
    "        report.log(f\"    Avg clicks: {df_browsing['num_clicks'].mean():.2f}\")\n",
    "        \n",
    "        # Sessions with no ad interactions\n",
    "        no_ads = df_browsing[(df_browsing['num_impressions'] == 0)].shape[0]\n",
    "        report.log(f\"    Sessions with no ads: {no_ads:,} ({no_ads/len(df_browsing):.1%})\")\n",
    "    \n",
    "    # Conversion within browsing sessions\n",
    "    if 'did_purchase' in df_browsing.columns:\n",
    "        browsing_conversions = df_browsing['did_purchase'].sum()\n",
    "        report.log(f\"\\n  Browsing sessions with purchases: {browsing_conversions:,} ({browsing_conversions/len(df_browsing):.2%})\")\n",
    "\n",
    "# Shopping Session Analysis\n",
    "if not df_shopping.empty:\n",
    "    report.log(\"\\nShopping Session Patterns:\")\n",
    "    \n",
    "    # Session length distribution\n",
    "    if 'session_duration_hours' in df_shopping.columns:\n",
    "        report.log(f\"\\n  Session Duration (Shopping):\")\n",
    "        duration_stats = df_shopping['session_duration_hours'].describe()\n",
    "        report.log(f\"    Mean: {duration_stats['mean']:.2f} hours\")\n",
    "        report.log(f\"    Median: {duration_stats['50%']:.2f} hours\")\n",
    "        report.log(f\"    95th percentile: {df_shopping['session_duration_hours'].quantile(0.95):.2f} hours\")\n",
    "    \n",
    "    # Multi-session user behavior\n",
    "    user_session_counts = df_shopping['user_id'].value_counts()\n",
    "    report.log(f\"\\n  Multi-Session User Behavior:\")\n",
    "    report.log(f\"    Single-session users: {(user_session_counts == 1).sum():,}\")\n",
    "    report.log(f\"    Multi-session users: {(user_session_counts > 1).sum():,}\")\n",
    "    report.log(f\"    Max sessions per user: {user_session_counts.max()}\")\n",
    "    \n",
    "    # Engagement progression\n",
    "    if 'num_browsing_sessions' in df_shopping.columns and 'did_purchase' in df_shopping.columns:\n",
    "        report.log(f\"\\n  Engagement to Conversion:\")\n",
    "        # Group by engagement level\n",
    "        engagement_bins = pd.cut(\n",
    "            df_shopping['num_browsing_sessions'],\n",
    "            bins=[0, 1, 3, 5, 10, float('inf')],\n",
    "            labels=['1 browse', '2-3 browse', '4-5 browse', '6-10 browse', '10+ browse']\n",
    "        )\n",
    "        engagement_conv = df_shopping.groupby(engagement_bins, observed=True)['did_purchase'].agg(['mean', 'count'])\n",
    "        for idx, row in engagement_conv.iterrows():\n",
    "            report.log(f\"    {idx}: {row['mean']:.2%} conversion (n={row['count']:,})\")\n",
    "    \n",
    "    # Ad exposure and conversion\n",
    "    if all(col in df_shopping.columns for col in ['total_impressions', 'total_clicks', 'did_purchase']):\n",
    "        report.log(f\"\\n  Ad Exposure Impact:\")\n",
    "        \n",
    "        # No ads vs with ads\n",
    "        no_ads_sessions = df_shopping[df_shopping['total_impressions'] == 0]\n",
    "        with_ads_sessions = df_shopping[df_shopping['total_impressions'] > 0]\n",
    "        \n",
    "        if len(no_ads_sessions) > 0:\n",
    "            no_ads_conv = no_ads_sessions['did_purchase'].mean()\n",
    "            report.log(f\"    Sessions without ads: {len(no_ads_sessions):,} ({no_ads_conv:.2%} conversion)\")\n",
    "        \n",
    "        if len(with_ads_sessions) > 0:\n",
    "            with_ads_conv = with_ads_sessions['did_purchase'].mean()\n",
    "            report.log(f\"    Sessions with ads: {len(with_ads_sessions):,} ({with_ads_conv:.2%} conversion)\")\n",
    "            \n",
    "            # Incrementality estimate\n",
    "            if len(no_ads_sessions) > 0 and len(with_ads_sessions) > 0:\n",
    "                lift = (with_ads_conv - no_ads_conv) / no_ads_conv if no_ads_conv > 0 else 0\n",
    "                report.log(f\"    Estimated lift from ads: {lift:.1%}\")\n",
    "\n",
    "# Cross-session analysis\n",
    "if not df_shopping.empty and not df_browsing.empty:\n",
    "    report.log(\"\\nCross-Session Insights:\")\n",
    "    \n",
    "    # Browsing to shopping funnel\n",
    "    total_browsing_users = df_browsing['user_id'].nunique()\n",
    "    total_shopping_users = df_shopping['user_id'].nunique()\n",
    "    report.log(f\"  Browsing to shopping funnel:\")\n",
    "    report.log(f\"    Users who browsed: {total_browsing_users:,}\")\n",
    "    report.log(f\"    Users who shopped: {total_shopping_users:,}\")\n",
    "    report.log(f\"    Browse-to-shop rate: {total_shopping_users/total_browsing_users:.2%}\" if total_browsing_users > 0 else \"    Browse-to-shop rate: N/A\")\n",
    "    \n",
    "    # Time patterns\n",
    "    if 'session_start' in df_shopping.columns:\n",
    "        df_shopping['session_start'] = pd.to_datetime(df_shopping['session_start'])\n",
    "        df_shopping['hour'] = df_shopping['session_start'].dt.hour\n",
    "        df_shopping['weekday'] = df_shopping['session_start'].dt.dayofweek\n",
    "        \n",
    "        report.log(f\"\\n  Temporal Patterns (Shopping Sessions):\")\n",
    "        \n",
    "        # Peak hours\n",
    "        peak_hours = df_shopping['hour'].value_counts().head(3)\n",
    "        report.log(f\"    Top 3 active hours:\")\n",
    "        for hour, count in peak_hours.items():\n",
    "            report.log(f\"      {hour}:00-{hour+1}:00: {count:,} sessions\")\n",
    "        \n",
    "        # Weekday vs weekend\n",
    "        df_shopping['is_weekend'] = df_shopping['weekday'].isin([5, 6])\n",
    "        weekend_sessions = df_shopping['is_weekend'].sum()\n",
    "        weekday_sessions = len(df_shopping) - weekend_sessions\n",
    "        report.log(f\"    Weekday sessions: {weekday_sessions:,} ({weekday_sessions/len(df_shopping):.1%})\")\n",
    "        report.log(f\"    Weekend sessions: {weekend_sessions:,} ({weekend_sessions/len(df_shopping):.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SECTION 12: PURCHASE FUNNEL CONSISTENCY & ATTRIBUTION\n",
      "================================================================================\n",
      "\n",
      "12.1 PURCHASE CONSIDERATION SET ANALYSIS\n",
      "----------------------------------------\n",
      "\n",
      "Total unique purchased products: 281\n",
      "Products in ad funnel:\n",
      "  - Products with bids: 366,426\n",
      "  - Products with impressions: 55,937\n",
      "  - Products with clicks: 1,860\n",
      "\n",
      "Purchased products overlap with ad funnel:\n",
      "  - Bid on: 23 (8.2%)\n",
      "  - Impressed: 15 (5.3%)\n",
      "  - Clicked: 15 (5.3%)\n",
      "  - In ANY funnel stage: 23 (8.2%)\n",
      "  - **ORGANIC (not in funnel): 258 (91.8%)**\n",
      "\n",
      "12.2 CLICK-IMPRESSION CONSISTENCY CHECK\n",
      "----------------------------------------\n",
      "\n",
      "Clicked products consistency:\n",
      "  Total clicked products: 1,860\n",
      "  Also impressed: 1,850 (99.5%)\n",
      "  NOT impressed: 10 (0.5%)\n",
      "\n",
      "  ⚠️  WARNING: 10 products were clicked but never impressed\n",
      "  This indicates potential data quality issues or missing impression records\n",
      "\n",
      "Event-level consistency:\n",
      "  Sample of 1,000 clicks:\n",
      "    - With matching impression: 972 (97.2%)\n",
      "    - Without matching impression: 28 (2.8%)\n",
      "\n",
      "  ⚠️  Estimated 58 clicks without impressions in full dataset\n",
      "\n",
      "12.3 PURCHASE ATTRIBUTION ANALYSIS\n",
      "----------------------------------------\n",
      "\n",
      "Purchase Attribution (7-day window):\n",
      "  Total purchases analyzed: 342\n",
      "  - Organic (no ad exposure): 327 (95.6%)\n",
      "  - View-through conversions: 0 (0.0%)\n",
      "  - Click-through conversions: 15 (4.4%)\n",
      "\n",
      "User-Level Purchase Patterns:\n",
      "  Total purchasing users: 137\n",
      "  Users with at least one ad-driven purchase: ~15\n",
      "  Users with only organic purchases: ~122\n",
      "\n",
      "12.4 IMPLICATIONS FOR CONSIDERATION SET MODELING\n",
      "----------------------------------------\n",
      "\n",
      "Key Findings:\n",
      "  1. 91.8% of purchased products are completely organic\n",
      "  2. Only 8.2% of purchases come from the ad funnel\n",
      "  3. Click-impression consistency is 97.2% (data quality concern)\n",
      "\n",
      "Recommendations for Extended Consideration Model:\n",
      "  • Incorporate browsing history beyond ad exposures\n",
      "  • Capture organic discovery patterns and search behavior\n",
      "  • Include category preferences and product similarity\n",
      "  • Account for the dominant role of organic purchases\n",
      "  • Address data quality issues in impression tracking\n",
      "\n",
      "12.5 DATA QUALITY ISSUES IDENTIFIED\n",
      "----------------------------------------\n",
      "\n",
      "Identified Issues:\n",
      "  • 10 products clicked but never impressed\n",
      "  • ~2.8% of clicks lack matching impressions\n",
      "  • 95.6% organic purchases suggest potential tracking gaps\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# --- PURCHASE FUNNEL CONSISTENCY & ATTRIBUTION ---\n",
    "report.log(\"\\n\" + \"=\"*80)\n",
    "report.log(\"SECTION 12: PURCHASE FUNNEL CONSISTENCY & ATTRIBUTION\")\n",
    "report.log(\"=\"*80)\n",
    "\n",
    "# Question 1: Are purchased products in the consideration set?\n",
    "report.log(\"\\n12.1 PURCHASE CONSIDERATION SET ANALYSIS\")\n",
    "report.log(\"-\" * 40)\n",
    "\n",
    "# Get all purchased products\n",
    "purchased_products = set(df_purchases['PRODUCT_ID'].unique())\n",
    "report.log(f\"\\nTotal unique purchased products: {len(purchased_products):,}\")\n",
    "\n",
    "# Get all products in the ad funnel\n",
    "bid_products = set(df_bids['PRODUCT_ID'].unique()) if not df_bids.empty else set()\n",
    "impression_products = set(df_impressions['PRODUCT_ID'].unique()) if not df_impressions.empty else set()\n",
    "click_products = set(df_clicks['PRODUCT_ID'].unique()) if not df_clicks.empty else set()\n",
    "\n",
    "report.log(f\"Products in ad funnel:\")\n",
    "report.log(f\"  - Products with bids: {len(bid_products):,}\")\n",
    "report.log(f\"  - Products with impressions: {len(impression_products):,}\")\n",
    "report.log(f\"  - Products with clicks: {len(click_products):,}\")\n",
    "\n",
    "# Check overlaps\n",
    "in_bids = purchased_products & bid_products\n",
    "in_impressions = purchased_products & impression_products\n",
    "in_clicks = purchased_products & click_products\n",
    "in_any_funnel = purchased_products & (bid_products | impression_products | click_products)\n",
    "organic_purchases = purchased_products - in_any_funnel\n",
    "\n",
    "report.log(f\"\\nPurchased products overlap with ad funnel:\")\n",
    "report.log(f\"  - Bid on: {len(in_bids):,} ({len(in_bids)/len(purchased_products)*100:.1f}%)\")\n",
    "report.log(f\"  - Impressed: {len(in_impressions):,} ({len(in_impressions)/len(purchased_products)*100:.1f}%)\")\n",
    "report.log(f\"  - Clicked: {len(in_clicks):,} ({len(in_clicks)/len(purchased_products)*100:.1f}%)\")\n",
    "report.log(f\"  - In ANY funnel stage: {len(in_any_funnel):,} ({len(in_any_funnel)/len(purchased_products)*100:.1f}%)\")\n",
    "report.log(f\"  - **ORGANIC (not in funnel): {len(organic_purchases):,} ({len(organic_purchases)/len(purchased_products)*100:.1f}%)**\")\n",
    "\n",
    "# Question 2: Are clicked products always impressed?\n",
    "report.log(\"\\n12.2 CLICK-IMPRESSION CONSISTENCY CHECK\")\n",
    "report.log(\"-\" * 40)\n",
    "\n",
    "if not df_clicks.empty and not df_impressions.empty:\n",
    "    # Product-level consistency\n",
    "    clicked_products = set(df_clicks['PRODUCT_ID'].unique())\n",
    "    impressed_products = set(df_impressions['PRODUCT_ID'].unique())\n",
    "    \n",
    "    clicked_and_impressed = clicked_products & impressed_products\n",
    "    clicked_not_impressed = clicked_products - impressed_products\n",
    "    \n",
    "    report.log(f\"\\nClicked products consistency:\")\n",
    "    report.log(f\"  Total clicked products: {len(clicked_products):,}\")\n",
    "    report.log(f\"  Also impressed: {len(clicked_and_impressed):,} ({len(clicked_and_impressed)/len(clicked_products)*100:.1f}%)\")\n",
    "    report.log(f\"  NOT impressed: {len(clicked_not_impressed):,} ({len(clicked_not_impressed)/len(clicked_products)*100:.1f}%)\")\n",
    "    \n",
    "    if len(clicked_not_impressed) > 0:\n",
    "        report.log(f\"\\n  ⚠️  WARNING: {len(clicked_not_impressed)} products were clicked but never impressed\")\n",
    "        report.log(\"  This indicates potential data quality issues or missing impression records\")\n",
    "    \n",
    "    # Event-level consistency check\n",
    "    report.log(f\"\\nEvent-level consistency:\")\n",
    "    clicks_matched = 0\n",
    "    clicks_unmatched = 0\n",
    "    \n",
    "    # Sample check for efficiency (checking all would be slow)\n",
    "    sample_size = min(1000, len(df_clicks))\n",
    "    click_sample = df_clicks.sample(n=sample_size, random_state=42)\n",
    "    \n",
    "    for _, click in click_sample.iterrows():\n",
    "        matching_impression = df_impressions[\n",
    "            (df_impressions['AUCTION_ID'] == click['AUCTION_ID']) &\n",
    "            (df_impressions['USER_ID'] == click['USER_ID']) &\n",
    "            (df_impressions['PRODUCT_ID'] == click['PRODUCT_ID'])\n",
    "        ]\n",
    "        if len(matching_impression) > 0:\n",
    "            clicks_matched += 1\n",
    "        else:\n",
    "            clicks_unmatched += 1\n",
    "    \n",
    "    match_rate = clicks_matched / sample_size * 100\n",
    "    report.log(f\"  Sample of {sample_size:,} clicks:\")\n",
    "    report.log(f\"    - With matching impression: {clicks_matched:,} ({match_rate:.1f}%)\")\n",
    "    report.log(f\"    - Without matching impression: {clicks_unmatched:,} ({100-match_rate:.1f}%)\")\n",
    "    \n",
    "    if match_rate < 100:\n",
    "        estimated_total_unmatched = int(len(df_clicks) * (100-match_rate) / 100)\n",
    "        report.log(f\"\\n  ⚠️  Estimated {estimated_total_unmatched:,} clicks without impressions in full dataset\")\n",
    "\n",
    "# Purchase Attribution Analysis\n",
    "report.log(\"\\n12.3 PURCHASE ATTRIBUTION ANALYSIS\")\n",
    "report.log(\"-\" * 40)\n",
    "\n",
    "if not df_purchases.empty:\n",
    "    # Convert timestamps\n",
    "    df_purchases_temp = df_purchases.copy()\n",
    "    df_purchases_temp['PURCHASED_AT'] = pd.to_datetime(df_purchases_temp['PURCHASED_AT'])\n",
    "    \n",
    "    if not df_impressions.empty:\n",
    "        df_impressions_temp = df_impressions.copy()\n",
    "        df_impressions_temp['OCCURRED_AT'] = pd.to_datetime(df_impressions_temp['OCCURRED_AT'])\n",
    "    \n",
    "    if not df_clicks.empty:\n",
    "        df_clicks_temp = df_clicks.copy()\n",
    "        df_clicks_temp['OCCURRED_AT'] = pd.to_datetime(df_clicks_temp['OCCURRED_AT'])\n",
    "    \n",
    "    # Analyze each purchase\n",
    "    purchase_attribution = []\n",
    "    for _, purchase in df_purchases_temp.iterrows():\n",
    "        user_id = purchase['USER_ID']\n",
    "        product_id = purchase['PRODUCT_ID']\n",
    "        purchase_time = purchase['PURCHASED_AT']\n",
    "        \n",
    "        # Look for prior exposure (7-day window)\n",
    "        time_window_start = purchase_time - pd.Timedelta(days=7)\n",
    "        \n",
    "        had_impression = False\n",
    "        had_click = False\n",
    "        \n",
    "        if not df_impressions.empty:\n",
    "            user_impressions = df_impressions_temp[\n",
    "                (df_impressions_temp['USER_ID'] == user_id) & \n",
    "                (df_impressions_temp['PRODUCT_ID'] == product_id) &\n",
    "                (df_impressions_temp['OCCURRED_AT'] >= time_window_start) &\n",
    "                (df_impressions_temp['OCCURRED_AT'] <= purchase_time)\n",
    "            ]\n",
    "            had_impression = len(user_impressions) > 0\n",
    "        \n",
    "        if not df_clicks.empty:\n",
    "            user_clicks = df_clicks_temp[\n",
    "                (df_clicks_temp['USER_ID'] == user_id) & \n",
    "                (df_clicks_temp['PRODUCT_ID'] == product_id) &\n",
    "                (df_clicks_temp['OCCURRED_AT'] >= time_window_start) &\n",
    "                (df_clicks_temp['OCCURRED_AT'] <= purchase_time)\n",
    "            ]\n",
    "            had_click = len(user_clicks) > 0\n",
    "        \n",
    "        purchase_attribution.append({\n",
    "            'had_impression': had_impression,\n",
    "            'had_click': had_click\n",
    "        })\n",
    "    \n",
    "    df_attribution = pd.DataFrame(purchase_attribution)\n",
    "    \n",
    "    # Calculate attribution categories\n",
    "    organic = (~df_attribution['had_impression']) & (~df_attribution['had_click'])\n",
    "    view_through = df_attribution['had_impression'] & (~df_attribution['had_click'])\n",
    "    click_through = df_attribution['had_click']\n",
    "    \n",
    "    report.log(f\"\\nPurchase Attribution (7-day window):\")\n",
    "    report.log(f\"  Total purchases analyzed: {len(df_attribution):,}\")\n",
    "    report.log(f\"  - Organic (no ad exposure): {organic.sum():,} ({organic.mean()*100:.1f}%)\")\n",
    "    report.log(f\"  - View-through conversions: {view_through.sum():,} ({view_through.mean()*100:.1f}%)\")\n",
    "    report.log(f\"  - Click-through conversions: {click_through.sum():,} ({click_through.mean()*100:.1f}%)\")\n",
    "    \n",
    "    # User-level analysis\n",
    "    report.log(f\"\\nUser-Level Purchase Patterns:\")\n",
    "    purchasing_users = df_purchases['USER_ID'].unique()\n",
    "    users_with_ad_purchases = df_attribution[df_attribution['had_impression'] | df_attribution['had_click']].index.nunique() if len(df_attribution) > 0 else 0\n",
    "    \n",
    "    report.log(f\"  Total purchasing users: {len(purchasing_users):,}\")\n",
    "    report.log(f\"  Users with at least one ad-driven purchase: ~{min(users_with_ad_purchases, len(purchasing_users)):,}\")\n",
    "    report.log(f\"  Users with only organic purchases: ~{len(purchasing_users) - min(users_with_ad_purchases, len(purchasing_users)):,}\")\n",
    "\n",
    "# Extended Consideration Set Recommendations\n",
    "report.log(\"\\n12.4 IMPLICATIONS FOR CONSIDERATION SET MODELING\")\n",
    "report.log(\"-\" * 40)\n",
    "\n",
    "report.log(\"\\nKey Findings:\")\n",
    "report.log(f\"  1. {len(organic_purchases)/len(purchased_products)*100:.1f}% of purchased products are completely organic\")\n",
    "report.log(f\"  2. Only {len(in_any_funnel)/len(purchased_products)*100:.1f}% of purchases come from the ad funnel\")\n",
    "report.log(f\"  3. Click-impression consistency is {match_rate:.1f}% (data quality concern)\" if 'match_rate' in locals() else \"  3. Click-impression consistency needs verification\")\n",
    "\n",
    "report.log(\"\\nRecommendations for Extended Consideration Model:\")\n",
    "report.log(\"  • Incorporate browsing history beyond ad exposures\")\n",
    "report.log(\"  • Capture organic discovery patterns and search behavior\")\n",
    "report.log(\"  • Include category preferences and product similarity\")\n",
    "report.log(\"  • Account for the dominant role of organic purchases\")\n",
    "report.log(\"  • Address data quality issues in impression tracking\")\n",
    "\n",
    "# Data Quality Summary\n",
    "report.log(\"\\n12.5 DATA QUALITY ISSUES IDENTIFIED\")\n",
    "report.log(\"-\" * 40)\n",
    "\n",
    "issues = []\n",
    "if len(clicked_not_impressed) > 0:\n",
    "    issues.append(f\"  • {len(clicked_not_impressed)} products clicked but never impressed\")\n",
    "if 'clicks_unmatched' in locals() and clicks_unmatched > 0:\n",
    "    issues.append(f\"  • ~{100-match_rate:.1f}% of clicks lack matching impressions\")\n",
    "if organic.mean() > 0.9:\n",
    "    issues.append(f\"  • {organic.mean()*100:.1f}% organic purchases suggest potential tracking gaps\")\n",
    "\n",
    "if issues:\n",
    "    report.log(\"\\nIdentified Issues:\")\n",
    "    for issue in issues:\n",
    "        report.log(issue)\n",
    "else:\n",
    "    report.log(\"\\n  No major data quality issues identified\")\n",
    "\n",
    "report.log(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SECTION 13: FIXED EFFECTS & PANEL STRUCTURE ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "13.1 PANEL DIMENSIONS OVERVIEW\n",
      "----------------------------------------\n",
      "\n",
      "Unique Entities in Dataset:\n",
      "  Users: 773\n",
      "  Products: 366,684\n",
      "  Vendors: 40,252\n",
      "  Campaigns: 66,668\n",
      "\n",
      "Time Periods:\n",
      "  Weeks: 2\n",
      "  Days: 10\n",
      "  Date range: 2025-08-28 to 2025-09-06\n",
      "\n",
      "13.2 USER FIXED EFFECTS POTENTIAL\n",
      "----------------------------------------\n",
      "\n",
      "User Repeat Activity:\n",
      "  Single-day users: 389 (50.3%)\n",
      "  Multi-day users: 384 (49.7%)\n",
      "  Multi-week users: 288 (37.3%)\n",
      "\n",
      "User Activity Distribution:\n",
      "  25th percentile: 2 auctions\n",
      "  Median: 6 auctions\n",
      "  75th percentile: 18 auctions\n",
      "  95th percentile: 118 auctions\n",
      "  99th percentile: 268 auctions\n",
      "\n",
      "Purchase Patterns:\n",
      "  Users with purchases: 137\n",
      "  Repeat purchasers: 57 (41.6%)\n",
      "  Max purchases per user: 65\n",
      "\n",
      "13.3 PRODUCT FIXED EFFECTS POTENTIAL\n",
      "----------------------------------------\n",
      "\n",
      "Product Repeat Exposure:\n",
      "  Products impressed: 55,937\n",
      "  Products shown multiple weeks: 2,007 (3.6%)\n",
      "  Products shown to multiple users: 2,185 (3.9%)\n",
      "\n",
      "Top 5 Most Impressed Products:\n",
      "  1. 68b862b5bedd34735ad1...: 43 impressions, 1 users\n",
      "  2. 686adfb14a072bc96394...: 36 impressions, 1 users\n",
      "  3. 68814ae29f034c1d5434...: 34 impressions, 1 users\n",
      "  4. 6779e535b1ef5831124d...: 31 impressions, 1 users\n",
      "  5. 67a90af2198524a81b90...: 30 impressions, 1 users\n",
      "\n",
      "13.4 VENDOR FIXED EFFECTS POTENTIAL\n",
      "----------------------------------------\n",
      "\n",
      "Vendor Activity Over Time:\n",
      "  Active vendors: 40,252\n",
      "  Vendors active multiple weeks: 26,908 (66.8%)\n",
      "\n",
      "Vendor Concentration:\n",
      "  Top 10 vendors: 7,760 bids (1.1% of total)\n",
      "  Top 100 vendors: 39,293 bids (5.5% of total)\n",
      "\n",
      "Vendor Performance Distribution:\n",
      "  25th percentile win rate: 65.12%\n",
      "  Median win rate: 77.78%\n",
      "  75th percentile win rate: 91.30%\n",
      "  90th percentile win rate: 100.00%\n",
      "\n",
      "13.5 TIME FIXED EFFECTS POTENTIAL\n",
      "----------------------------------------\n",
      "\n",
      "Weekly Activity Variation:\n",
      "  Mean auctions per week: 9586\n",
      "  Std dev: 3188\n",
      "  Coefficient of variation: 0.33\n",
      "\n",
      "Day of Week Patterns:\n",
      "  Monday: 2,364 auctions (12.3%)\n",
      "  Tuesday: 2,001 auctions (10.4%)\n",
      "  Wednesday: 1,747 auctions (9.1%)\n",
      "  Thursday: 3,623 auctions (18.9%)\n",
      "  Friday: 3,596 auctions (18.8%)\n",
      "  Saturday: 3,991 auctions (20.8%)\n",
      "  Sunday: 1,851 auctions (9.7%)\n",
      "\n",
      "Peak Activity Hours:\n",
      "  3:00-4:00: 1,260 auctions (6.6%)\n",
      "  1:00-2:00: 1,179 auctions (6.1%)\n",
      "  2:00-3:00: 1,149 auctions (6.0%)\n",
      "\n",
      "13.6 PANEL BALANCE ASSESSMENT\n",
      "----------------------------------------\n",
      "\n",
      "User-Week Panel:\n",
      "  Potential observations: 1,546\n",
      "  Actual observations: 1,061\n",
      "  Panel completeness: 68.6%\n",
      "  Fully balanced users (all weeks): 288 (37.3%)\n",
      "\n",
      "13.7 FIXED EFFECTS MODEL RECOMMENDATIONS\n",
      "----------------------------------------\n",
      "\n",
      "Viability Assessment:\n",
      "  User Fixed Effects: ✓ RECOMMENDED\n",
      "    - 49.7% of users appear multiple days\n",
      "    - 37.3% of users appear multiple weeks\n",
      "  Product Fixed Effects: ✗ LIMITED\n",
      "    - 3.6% of products appear multiple weeks\n",
      "  Vendor Fixed Effects: ✓ RECOMMENDED\n",
      "    - 66.8% of vendors active multiple weeks\n",
      "  Time Fixed Effects: ✓ RECOMMENDED\n",
      "    - 2 weeks available\n",
      "    - Clear day-of-week patterns observed\n",
      "\n",
      "Suggested Model Specifications:\n",
      "  1. User FE + Time FE (for user-level outcomes)\n",
      "  2. Product FE + Time FE (for product performance)\n",
      "  3. Vendor FE + Time FE (for vendor competition analysis)\n",
      "  4. Two-way FE: User × Product (if sufficient overlap)\n",
      "\n",
      "  User-Product pairs with repeats: 11,836 (20.3%)\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# --- FIXED EFFECTS & PANEL STRUCTURE ANALYSIS ---\n",
    "report.log(\"\\n\" + \"=\"*80)\n",
    "report.log(\"SECTION 13: FIXED EFFECTS & PANEL STRUCTURE ANALYSIS\")\n",
    "report.log(\"=\"*80)\n",
    "\n",
    "report.log(\"\\n13.1 PANEL DIMENSIONS OVERVIEW\")\n",
    "report.log(\"-\" * 40)\n",
    "\n",
    "# Add time columns if not present\n",
    "if not df_auctions.empty and 'CREATED_AT' in df_auctions.columns:\n",
    "    df_auctions['CREATED_AT'] = pd.to_datetime(df_auctions['CREATED_AT'])\n",
    "    df_auctions['date'] = df_auctions['CREATED_AT'].dt.date\n",
    "    df_auctions['week'] = df_auctions['CREATED_AT'].dt.to_period('W')\n",
    "    df_auctions['day'] = df_auctions['CREATED_AT'].dt.to_period('D')\n",
    "    df_auctions['hour'] = df_auctions['CREATED_AT'].dt.hour\n",
    "\n",
    "if not df_impressions.empty and 'OCCURRED_AT' in df_impressions.columns:\n",
    "    df_impressions['OCCURRED_AT'] = pd.to_datetime(df_impressions['OCCURRED_AT'])\n",
    "    df_impressions['date'] = df_impressions['OCCURRED_AT'].dt.date\n",
    "    df_impressions['week'] = df_impressions['OCCURRED_AT'].dt.to_period('W')\n",
    "\n",
    "if not df_clicks.empty and 'OCCURRED_AT' in df_clicks.columns:\n",
    "    df_clicks['OCCURRED_AT'] = pd.to_datetime(df_clicks['OCCURRED_AT'])\n",
    "    df_clicks['date'] = df_clicks['OCCURRED_AT'].dt.date\n",
    "    df_clicks['week'] = df_clicks['OCCURRED_AT'].dt.to_period('W')\n",
    "\n",
    "if not df_purchases.empty and 'PURCHASED_AT' in df_purchases.columns:\n",
    "    df_purchases['PURCHASED_AT'] = pd.to_datetime(df_purchases['PURCHASED_AT'])\n",
    "    df_purchases['date'] = df_purchases['PURCHASED_AT'].dt.date\n",
    "    df_purchases['week'] = df_purchases['PURCHASED_AT'].dt.to_period('W')\n",
    "\n",
    "# Basic panel dimensions\n",
    "report.log(\"\\nUnique Entities in Dataset:\")\n",
    "n_users = df_auctions['OPAQUE_USER_ID'].nunique() if 'OPAQUE_USER_ID' in df_auctions.columns else 0\n",
    "n_products = len(set(df_bids['PRODUCT_ID'].unique()) | set(df_purchases['PRODUCT_ID'].unique())) if not df_bids.empty else 0\n",
    "n_vendors = df_bids['VENDOR_ID'].nunique() if 'VENDOR_ID' in df_bids.columns else 0\n",
    "n_campaigns = df_bids['CAMPAIGN_ID'].nunique() if 'CAMPAIGN_ID' in df_bids.columns else 0\n",
    "\n",
    "report.log(f\"  Users: {n_users:,}\")\n",
    "report.log(f\"  Products: {n_products:,}\")\n",
    "report.log(f\"  Vendors: {n_vendors:,}\")\n",
    "report.log(f\"  Campaigns: {n_campaigns:,}\")\n",
    "\n",
    "# Time dimensions\n",
    "if 'week' in df_auctions.columns:\n",
    "    n_weeks = df_auctions['week'].nunique()\n",
    "    n_days = df_auctions['day'].nunique()\n",
    "    report.log(f\"\\nTime Periods:\")\n",
    "    report.log(f\"  Weeks: {n_weeks}\")\n",
    "    report.log(f\"  Days: {n_days}\")\n",
    "    report.log(f\"  Date range: {df_auctions['CREATED_AT'].min().date()} to {df_auctions['CREATED_AT'].max().date()}\")\n",
    "\n",
    "# USER FIXED EFFECTS ANALYSIS\n",
    "report.log(\"\\n13.2 USER FIXED EFFECTS POTENTIAL\")\n",
    "report.log(\"-\" * 40)\n",
    "\n",
    "# User activity across time\n",
    "if not df_auctions.empty:\n",
    "    user_activity = df_auctions.groupby('OPAQUE_USER_ID').agg({\n",
    "        'AUCTION_ID': 'count',\n",
    "        'week': 'nunique' if 'week' in df_auctions.columns else lambda x: 0,\n",
    "        'day': 'nunique' if 'day' in df_auctions.columns else lambda x: 0\n",
    "    }).rename(columns={'AUCTION_ID': 'auctions', 'week': 'weeks_active', 'day': 'days_active'})\n",
    "    \n",
    "    # Categorize users by activity level\n",
    "    single_day_users = (user_activity['days_active'] == 1).sum()\n",
    "    multi_day_users = (user_activity['days_active'] > 1).sum()\n",
    "    multi_week_users = (user_activity['weeks_active'] > 1).sum() if 'week' in df_auctions.columns else 0\n",
    "    \n",
    "    report.log(\"\\nUser Repeat Activity:\")\n",
    "    report.log(f\"  Single-day users: {single_day_users:,} ({single_day_users/n_users*100:.1f}%)\")\n",
    "    report.log(f\"  Multi-day users: {multi_day_users:,} ({multi_day_users/n_users*100:.1f}%)\")\n",
    "    report.log(f\"  Multi-week users: {multi_week_users:,} ({multi_week_users/n_users*100:.1f}%)\")\n",
    "    \n",
    "    # User activity distribution\n",
    "    report.log(\"\\nUser Activity Distribution:\")\n",
    "    activity_percentiles = user_activity['auctions'].quantile([0.25, 0.50, 0.75, 0.90, 0.95, 0.99])\n",
    "    report.log(f\"  25th percentile: {activity_percentiles[0.25]:.0f} auctions\")\n",
    "    report.log(f\"  Median: {activity_percentiles[0.50]:.0f} auctions\")\n",
    "    report.log(f\"  75th percentile: {activity_percentiles[0.75]:.0f} auctions\")\n",
    "    report.log(f\"  95th percentile: {activity_percentiles[0.95]:.0f} auctions\")\n",
    "    report.log(f\"  99th percentile: {activity_percentiles[0.99]:.0f} auctions\")\n",
    "    \n",
    "    # Users with purchases\n",
    "    if not df_purchases.empty:\n",
    "        purchasing_users = df_purchases['USER_ID'].value_counts()\n",
    "        repeat_purchasers = (purchasing_users > 1).sum()\n",
    "        report.log(f\"\\nPurchase Patterns:\")\n",
    "        report.log(f\"  Users with purchases: {len(purchasing_users):,}\")\n",
    "        report.log(f\"  Repeat purchasers: {repeat_purchasers:,} ({repeat_purchasers/len(purchasing_users)*100:.1f}%)\")\n",
    "        report.log(f\"  Max purchases per user: {purchasing_users.max()}\")\n",
    "\n",
    "# PRODUCT FIXED EFFECTS ANALYSIS\n",
    "report.log(\"\\n13.3 PRODUCT FIXED EFFECTS POTENTIAL\")\n",
    "report.log(\"-\" * 40)\n",
    "\n",
    "if not df_impressions.empty:\n",
    "    product_impressions = df_impressions.groupby('PRODUCT_ID').agg({\n",
    "        'INTERACTION_ID': 'count',\n",
    "        'week': 'nunique' if 'week' in df_impressions.columns else lambda x: 0,\n",
    "        'USER_ID': 'nunique'\n",
    "    }).rename(columns={'INTERACTION_ID': 'impressions', 'week': 'weeks_active', 'USER_ID': 'unique_users'})\n",
    "    \n",
    "    # Products with repeated exposure\n",
    "    products_multi_week = (product_impressions['weeks_active'] > 1).sum() if 'week' in df_impressions.columns else 0\n",
    "    products_multi_user = (product_impressions['unique_users'] > 1).sum()\n",
    "    \n",
    "    report.log(\"\\nProduct Repeat Exposure:\")\n",
    "    report.log(f\"  Products impressed: {len(product_impressions):,}\")\n",
    "    report.log(f\"  Products shown multiple weeks: {products_multi_week:,} ({products_multi_week/len(product_impressions)*100:.1f}%)\")\n",
    "    report.log(f\"  Products shown to multiple users: {products_multi_user:,} ({products_multi_user/len(product_impressions)*100:.1f}%)\")\n",
    "    \n",
    "    # Top products\n",
    "    report.log(\"\\nTop 5 Most Impressed Products:\")\n",
    "    for idx, (product, row) in enumerate(product_impressions.nlargest(5, 'impressions').iterrows(), 1):\n",
    "        report.log(f\"  {idx}. {str(product)[:20]}...: {row['impressions']:,} impressions, {row['unique_users']:,} users\")\n",
    "\n",
    "# VENDOR FIXED EFFECTS ANALYSIS\n",
    "report.log(\"\\n13.4 VENDOR FIXED EFFECTS POTENTIAL\")\n",
    "report.log(\"-\" * 40)\n",
    "\n",
    "if not df_bids.empty:\n",
    "    # Vendor activity\n",
    "    vendor_activity = df_bids.groupby('VENDOR_ID').agg({\n",
    "        'AUCTION_ID': 'nunique',\n",
    "        'PRODUCT_ID': 'nunique',\n",
    "        'CAMPAIGN_ID': 'nunique',\n",
    "        'IS_WINNER': ['sum', 'mean']\n",
    "    })\n",
    "    vendor_activity.columns = ['auctions', 'products', 'campaigns', 'wins', 'win_rate']\n",
    "    \n",
    "    # Vendor persistence\n",
    "    if 'week' in df_auctions.columns:\n",
    "        vendor_weeks = df_bids.merge(df_auctions[['AUCTION_ID', 'week']], on='AUCTION_ID')\n",
    "        vendor_time_activity = vendor_weeks.groupby('VENDOR_ID')['week'].nunique()\n",
    "        vendors_multi_week = (vendor_time_activity > 1).sum()\n",
    "        \n",
    "        report.log(f\"\\nVendor Activity Over Time:\")\n",
    "        report.log(f\"  Active vendors: {n_vendors:,}\")\n",
    "        report.log(f\"  Vendors active multiple weeks: {vendors_multi_week:,} ({vendors_multi_week/n_vendors*100:.1f}%)\")\n",
    "    \n",
    "    # Vendor concentration\n",
    "    report.log(\"\\nVendor Concentration:\")\n",
    "    vendor_bid_counts = df_bids['VENDOR_ID'].value_counts()\n",
    "    top_10_vendors = vendor_bid_counts.head(10).sum()\n",
    "    top_100_vendors = vendor_bid_counts.head(100).sum()\n",
    "    report.log(f\"  Top 10 vendors: {top_10_vendors:,} bids ({top_10_vendors/len(df_bids)*100:.1f}% of total)\")\n",
    "    report.log(f\"  Top 100 vendors: {top_100_vendors:,} bids ({top_100_vendors/len(df_bids)*100:.1f}% of total)\")\n",
    "    \n",
    "    # Vendor performance distribution\n",
    "    report.log(\"\\nVendor Performance Distribution:\")\n",
    "    win_rate_percentiles = vendor_activity['win_rate'].quantile([0.25, 0.50, 0.75, 0.90])\n",
    "    report.log(f\"  25th percentile win rate: {win_rate_percentiles[0.25]:.2%}\")\n",
    "    report.log(f\"  Median win rate: {win_rate_percentiles[0.50]:.2%}\")\n",
    "    report.log(f\"  75th percentile win rate: {win_rate_percentiles[0.75]:.2%}\")\n",
    "    report.log(f\"  90th percentile win rate: {win_rate_percentiles[0.90]:.2%}\")\n",
    "\n",
    "# TIME FIXED EFFECTS ANALYSIS\n",
    "report.log(\"\\n13.5 TIME FIXED EFFECTS POTENTIAL\")\n",
    "report.log(\"-\" * 40)\n",
    "\n",
    "if 'week' in df_auctions.columns:\n",
    "    # Weekly patterns\n",
    "    weekly_activity = df_auctions.groupby('week').agg({\n",
    "        'AUCTION_ID': 'count',\n",
    "        'OPAQUE_USER_ID': 'nunique'\n",
    "    }).rename(columns={'AUCTION_ID': 'auctions', 'OPAQUE_USER_ID': 'unique_users'})\n",
    "    \n",
    "    report.log(\"\\nWeekly Activity Variation:\")\n",
    "    report.log(f\"  Mean auctions per week: {weekly_activity['auctions'].mean():.0f}\")\n",
    "    report.log(f\"  Std dev: {weekly_activity['auctions'].std():.0f}\")\n",
    "    report.log(f\"  Coefficient of variation: {weekly_activity['auctions'].std()/weekly_activity['auctions'].mean():.2f}\")\n",
    "    \n",
    "    # Day of week patterns\n",
    "    if not df_auctions.empty:\n",
    "        df_auctions['dayofweek'] = pd.to_datetime(df_auctions['CREATED_AT']).dt.dayofweek\n",
    "        day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "        \n",
    "        report.log(\"\\nDay of Week Patterns:\")\n",
    "        for day in range(7):\n",
    "            day_auctions = (df_auctions['dayofweek'] == day).sum()\n",
    "            report.log(f\"  {day_names[day]}: {day_auctions:,} auctions ({day_auctions/len(df_auctions)*100:.1f}%)\")\n",
    "    \n",
    "    # Hour of day patterns\n",
    "    if 'hour' in df_auctions.columns:\n",
    "        peak_hours = df_auctions['hour'].value_counts().head(3)\n",
    "        report.log(\"\\nPeak Activity Hours:\")\n",
    "        for hour, count in peak_hours.items():\n",
    "            report.log(f\"  {hour}:00-{hour+1}:00: {count:,} auctions ({count/len(df_auctions)*100:.1f}%)\")\n",
    "\n",
    "# PANEL BALANCE ASSESSMENT\n",
    "report.log(\"\\n13.6 PANEL BALANCE ASSESSMENT\")\n",
    "report.log(\"-\" * 40)\n",
    "\n",
    "# Create user-week panel\n",
    "if 'week' in df_auctions.columns:\n",
    "    user_weeks = df_auctions.groupby(['OPAQUE_USER_ID', 'week']).size().reset_index(name='activity')\n",
    "    all_weeks = df_auctions['week'].unique()\n",
    "    all_users = df_auctions['OPAQUE_USER_ID'].unique()\n",
    "    \n",
    "    # Calculate panel completeness\n",
    "    potential_observations = len(all_users) * len(all_weeks)\n",
    "    actual_observations = len(user_weeks)\n",
    "    panel_completeness = actual_observations / potential_observations * 100\n",
    "    \n",
    "    report.log(f\"\\nUser-Week Panel:\")\n",
    "    report.log(f\"  Potential observations: {potential_observations:,}\")\n",
    "    report.log(f\"  Actual observations: {actual_observations:,}\")\n",
    "    report.log(f\"  Panel completeness: {panel_completeness:.1f}%\")\n",
    "    \n",
    "    # Balance categories\n",
    "    user_week_counts = user_weeks.groupby('OPAQUE_USER_ID').size()\n",
    "    balanced_users = (user_week_counts == n_weeks).sum()\n",
    "    report.log(f\"  Fully balanced users (all weeks): {balanced_users:,} ({balanced_users/n_users*100:.1f}%)\")\n",
    "\n",
    "# FIXED EFFECTS RECOMMENDATIONS\n",
    "report.log(\"\\n13.7 FIXED EFFECTS MODEL RECOMMENDATIONS\")\n",
    "report.log(\"-\" * 40)\n",
    "\n",
    "report.log(\"\\nViability Assessment:\")\n",
    "\n",
    "# User FE\n",
    "user_fe_viable = multi_day_users > n_users * 0.3\n",
    "report.log(f\"  User Fixed Effects: {'✓ RECOMMENDED' if user_fe_viable else '✗ LIMITED'}\")\n",
    "report.log(f\"    - {multi_day_users/n_users*100:.1f}% of users appear multiple days\")\n",
    "report.log(f\"    - {multi_week_users/n_users*100:.1f}% of users appear multiple weeks\")\n",
    "\n",
    "# Product FE\n",
    "if 'products_multi_week' in locals():\n",
    "    product_fe_viable = products_multi_week > len(product_impressions) * 0.3\n",
    "    report.log(f\"  Product Fixed Effects: {'✓ RECOMMENDED' if product_fe_viable else '✗ LIMITED'}\")\n",
    "    report.log(f\"    - {products_multi_week/len(product_impressions)*100:.1f}% of products appear multiple weeks\")\n",
    "\n",
    "# Vendor FE\n",
    "if 'vendors_multi_week' in locals():\n",
    "    vendor_fe_viable = vendors_multi_week > n_vendors * 0.3\n",
    "    report.log(f\"  Vendor Fixed Effects: {'✓ RECOMMENDED' if vendor_fe_viable else '✗ LIMITED'}\")\n",
    "    report.log(f\"    - {vendors_multi_week/n_vendors*100:.1f}% of vendors active multiple weeks\")\n",
    "\n",
    "# Time FE\n",
    "report.log(f\"  Time Fixed Effects: ✓ RECOMMENDED\")\n",
    "report.log(f\"    - {n_weeks} weeks available\")\n",
    "report.log(f\"    - Clear day-of-week patterns observed\")\n",
    "\n",
    "report.log(\"\\nSuggested Model Specifications:\")\n",
    "report.log(\"  1. User FE + Time FE (for user-level outcomes)\")\n",
    "report.log(\"  2. Product FE + Time FE (for product performance)\")\n",
    "report.log(\"  3. Vendor FE + Time FE (for vendor competition analysis)\")\n",
    "report.log(\"  4. Two-way FE: User × Product (if sufficient overlap)\")\n",
    "\n",
    "# Calculate some two-way FE potential\n",
    "if not df_impressions.empty:\n",
    "    user_product_pairs = df_impressions.groupby(['USER_ID', 'PRODUCT_ID']).size()\n",
    "    repeat_pairs = (user_product_pairs > 1).sum()\n",
    "    report.log(f\"\\n  User-Product pairs with repeats: {repeat_pairs:,} ({repeat_pairs/len(user_product_pairs)*100:.1f}%)\")\n",
    "\n",
    "report.log(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
