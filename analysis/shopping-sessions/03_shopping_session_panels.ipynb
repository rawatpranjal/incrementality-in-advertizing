{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Panel Construction for Funnel Econometric Analysis\n",
    "\n",
    "This notebook creates three specialized panel datasets for econometric analysis:\n",
    "1. **Model 1**: Ad Effectiveness Panel (impression-level)\n",
    "2. **Model 2**: Journey Continuation Panel (browsing session-level)\n",
    "3. **Model 3**: Final Conversion Panel (shopping session-level)\n",
    "\n",
    "Each panel is optimized for memory efficiency and saved separately for use in `04_fixed_effects.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PANEL CONSTRUCTION FOR FUNNEL ECONOMETRIC ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Configuration:\n",
      "  Data directory: data\n",
      "  Panel directory: data/panels\n",
      "  Auction sample: 100%\n",
      "  User sample: 100%\n",
      "  Random seed: 42\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "import gc\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "DATA_DIR = Path('./data')\n",
    "PANEL_DIR = Path('./data/panels')\n",
    "PANEL_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Sampling parameters for memory efficiency\n",
    "AUCTION_SAMPLE_FRACTION = 1  # 10% of auctions for Model 1\n",
    "USER_SAMPLE_FRACTION = 1     # 5% of users for Models 2 & 3\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PANEL CONSTRUCTION FOR FUNNEL ECONOMETRIC ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  Data directory: {DATA_DIR}\")\n",
    "print(f\"  Panel directory: {PANEL_DIR}\")\n",
    "print(f\"  Auction sample: {AUCTION_SAMPLE_FRACTION:.0%}\")\n",
    "print(f\"  User sample: {USER_SAMPLE_FRACTION:.0%}\")\n",
    "print(f\"  Random seed: {RANDOM_SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Ad Effectiveness Panel (Impression-Level)\n",
    "\n",
    "Unit of analysis: Individual ad impression\n",
    "Key outcome: WasClicked (binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL 1: AD EFFECTIVENESS PANEL\n",
      "================================================================================\n",
      "\n",
      "Loading data...\n",
      "  Impressions: 1,118,310 rows\n",
      "  Bids: 11,254,106 rows\n",
      "  Clicks: 34,260 rows\n",
      "  Catalog: 3,981,005 rows\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL 1: AD EFFECTIVENESS PANEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load required data\n",
    "print(\"\\nLoading data...\")\n",
    "df_impressions = pl.read_parquet(DATA_DIR / 'raw_sample_impressions.parquet')\n",
    "df_bids = pl.read_parquet(DATA_DIR / 'raw_sample_auctions_results.parquet')\n",
    "df_clicks = pl.read_parquet(DATA_DIR / 'raw_sample_clicks.parquet')\n",
    "df_catalog = pl.read_parquet(DATA_DIR / 'processed_sample_catalog.parquet')\n",
    "\n",
    "print(f\"  Impressions: {len(df_impressions):,} rows\")\n",
    "print(f\"  Bids: {len(df_bids):,} rows\")\n",
    "print(f\"  Clicks: {len(df_clicks):,} rows\")\n",
    "print(f\"  Catalog: {len(df_catalog):,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Joining impressions with bid rankings...\n",
      "Adding click indicators...\n",
      "\n",
      "Basic statistics:\n",
      "  Total impressions: 1,121,199\n",
      "  Click rate: 2.66%\n",
      "  Average rank: 12.62\n"
     ]
    }
   ],
   "source": [
    "# Join impressions with bids to get ranking\n",
    "print(\"\\nJoining impressions with bid rankings...\")\n",
    "join_keys = ['AUCTION_ID', 'PRODUCT_ID', 'VENDOR_ID', 'CAMPAIGN_ID']\n",
    "\n",
    "model1_data = df_impressions.join(\n",
    "    df_bids.select(join_keys + ['RANKING', 'IS_WINNER']),\n",
    "    on=join_keys,\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Add click indicator\n",
    "print(\"Adding click indicators...\")\n",
    "clicks_dedup = df_clicks.select(join_keys).unique().with_columns(\n",
    "    pl.lit(1).alias('WasClicked')\n",
    ")\n",
    "\n",
    "model1_data = model1_data.join(\n",
    "    clicks_dedup,\n",
    "    on=join_keys,\n",
    "    how='left'\n",
    ").with_columns(\n",
    "    pl.col('WasClicked').fill_null(0).cast(pl.Int8)\n",
    ")\n",
    "\n",
    "print(f\"\\nBasic statistics:\")\n",
    "print(f\"  Total impressions: {len(model1_data):,}\")\n",
    "print(f\"  Click rate: {model1_data['WasClicked'].mean():.2%}\")\n",
    "print(f\"  Average rank: {model1_data['RANKING'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating auction-level controls...\n",
      "  Added NumWinningBids_a: mean=38.1\n",
      "  Added AvgPriceTop5_a: mean=$716388.69\n",
      "  Added BrandConcentration_a: mean=0.078\n"
     ]
    }
   ],
   "source": [
    "# Calculate auction-level aggregates\n",
    "print(\"\\nCalculating auction-level controls...\")\n",
    "\n",
    "# Get auction aggregates\n",
    "auction_aggs = df_bids.filter(pl.col('IS_WINNER') == True).group_by('AUCTION_ID').agg([\n",
    "    pl.count().alias('NumWinningBids_a'),\n",
    "    pl.col('RANKING').filter(pl.col('RANKING') <= 5).count().alias('NumTop5_a')\n",
    "])\n",
    "\n",
    "# Get product prices for top 5 items\n",
    "top5_bids = df_bids.filter((pl.col('IS_WINNER') == True) & (pl.col('RANKING') <= 5))\n",
    "top5_with_price = top5_bids.join(\n",
    "    df_catalog.select(['PRODUCT_ID', 'PRICE']),\n",
    "    on='PRODUCT_ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Calculate average price of top 5\n",
    "price_aggs = top5_with_price.group_by('AUCTION_ID').agg([\n",
    "    pl.col('PRICE').mean().alias('AvgPriceTop5_a'),\n",
    "    pl.col('PRICE').std().alias('StdPriceTop5_a')\n",
    "]).with_columns([\n",
    "    pl.col('AvgPriceTop5_a').fill_null(50.0),\n",
    "    pl.col('StdPriceTop5_a').fill_null(10.0)\n",
    "])\n",
    "\n",
    "# Calculate brand concentration (simplified HHI)\n",
    "brand_conc = df_bids.filter(pl.col('IS_WINNER') == True).group_by(['AUCTION_ID', 'VENDOR_ID']).agg(\n",
    "    pl.count().alias('vendor_count')\n",
    ").group_by('AUCTION_ID').agg(\n",
    "    (pl.col('vendor_count').pow(2).sum() / pl.col('vendor_count').sum().pow(2)).alias('BrandConcentration_a')\n",
    ")\n",
    "\n",
    "# Join all auction-level controls\n",
    "auction_controls = auction_aggs.join(price_aggs, on='AUCTION_ID', how='left')\n",
    "auction_controls = auction_controls.join(brand_conc, on='AUCTION_ID', how='left')\n",
    "\n",
    "# Add to main data\n",
    "model1_data = model1_data.join(auction_controls, on='AUCTION_ID', how='left')\n",
    "\n",
    "# Fill nulls with sensible defaults\n",
    "model1_data = model1_data.with_columns([\n",
    "    pl.col('NumWinningBids_a').fill_null(10),\n",
    "    pl.col('AvgPriceTop5_a').fill_null(50.0),\n",
    "    pl.col('BrandConcentration_a').fill_null(0.5)\n",
    "])\n",
    "\n",
    "print(f\"  Added NumWinningBids_a: mean={model1_data['NumWinningBids_a'].mean():.1f}\")\n",
    "print(f\"  Added AvgPriceTop5_a: mean=${model1_data['AvgPriceTop5_a'].mean():.2f}\")\n",
    "print(f\"  Added BrandConcentration_a: mean={model1_data['BrandConcentration_a'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 100% of auctions...\n",
      "\n",
      "Final Model 1 Panel:\n",
      "  Observations: 1,121,199\n",
      "  Unique auctions: 152,959\n",
      "  Unique vendors: 100,306\n",
      "  Click rate: 2.66%\n",
      "\n",
      "✓ Saved to data/panels/panel_model1_ad_effectiveness.parquet\n",
      "  File size: 79.00 MB\n",
      "\n",
      "✓ Memory cleared\n"
     ]
    }
   ],
   "source": [
    "# Sample auctions for memory efficiency\n",
    "print(f\"\\nSampling {AUCTION_SAMPLE_FRACTION:.0%} of auctions...\")\n",
    "unique_auctions = model1_data['AUCTION_ID'].unique()\n",
    "sampled_auctions = pl.DataFrame({'AUCTION_ID': unique_auctions}).sample(\n",
    "    fraction=AUCTION_SAMPLE_FRACTION,\n",
    "    with_replacement=False,\n",
    "    shuffle=True,\n",
    "    seed=RANDOM_SEED\n",
    ")\n",
    "\n",
    "model1_panel = model1_data.join(\n",
    "    sampled_auctions,\n",
    "    on='AUCTION_ID',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Add polynomial and interaction terms\n",
    "model1_panel = model1_panel.with_columns([\n",
    "    pl.col('RANKING').pow(2).alias('RankSquared'),\n",
    "    (pl.col('RANKING') * pl.col('AvgPriceTop5_a')).alias('Rank_x_AvgPrice')\n",
    "])\n",
    "\n",
    "print(f\"\\nFinal Model 1 Panel:\")\n",
    "print(f\"  Observations: {len(model1_panel):,}\")\n",
    "print(f\"  Unique auctions: {model1_panel['AUCTION_ID'].n_unique():,}\")\n",
    "print(f\"  Unique vendors: {model1_panel['VENDOR_ID'].n_unique():,}\")\n",
    "print(f\"  Click rate: {model1_panel['WasClicked'].mean():.2%}\")\n",
    "\n",
    "# Save panel\n",
    "model1_path = PANEL_DIR / 'panel_model1_ad_effectiveness.parquet'\n",
    "model1_panel.write_parquet(model1_path)\n",
    "print(f\"\\n✓ Saved to {model1_path}\")\n",
    "print(f\"  File size: {model1_path.stat().st_size / (1024**2):.2f} MB\")\n",
    "\n",
    "# Clear memory\n",
    "del df_impressions, df_bids, df_clicks, df_catalog\n",
    "del model1_data, model1_panel\n",
    "gc.collect()\n",
    "print(\"\\n✓ Memory cleared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Journey Continuation Panel (Session-Level)\n",
    "\n",
    "Unit of analysis: Browsing session\n",
    "Key outcome: ReturnedForNextSession (binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL 2: JOURNEY CONTINUATION PANEL\n",
      "================================================================================\n",
      "\n",
      "Loading browsing sessions...\n",
      "  Total sessions: 56,324\n",
      "  Unique users: 3,396\n",
      "\n",
      "Creating outcome variable (ReturnedForNextSession)...\n",
      "  Return rate: 83.64%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL 2: JOURNEY CONTINUATION PANEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load browsing sessions\n",
    "print(\"\\nLoading browsing sessions...\")\n",
    "df_browsing = pl.read_parquet(DATA_DIR / 'browsing_sessions.parquet')\n",
    "print(f\"  Total sessions: {len(df_browsing):,}\")\n",
    "print(f\"  Unique users: {df_browsing['user_id'].n_unique():,}\")\n",
    "\n",
    "# Sort by user and time\n",
    "model2_data = df_browsing.sort(['user_id', 'session_start'])\n",
    "\n",
    "# Create outcome variable using window functions\n",
    "print(\"\\nCreating outcome variable (ReturnedForNextSession)...\")\n",
    "\n",
    "# Get next session start time within same shopping session\n",
    "model2_data = model2_data.with_columns(\n",
    "    pl.col('session_start').shift(-1).over(['user_id', 'shopping_session_id']).alias('next_session_start')\n",
    ")\n",
    "\n",
    "# Create binary outcome\n",
    "model2_data = model2_data.with_columns(\n",
    "    pl.col('next_session_start').is_not_null().cast(pl.Int8).alias('ReturnedForNextSession')\n",
    ")\n",
    "\n",
    "print(f\"  Return rate: {model2_data['ReturnedForNextSession'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adding session-level features...\n",
      "  Average clicks per session: 0.61\n",
      "  Purchase rate: 6.72%\n",
      "  Average session duration: 8.1 minutes\n"
     ]
    }
   ],
   "source": [
    "# Add session-level features\n",
    "print(\"\\nAdding session-level features...\")\n",
    "\n",
    "# Basic features\n",
    "model2_data = model2_data.with_columns([\n",
    "    # Engagement metrics\n",
    "    pl.col('num_clicks').alias('NumClicks'),\n",
    "    pl.col('num_impressions').alias('NumImpressions'),\n",
    "    pl.col('unique_products').alias('VarietyProductsClicked'),\n",
    "    \n",
    "    # Purchase indicator\n",
    "    (pl.col('session_revenue_usd') > 0).cast(pl.Int8).alias('MadePurchase'),\n",
    "    \n",
    "    # Session duration in minutes\n",
    "    pl.col('duration_minutes').alias('SessionDuration'),\n",
    "    \n",
    "    # Session order within user\n",
    "    pl.col('user_id').cum_count().over('user_id').alias('session_number')\n",
    "])\n",
    "\n",
    "# Add first session indicator\n",
    "model2_data = model2_data.with_columns(\n",
    "    (pl.col('session_number') == 1).cast(pl.Int8).alias('IsFirstSession')\n",
    ")\n",
    "\n",
    "# Calculate time since last session\n",
    "model2_data = model2_data.with_columns(\n",
    "    pl.col('session_end').shift(1).over('user_id').alias('prev_session_end')\n",
    ")\n",
    "\n",
    "# Convert to datetime if needed\n",
    "if model2_data['session_start'].dtype == pl.Utf8:\n",
    "    model2_data = model2_data.with_columns([\n",
    "        pl.col('session_start').str.to_datetime(format='%Y-%m-%dT%H:%M:%S%.f%z', strict=False),\n",
    "        pl.col('session_end').str.to_datetime(format='%Y-%m-%dT%H:%M:%S%.f%z', strict=False),\n",
    "        pl.col('prev_session_end').str.to_datetime(format='%Y-%m-%dT%H:%M:%S%.f%z', strict=False)\n",
    "    ])\n",
    "\n",
    "# Calculate time since last session in hours\n",
    "model2_data = model2_data.with_columns(\n",
    "    ((pl.col('session_start') - pl.col('prev_session_end')).dt.total_seconds() / 3600)\n",
    "    .fill_null(0.0)\n",
    "    .alias('TimeSinceLastSession')\n",
    ")\n",
    "\n",
    "# Add day of week\n",
    "model2_data = model2_data.with_columns(\n",
    "    pl.col('session_start').dt.weekday().alias('dayofweek')\n",
    ")\n",
    "\n",
    "print(f\"  Average clicks per session: {model2_data['NumClicks'].mean():.2f}\")\n",
    "print(f\"  Purchase rate: {model2_data['MadePurchase'].mean():.2%}\")\n",
    "print(f\"  Average session duration: {model2_data['SessionDuration'].mean():.1f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 100% of users...\n",
      "\n",
      "Final Model 2 Panel:\n",
      "  Observations: 56,324\n",
      "  Unique users: 3,396\n",
      "  Return rate: 83.64%\n",
      "\n",
      "✓ Saved to data/panels/panel_model2_continuation.parquet\n",
      "  File size: 2.81 MB\n",
      "\n",
      "✓ Memory cleared\n"
     ]
    }
   ],
   "source": [
    "# Sample users for memory efficiency\n",
    "print(f\"\\nSampling {USER_SAMPLE_FRACTION:.0%} of users...\")\n",
    "unique_users = model2_data['user_id'].unique()\n",
    "sampled_users = pl.DataFrame({'user_id': unique_users}).sample(\n",
    "    fraction=USER_SAMPLE_FRACTION,\n",
    "    with_replacement=False,\n",
    "    shuffle=True,\n",
    "    seed=RANDOM_SEED\n",
    ")\n",
    "\n",
    "model2_panel = model2_data.join(\n",
    "    sampled_users,\n",
    "    on='user_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(f\"\\nFinal Model 2 Panel:\")\n",
    "print(f\"  Observations: {len(model2_panel):,}\")\n",
    "print(f\"  Unique users: {model2_panel['user_id'].n_unique():,}\")\n",
    "print(f\"  Return rate: {model2_panel['ReturnedForNextSession'].mean():.2%}\")\n",
    "\n",
    "# Save panel\n",
    "model2_path = PANEL_DIR / 'panel_model2_continuation.parquet'\n",
    "model2_panel.write_parquet(model2_path)\n",
    "print(f\"\\n✓ Saved to {model2_path}\")\n",
    "print(f\"  File size: {model2_path.stat().st_size / (1024**2):.2f} MB\")\n",
    "\n",
    "# Clear memory\n",
    "del df_browsing, model2_data, model2_panel\n",
    "gc.collect()\n",
    "print(\"\\n✓ Memory cleared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Final Conversion Panel (Shopping Session Level)\n",
    "\n",
    "Unit of analysis: Shopping session (complete journey)\n",
    "Key outcome: DidPurchase (binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL 3: FINAL CONVERSION PANEL\n",
      "================================================================================\n",
      "\n",
      "Loading shopping sessions...\n",
      "  Total shopping sessions: 9,214\n",
      "  Unique users: 3,396\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL 3: FINAL CONVERSION PANEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load shopping sessions\n",
    "print(\"\\nLoading shopping sessions...\")\n",
    "df_shopping = pl.read_parquet(DATA_DIR / 'shopping_sessions.parquet')\n",
    "print(f\"  Total shopping sessions: {len(df_shopping):,}\")\n",
    "print(f\"  Unique users: {df_shopping['user_id'].n_unique():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing shopping session features...\n",
      "  Conversion rate: 16.21%\n",
      "  Average browsing sessions: 6.11\n",
      "  Average total clicks: 3.72\n"
     ]
    }
   ],
   "source": [
    "# Prepare features\n",
    "print(\"\\nPreparing shopping session features...\")\n",
    "\n",
    "model3_data = df_shopping.with_columns([\n",
    "    # Outcome\n",
    "    pl.col('did_purchase').cast(pl.Int8).alias('DidPurchase'),\n",
    "    \n",
    "    # Journey engagement metrics\n",
    "    pl.col('num_browsing_sessions').alias('NumBrowsingSessions'),\n",
    "    pl.col('total_clicks').alias('TotalClicks'),\n",
    "    pl.col('total_impressions').alias('TotalImpressions'),\n",
    "    \n",
    "    # Journey duration\n",
    "    pl.col('shopping_duration_days').alias('TotalDurationDays'),\n",
    "    \n",
    "    # Variety metrics - using correct column names\n",
    "    pl.col('total_unique_products').alias('UniqueProductsViewed'),\n",
    "    pl.col('total_unique_auctions').alias('UniqueAuctionsEngaged'),\n",
    "    \n",
    "    # Revenue metrics\n",
    "    pl.col('total_revenue_usd').alias('TotalRevenue')\n",
    "])\n",
    "\n",
    "# Add derived features\n",
    "model3_data = model3_data.with_columns([\n",
    "    # Session density (sessions per day)\n",
    "    (pl.col('NumBrowsingSessions') / (pl.col('TotalDurationDays') + 0.01)).alias('SessionDensity'),\n",
    "    \n",
    "    # Click-to-impression ratio\n",
    "    (pl.col('TotalClicks') / (pl.col('TotalImpressions') + 1)).alias('ClickThroughRate'),\n",
    "    \n",
    "    # Interaction term\n",
    "    (pl.col('NumBrowsingSessions') * pl.col('TotalClicks')).alias('Sessions_x_Clicks'),\n",
    "    \n",
    "    # Variety vendor proxy (using unique auctions as proxy)\n",
    "    pl.col('UniqueAuctionsEngaged').alias('VarietyVendorsClicked')\n",
    "])\n",
    "\n",
    "print(f\"  Conversion rate: {model3_data['DidPurchase'].mean():.2%}\")\n",
    "print(f\"  Average browsing sessions: {model3_data['NumBrowsingSessions'].mean():.2f}\")\n",
    "print(f\"  Average total clicks: {model3_data['TotalClicks'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adding time identifiers...\n",
      "\n",
      "Sampling 100% of users...\n",
      "Filtering to multi-session users for panel analysis...\n",
      "\n",
      "Final Model 3 Panel:\n",
      "  Observations: 7,675\n",
      "  Unique users: 1,857\n",
      "  Conversion rate: 17.43%\n",
      "  Average sessions per user: 4.13\n",
      "\n",
      "Panel Balance:\n",
      "  Avg browsing sessions per shopping journey: 5.25\n",
      "  Avg total clicks per journey: 3.15\n",
      "  Avg journey duration: 5.26 days\n",
      "\n",
      "  User distribution:\n",
      "    Users with 2+ shopping sessions: 1,857\n",
      "    Users with 3+ shopping sessions: 1,239\n",
      "    Users with 5+ shopping sessions: 674\n",
      "    Max shopping sessions per user: 14\n",
      "\n",
      "  Purchase distribution:\n",
      "    Users with 0 purchases: 1,082\n",
      "    Users with 1+ purchases: 775\n",
      "    Users with 2+ purchases: 330\n",
      "    Max purchases per user: 7\n",
      "\n",
      "  Temporal distribution:\n",
      "    Unique week-years: 26\n",
      "    Min sessions per week: 223\n",
      "    Max sessions per week: 455\n",
      "    Avg sessions per week: 295.2\n",
      "\n",
      "✓ Saved to data/panels/panel_model3_conversion.parquet\n",
      "  File size: 0.57 MB\n",
      "\n",
      "✓ Memory cleared\n"
     ]
    }
   ],
   "source": [
    "# Add time identifiers\n",
    "print(\"\\nAdding time identifiers...\")\n",
    "\n",
    "# Convert to datetime if needed\n",
    "if model3_data['shopping_start'].dtype == pl.Utf8:\n",
    "    model3_data = model3_data.with_columns(\n",
    "        pl.col('shopping_start').str.to_datetime(format='%Y-%m-%dT%H:%M:%S%.f%z', strict=False)\n",
    "    )\n",
    "\n",
    "# Extract week and year\n",
    "model3_data = model3_data.with_columns([\n",
    "    pl.col('shopping_start').dt.week().alias('week_of_year'),\n",
    "    pl.col('shopping_start').dt.year().alias('year')\n",
    "])\n",
    "\n",
    "# Create week-year identifier\n",
    "model3_data = model3_data.with_columns(\n",
    "    (pl.col('year').cast(pl.Utf8) + '_' + pl.col('week_of_year').cast(pl.Utf8)).alias('week_year')\n",
    ")\n",
    "\n",
    "# Sample users and filter to multi-session users\n",
    "print(f\"\\nSampling {USER_SAMPLE_FRACTION:.0%} of users...\")\n",
    "unique_users = model3_data['user_id'].unique()\n",
    "sampled_users = pl.DataFrame({'user_id': unique_users}).sample(\n",
    "    fraction=USER_SAMPLE_FRACTION,\n",
    "    with_replacement=False,\n",
    "    shuffle=True,\n",
    "    seed=RANDOM_SEED\n",
    ")\n",
    "\n",
    "model3_sampled = model3_data.join(\n",
    "    sampled_users,\n",
    "    on='user_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Filter to users with multiple shopping sessions for panel variation\n",
    "print(\"Filtering to multi-session users for panel analysis...\")\n",
    "user_counts = model3_sampled.group_by('user_id').agg(\n",
    "    pl.count().alias('n_shopping_sessions')\n",
    ")\n",
    "multi_users = user_counts.filter(pl.col('n_shopping_sessions') > 1)['user_id']\n",
    "\n",
    "model3_panel = model3_sampled.join(\n",
    "    pl.DataFrame({'user_id': multi_users}),\n",
    "    on='user_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(f\"\\nFinal Model 3 Panel:\")\n",
    "print(f\"  Observations: {len(model3_panel):,}\")\n",
    "print(f\"  Unique users: {model3_panel['user_id'].n_unique():,}\")\n",
    "print(f\"  Conversion rate: {model3_panel['DidPurchase'].mean():.2%}\")\n",
    "print(f\"  Average sessions per user: {len(model3_panel) / model3_panel['user_id'].n_unique():.2f}\")\n",
    "\n",
    "# Panel balance checks\n",
    "print(f\"\\nPanel Balance:\")\n",
    "print(f\"  Avg browsing sessions per shopping journey: {model3_panel['NumBrowsingSessions'].mean():.2f}\")\n",
    "print(f\"  Avg total clicks per journey: {model3_panel['TotalClicks'].mean():.2f}\")\n",
    "print(f\"  Avg journey duration: {model3_panel['TotalDurationDays'].mean():.2f} days\")\n",
    "\n",
    "# Check user distribution\n",
    "user_shopping_counts = model3_panel.group_by('user_id').agg([\n",
    "    pl.count().alias('shopping_sessions'),\n",
    "    pl.col('DidPurchase').sum().alias('purchases')\n",
    "])\n",
    "\n",
    "print(f\"\\n  User distribution:\")\n",
    "print(f\"    Users with 2+ shopping sessions: {user_shopping_counts.filter(pl.col('shopping_sessions') >= 2).height:,}\")\n",
    "print(f\"    Users with 3+ shopping sessions: {user_shopping_counts.filter(pl.col('shopping_sessions') >= 3).height:,}\")\n",
    "print(f\"    Users with 5+ shopping sessions: {user_shopping_counts.filter(pl.col('shopping_sessions') >= 5).height:,}\")\n",
    "print(f\"    Max shopping sessions per user: {user_shopping_counts['shopping_sessions'].max()}\")\n",
    "\n",
    "print(f\"\\n  Purchase distribution:\")\n",
    "print(f\"    Users with 0 purchases: {user_shopping_counts.filter(pl.col('purchases') == 0).height:,}\")\n",
    "print(f\"    Users with 1+ purchases: {user_shopping_counts.filter(pl.col('purchases') >= 1).height:,}\")\n",
    "print(f\"    Users with 2+ purchases: {user_shopping_counts.filter(pl.col('purchases') >= 2).height:,}\")\n",
    "print(f\"    Max purchases per user: {user_shopping_counts['purchases'].max()}\")\n",
    "\n",
    "# Check temporal balance\n",
    "week_counts = model3_panel.group_by('week_year').agg(pl.count().alias('count'))\n",
    "print(f\"\\n  Temporal distribution:\")\n",
    "print(f\"    Unique week-years: {week_counts.height}\")\n",
    "print(f\"    Min sessions per week: {week_counts['count'].min()}\")\n",
    "print(f\"    Max sessions per week: {week_counts['count'].max()}\")\n",
    "print(f\"    Avg sessions per week: {week_counts['count'].mean():.1f}\")\n",
    "\n",
    "# Save panel\n",
    "model3_path = PANEL_DIR / 'panel_model3_conversion.parquet'\n",
    "model3_panel.write_parquet(model3_path)\n",
    "print(f\"\\n✓ Saved to {model3_path}\")\n",
    "print(f\"  File size: {model3_path.stat().st_size / (1024**2):.2f} MB\")\n",
    "\n",
    "# Clear memory\n",
    "del df_shopping, model3_data, model3_sampled, model3_panel\n",
    "gc.collect()\n",
    "print(\"\\n✓ Memory cleared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PANEL CONSTRUCTION COMPLETE\n",
      "================================================================================\n",
      "\n",
      "Created panels:\n",
      "  ✓ panel_model1_ad_effectiveness.parquet: 1,121,199 rows, 79.00 MB\n",
      "  ✓ panel_model2_continuation.parquet: 56,324 rows, 2.81 MB\n",
      "  ✓ panel_model3_conversion.parquet: 7,675 rows, 0.57 MB\n",
      "\n",
      "✓ All panels ready for econometric analysis in 04_fixed_effects.ipynb\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PANEL CONSTRUCTION COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nCreated panels:\")\n",
    "\n",
    "for filename in ['panel_model1_ad_effectiveness.parquet', \n",
    "                 'panel_model2_continuation.parquet',\n",
    "                 'panel_model3_conversion.parquet']:\n",
    "    filepath = PANEL_DIR / filename\n",
    "    if filepath.exists():\n",
    "        size_mb = filepath.stat().st_size / (1024**2)\n",
    "        df_temp = pl.scan_parquet(filepath)\n",
    "        n_rows = df_temp.select(pl.count()).collect().item()\n",
    "        print(f\"  ✓ {filename}: {n_rows:,} rows, {size_mb:.2f} MB\")\n",
    "    else:\n",
    "        print(f\"  ✗ {filename}: not created\")\n",
    "\n",
    "print(\"\\n✓ All panels ready for econometric analysis in 04_fixed_effects.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
