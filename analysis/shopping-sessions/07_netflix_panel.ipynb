{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Netflix Incrementality Panel Construction\n",
    "\n",
    "This notebook implements the continuous-time, event-sampled panel methodology from the Netflix incrementality paper.\n",
    "\n",
    "## Key Differences from Standard Panel Approach\n",
    "\n",
    "1. **Sampling Strategy**: Not a balanced panel, but strategic sampling of conversion and non-conversion moments\n",
    "2. **Continuous-Time Features**: Ad stock calculated dynamically at each sampled timestamp\n",
    "3. **Weighting Scheme**: Sophisticated weights to correct for sampling bias\n",
    "4. **Unit of Analysis**: (user, vendor, timestamp) not (user, vendor, day)\n",
    "\n",
    "## References\n",
    "\n",
    "- Netflix Paper: \"Incrementality Bidding & Attribution\"\n",
    "- Model: yᵢᵥ(t) = αᵢ + δₜ + γᵥ + Σₖ βₖxᵢᵥₖ(t) + Wᵢᵥ(t)'θ + εᵢᵥ(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('Libraries loaded successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Raw Event Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load all event streams\nimpressions = pd.read_parquet('data/raw_sample_impressions.parquet')\nimpressions['timestamp'] = pd.to_datetime(impressions['OCCURRED_AT'])\nimpressions['user_id'] = impressions['USER_ID']\nimpressions['vendor_id'] = impressions['VENDOR_ID']\nprint(f'Loaded {len(impressions):,} impressions')\n\nclicks = pd.read_parquet('data/raw_sample_clicks.parquet')\nclicks['timestamp'] = pd.to_datetime(clicks['OCCURRED_AT'])\nclicks['user_id'] = clicks['USER_ID']\nclicks['vendor_id'] = clicks['VENDOR_ID']\nprint(f'Loaded {len(clicks):,} clicks')\n\npurchases = pd.read_parquet('data/raw_sample_purchases.parquet')\npurchases['timestamp'] = pd.to_datetime(purchases['PURCHASED_AT'])\npurchases['user_id'] = purchases['USER_ID']\n# GMV calculation: prices are in CENTS, convert to dollars\npurchases['gmv'] = (purchases['QUANTITY'] * purchases['UNIT_PRICE']) / 100\nprint(f'Loaded {len(purchases):,} purchases')\n\nauctions = pd.read_parquet('data/raw_sample_auctions_users.parquet')\nauctions['timestamp'] = pd.to_datetime(auctions['CREATED_AT'])\nauctions['user_id'] = auctions['OPAQUE_USER_ID']\nprint(f'Loaded {len(auctions):,} auctions')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Identify Conversions with Vendor Attribution\n",
    "\n",
    "Match purchases to vendors via product-level impressions/clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Identified 157 user-vendor-timestamp conversions\n",
      "Total GMV: $505,900.00\n",
      "Unique users: 111\n",
      "Unique vendors: 154\n"
     ]
    }
   ],
   "source": [
    "# Get impression/click data at product level for vendor attribution\n",
    "imp_with_product = impressions[['user_id', 'vendor_id', 'PRODUCT_ID', 'timestamp']].copy()\n",
    "click_with_product = clicks[['user_id', 'vendor_id', 'PRODUCT_ID', 'timestamp']].copy()\n",
    "\n",
    "# Create purchase-product mapping\n",
    "purchase_products = purchases[['user_id', 'PRODUCT_ID', 'timestamp', 'gmv']].copy()\n",
    "\n",
    "# Match clicks to purchases (same day attribution)\n",
    "click_with_product['date'] = click_with_product['timestamp'].dt.date\n",
    "purchase_products['date'] = purchase_products['timestamp'].dt.date\n",
    "\n",
    "click_conversions = pd.merge(\n",
    "    click_with_product,\n",
    "    purchase_products[['user_id', 'PRODUCT_ID', 'date', 'gmv', 'timestamp']],\n",
    "    on=['user_id', 'PRODUCT_ID', 'date'],\n",
    "    how='inner',\n",
    "    suffixes=('_click', '_purchase')\n",
    ")\n",
    "\n",
    "# Match impressions to purchases (same day attribution)\n",
    "imp_with_product['date'] = imp_with_product['timestamp'].dt.date\n",
    "\n",
    "imp_conversions = pd.merge(\n",
    "    imp_with_product,\n",
    "    purchase_products[['user_id', 'PRODUCT_ID', 'date', 'gmv', 'timestamp']],\n",
    "    on=['user_id', 'PRODUCT_ID', 'date'],\n",
    "    how='inner',\n",
    "    suffixes=('_imp', '_purchase')\n",
    ")\n",
    "\n",
    "# Combine and deduplicate (prefer click attribution)\n",
    "all_conversions = pd.concat([\n",
    "    click_conversions[['user_id', 'vendor_id', 'timestamp_purchase', 'gmv']],\n",
    "    imp_conversions[['user_id', 'vendor_id', 'timestamp_purchase', 'gmv']]\n",
    "])\n",
    "\n",
    "# Keep unique user-vendor-timestamp conversions\n",
    "all_conversions = all_conversions.drop_duplicates(\n",
    "    subset=['user_id', 'vendor_id', 'timestamp_purchase'], \n",
    "    keep='first'\n",
    ")\n",
    "\n",
    "# Aggregate to user-vendor-timestamp level\n",
    "conversions = all_conversions.groupby(\n",
    "    ['user_id', 'vendor_id', 'timestamp_purchase']\n",
    ").agg({'gmv': 'sum'}).reset_index()\n",
    "\n",
    "conversions = conversions.rename(columns={'timestamp_purchase': 'timestamp'})\n",
    "\n",
    "print(f'\\nIdentified {len(conversions)} user-vendor-timestamp conversions')\n",
    "print(f'Total GMV: ${conversions.gmv.sum():,.2f}')\n",
    "print(f'Unique users: {conversions.user_id.nunique()}')\n",
    "print(f'Unique vendors: {conversions.vendor_id.nunique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Positive Samples (+)\n",
    "\n",
    "One row for each conversion event at the exact timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 157 positive samples\n",
      "Mean GMV: $3222.29\n",
      "                                     user_id  \\\n",
      "0  ext1:02910a27-2d21-4945-8b34-31a2bdba9ce7   \n",
      "1  ext1:047ec1e3-142c-47d2-b492-9b3047c26591   \n",
      "2  ext1:05ffe8c2-b009-4cac-b0d4-77688bb01774   \n",
      "3  ext1:064d91e2-c3b0-47e9-8155-cecf17f5e84e   \n",
      "4  ext1:08694c1c-3a35-47e1-8f36-25d7171e2403   \n",
      "\n",
      "                          vendor_id           timestamp   gmv  outcome  \\\n",
      "0  064bd96336977540a524f04181b7c74b 2025-06-07 02:48:08  1500        1   \n",
      "1  01951ac662f57100ba9c7b69a206b10d 2025-07-16 15:17:47   500        1   \n",
      "2  0193c5e7b7487c2297ae709c7bac36e6 2025-09-18 09:20:17  6000        1   \n",
      "3  06508dd4a57971b0b2242e04d0c73641 2025-04-19 10:51:19  2800        1   \n",
      "4  01902b58f7da79b79f43cd00b4bd3051 2025-07-02 13:47:50  1500        1   \n",
      "\n",
      "  sample_type  sample_weight  \n",
      "0    positive            1.0  \n",
      "1    positive            1.0  \n",
      "2    positive            1.0  \n",
      "3    positive            1.0  \n",
      "4    positive            1.0  \n"
     ]
    }
   ],
   "source": [
    "# Create positive samples\n",
    "positives = conversions.copy()\n",
    "positives['outcome'] = 1\n",
    "positives['sample_type'] = 'positive'\n",
    "positives['sample_weight'] = 1.0\n",
    "\n",
    "print(f'Created {len(positives)} positive samples')\n",
    "print(f'Mean GMV: ${positives.gmv.mean():.2f}')\n",
    "print(positives.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Negative Samples (-)\n",
    "\n",
    "Random sample of (user, vendor, random_timestamp) with no conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 599,032 active user-vendor pairs\n",
      "Time window: 2025-03-25 00:01:05 to 2025-09-20 23:59:56\n",
      "\n",
      "Sampling 2355 negative observations...\n",
      "Created 2355 negative samples\n",
      "Negative weight: 45531.52\n",
      "                                          user_id  \\\n",
      "149628  ext1:d0fcb300-57cf-4b03-91b8-4c9fb7f0f69f   \n",
      "163660  ext1:910d10a3-aa04-49cc-bc70-89b0c91fe1f2   \n",
      "568162  ext1:0ee7c369-683f-4aed-a0a4-08877570b015   \n",
      "366479  ext1:4075d35d-a94e-40f6-bf0c-c955f8151a71   \n",
      "133523  ext1:d380462b-180f-434d-91d7-d4571b0358a0   \n",
      "\n",
      "                               vendor_id                     timestamp  \\\n",
      "149628  018f4e7e4cff72738f36359e65c2259e 2025-09-14 16:18:14.972595714   \n",
      "163660  0190b91e03f47451af9a03dfe7f36a66 2025-07-01 15:21:30.206157375   \n",
      "568162  01964ed8d81e75128a8f70c39a4b6a36 2025-07-09 14:51:40.247825669   \n",
      "366479  018e9bcec3e37aa8ad15a89b912fb485 2025-07-14 03:04:45.539634172   \n",
      "133523  01985c650bb57ed2b5baebcfc4f87e02 2025-07-11 18:51:20.900539825   \n",
      "\n",
      "        outcome  gmv sample_type  sample_weight  \n",
      "149628        0  0.0    negative   45531.519321  \n",
      "163660        0  0.0    negative   45531.519321  \n",
      "568162        0  0.0    negative   45531.519321  \n",
      "366479        0  0.0    negative   45531.519321  \n",
      "133523        0  0.0    negative   45531.519321  \n"
     ]
    }
   ],
   "source": [
    "# Get observation window\n",
    "min_time = impressions['timestamp'].min()\n",
    "max_time = impressions['timestamp'].max()\n",
    "time_range_seconds = (max_time - min_time).total_seconds()\n",
    "\n",
    "# Get unique user-vendor pairs that had any activity\n",
    "active_pairs = pd.concat([\n",
    "    impressions[['user_id', 'vendor_id']],\n",
    "    clicks[['user_id', 'vendor_id']]\n",
    "]).drop_duplicates()\n",
    "\n",
    "print(f'Found {len(active_pairs):,} active user-vendor pairs')\n",
    "print(f'Time window: {min_time} to {max_time}')\n",
    "\n",
    "# Sample negatives\n",
    "# Rule of thumb: 10-20x more negatives than positives for stable estimation\n",
    "n_negatives = len(positives) * 15\n",
    "print(f'\\nSampling {n_negatives} negative observations...')\n",
    "\n",
    "# Randomly sample user-vendor pairs with replacement\n",
    "negative_pairs = active_pairs.sample(n=n_negatives, replace=True, random_state=42)\n",
    "\n",
    "# Generate random timestamps for each\n",
    "random_seconds = np.random.uniform(0, time_range_seconds, size=n_negatives)\n",
    "negative_pairs['timestamp'] = min_time + pd.to_timedelta(random_seconds, unit='s')\n",
    "\n",
    "# Mark as negatives\n",
    "negative_pairs['outcome'] = 0\n",
    "negative_pairs['gmv'] = 0.0\n",
    "negative_pairs['sample_type'] = 'negative'\n",
    "\n",
    "# Calculate negative weight\n",
    "# w⁻ = (Total user-time space) / (# negative samples)\n",
    "# Total user-time = # active user-vendor pairs × # days\n",
    "n_days = (max_time - min_time).days\n",
    "\n",
    "total_user_time = len(active_pairs) * n_days\n",
    "negative_weight = total_user_time / n_negatives\n",
    "\n",
    "negative_pairs['sample_weight'] = negative_weight\n",
    "\n",
    "negatives = negative_pairs\n",
    "\n",
    "print(f'Created {len(negatives)} negative samples')\n",
    "print(f'Negative weight: {negative_weight:.2f}')\n",
    "print(negatives.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Double-Negative Samples (+0)\n",
    "\n",
    "Duplicate of each positive with outcome=0 and negative weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 157 double-negative samples\n",
      "                                     user_id  \\\n",
      "0  ext1:02910a27-2d21-4945-8b34-31a2bdba9ce7   \n",
      "1  ext1:047ec1e3-142c-47d2-b492-9b3047c26591   \n",
      "2  ext1:05ffe8c2-b009-4cac-b0d4-77688bb01774   \n",
      "3  ext1:064d91e2-c3b0-47e9-8155-cecf17f5e84e   \n",
      "4  ext1:08694c1c-3a35-47e1-8f36-25d7171e2403   \n",
      "\n",
      "                          vendor_id           timestamp   gmv  outcome  \\\n",
      "0  064bd96336977540a524f04181b7c74b 2025-06-07 02:48:08  1500        0   \n",
      "1  01951ac662f57100ba9c7b69a206b10d 2025-07-16 15:17:47   500        0   \n",
      "2  0193c5e7b7487c2297ae709c7bac36e6 2025-09-18 09:20:17  6000        0   \n",
      "3  06508dd4a57971b0b2242e04d0c73641 2025-04-19 10:51:19  2800        0   \n",
      "4  01902b58f7da79b79f43cd00b4bd3051 2025-07-02 13:47:50  1500        0   \n",
      "\n",
      "       sample_type  sample_weight  \n",
      "0  double_negative           -1.0  \n",
      "1  double_negative           -1.0  \n",
      "2  double_negative           -1.0  \n",
      "3  double_negative           -1.0  \n",
      "4  double_negative           -1.0  \n"
     ]
    }
   ],
   "source": [
    "# Create double-negatives\n",
    "double_negatives = positives.copy()\n",
    "double_negatives['outcome'] = 0\n",
    "double_negatives['sample_type'] = 'double_negative'\n",
    "double_negatives['sample_weight'] = -1.0\n",
    "\n",
    "print(f'Created {len(double_negatives)} double-negative samples')\n",
    "print(double_negatives.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Combine All Samples\n",
    "\n",
    "Stack positives, negatives, and double-negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combined panel size: 2,669 rows\n",
      "\n",
      "Sample type breakdown:\n",
      "sample_type\n",
      "negative           2355\n",
      "positive            157\n",
      "double_negative     157\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outcome distribution:\n",
      "outcome\n",
      "0    2512\n",
      "1     157\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Weighted outcome mean: 0.000001\n"
     ]
    }
   ],
   "source": [
    "# Combine all samples\n",
    "panel = pd.concat([positives, negatives, double_negatives], ignore_index=True)\n",
    "\n",
    "# Sort by user, vendor, timestamp\n",
    "panel = panel.sort_values(['user_id', 'vendor_id', 'timestamp']).reset_index(drop=True)\n",
    "\n",
    "print(f'\\nCombined panel size: {len(panel):,} rows')\n",
    "print(f'\\nSample type breakdown:')\n",
    "print(panel['sample_type'].value_counts())\n",
    "print(f'\\nOutcome distribution:')\n",
    "print(panel['outcome'].value_counts())\n",
    "print(f'\\nWeighted outcome mean: {(panel[\"outcome\"] * panel[\"sample_weight\"]).sum() / panel[\"sample_weight\"].sum():.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Calculate Continuous-Time Ad Stock Features\n",
    "\n",
    "For each row at timestamp t, calculate vendor-specific ad stock from all prior impressions/clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating continuous-time ad stock features...\n",
      "Using optimized vectorized approach for performance.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "impression 1hr: 100%|██████████| 2503/2503 [02:18<00:00, 18.09it/s]\n",
      "impression 3hr: 100%|██████████| 2503/2503 [02:19<00:00, 17.94it/s]\n",
      "impression 12hr: 100%|██████████| 2503/2503 [02:18<00:00, 18.10it/s]\n",
      "impression 24hr: 100%|██████████| 2503/2503 [02:19<00:00, 18.00it/s]\n",
      "impression 72hr: 100%|██████████| 2503/2503 [02:20<00:00, 17.87it/s]\n",
      "click 1hr: 100%|██████████| 2503/2503 [00:04<00:00, 533.19it/s]\n",
      "click 3hr: 100%|██████████| 2503/2503 [00:04<00:00, 536.05it/s]\n",
      "click 12hr: 100%|██████████| 2503/2503 [00:04<00:00, 534.58it/s]\n",
      "click 24hr: 100%|██████████| 2503/2503 [00:04<00:00, 526.11it/s]\n",
      "click 72hr: 100%|██████████| 2503/2503 [00:04<00:00, 537.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ad stock features calculated\n",
      "\n",
      "Sample ad stock statistics:\n",
      "       adstock_imp_1hr  adstock_imp_1day  adstock_click_1hr\n",
      "count     2.669000e+03      2.669000e+03        2669.000000\n",
      "mean      1.454700e-01      2.978965e-01           0.111182\n",
      "std       7.066548e-01      1.520682e+00           0.427172\n",
      "min       0.000000e+00      0.000000e+00           0.000000\n",
      "25%       0.000000e+00      0.000000e+00           0.000000\n",
      "50%       0.000000e+00      7.612156e-35           0.000000\n",
      "75%      6.170078e-188      1.776555e-08           0.000000\n",
      "max       1.504522e+01      3.010593e+01           4.762028\n"
     ]
    }
   ],
   "source": [
    "print('Calculating continuous-time ad stock features...')\n",
    "print('Using optimized vectorized approach for performance.\\n')\n",
    "\n",
    "# Define decay half-lives (in hours)\n",
    "decay_specs = [\n",
    "    ('1hr', 1),\n",
    "    ('3hr', 3),\n",
    "    ('12hr', 12),\n",
    "    ('1day', 24),\n",
    "    ('3day', 72)\n",
    "]\n",
    "\n",
    "def calculate_adstock_optimized(panel_df, exposure_df, decay_halflife_hours, exposure_type='impression'):\n",
    "    \"\"\"\n",
    "    Optimized vectorized calculation of ad stock\n",
    "    Groups by user-vendor to process efficiently\n",
    "    \"\"\"\n",
    "    decay_rate = np.log(2) / decay_halflife_hours\n",
    "    results = []\n",
    "    \n",
    "    # Group both panel and exposures by user-vendor\n",
    "    for (user_id, vendor_id), panel_group in tqdm(\n",
    "        panel_df.groupby(['user_id', 'vendor_id']), \n",
    "        desc=f'{exposure_type} {decay_halflife_hours}hr'\n",
    "    ):\n",
    "        # Get exposures for this user-vendor pair\n",
    "        user_vendor_exp = exposure_df[\n",
    "            (exposure_df['user_id'] == user_id) & \n",
    "            (exposure_df['vendor_id'] == vendor_id)\n",
    "        ].sort_values('timestamp')\n",
    "        \n",
    "        if len(user_vendor_exp) == 0:\n",
    "            # No exposures - all zeros\n",
    "            results.extend([0.0] * len(panel_group))\n",
    "            continue\n",
    "        \n",
    "        # For each panel timestamp, calculate ad stock\n",
    "        exposure_times = user_vendor_exp['timestamp'].values\n",
    "        \n",
    "        adstocks = []\n",
    "        for panel_time in panel_group['timestamp'].values:\n",
    "            # Find exposures before this time\n",
    "            time_diffs_seconds = (panel_time - exposure_times).astype('timedelta64[s]').astype(float)\n",
    "            \n",
    "            # Only keep positive diffs (past exposures) and convert to hours\n",
    "            prior_mask = time_diffs_seconds > 0\n",
    "            if not np.any(prior_mask):\n",
    "                adstocks.append(0.0)\n",
    "                continue\n",
    "                \n",
    "            time_diffs_hours = time_diffs_seconds[prior_mask] / 3600\n",
    "            \n",
    "            # Calculate exponential decay weights\n",
    "            weights = np.exp(-decay_rate * time_diffs_hours)\n",
    "            adstocks.append(weights.sum())\n",
    "        \n",
    "        results.extend(adstocks)\n",
    "    \n",
    "    return pd.Series(results, index=panel_df.index)\n",
    "\n",
    "# Calculate impression ad stock for all decay rates\n",
    "for name, halflife in decay_specs:\n",
    "    panel[f'adstock_imp_{name}'] = calculate_adstock_optimized(\n",
    "        panel, impressions, halflife, 'impression'\n",
    "    )\n",
    "\n",
    "# Calculate click ad stock for all decay rates  \n",
    "for name, halflife in decay_specs:\n",
    "    panel[f'adstock_click_{name}'] = calculate_adstock_optimized(\n",
    "        panel, clicks, halflife, 'click'\n",
    "    )\n",
    "\n",
    "print('\\nAd stock features calculated')\n",
    "print('\\nSample ad stock statistics:')\n",
    "print(panel[['adstock_imp_1hr', 'adstock_imp_1day', 'adstock_click_1hr']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Calculate Event Stock (Retargeting Signals)\n",
    "\n",
    "Similar to ad stock, but for user actions like auctions/clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating event stock features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Event stock 6hr: 100%|██████████| 816/816 [00:05<00:00, 138.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event stock features calculated\n",
      "       auction_stock_6hr  click_stock_1hr\n",
      "count       2.669000e+03      2669.000000\n",
      "mean        3.943215e+00         0.111182\n",
      "std         1.023454e+01         0.427172\n",
      "min         0.000000e+00         0.000000\n",
      "25%         6.431615e-13         0.000000\n",
      "50%         4.112866e-02         0.000000\n",
      "75%         2.558479e+00         0.000000\n",
      "max         1.047098e+02         4.762028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('Calculating event stock features...')\n",
    "\n",
    "def calculate_user_event_stock(panel_df, event_df, halflife_hours):\n",
    "    \"\"\"\n",
    "    Calculate event stock at user level (not vendor-specific)\n",
    "    Optimized version\n",
    "    \"\"\"\n",
    "    decay_rate = np.log(2) / halflife_hours\n",
    "    results = []\n",
    "    \n",
    "    for user_id, panel_group in tqdm(panel_df.groupby('user_id'), desc=f'Event stock {halflife_hours}hr'):\n",
    "        # Get events for this user\n",
    "        user_events = event_df[event_df['user_id'] == user_id].sort_values('timestamp')\n",
    "        \n",
    "        if len(user_events) == 0:\n",
    "            results.extend([0.0] * len(panel_group))\n",
    "            continue\n",
    "        \n",
    "        event_times = user_events['timestamp'].values\n",
    "        \n",
    "        stocks = []\n",
    "        for panel_time in panel_group['timestamp'].values:\n",
    "            time_diffs_seconds = (panel_time - event_times).astype('timedelta64[s]').astype(float)\n",
    "            \n",
    "            prior_mask = time_diffs_seconds > 0\n",
    "            if not np.any(prior_mask):\n",
    "                stocks.append(0.0)\n",
    "                continue\n",
    "            \n",
    "            time_diffs_hours = time_diffs_seconds[prior_mask] / 3600\n",
    "            weights = np.exp(-decay_rate * time_diffs_hours)\n",
    "            stocks.append(weights.sum())\n",
    "        \n",
    "        results.extend(stocks)\n",
    "    \n",
    "    return pd.Series(results, index=panel_df.index)\n",
    "\n",
    "# Calculate auction stock\n",
    "panel['auction_stock_6hr'] = calculate_user_event_stock(panel, auctions, 6)\n",
    "\n",
    "# Click stock is already calculated in previous cell as adstock_click_1hr\n",
    "panel['click_stock_1hr'] = panel['adstock_click_1hr']\n",
    "\n",
    "print('Event stock features calculated')\n",
    "print(panel[['auction_stock_6hr', 'click_stock_1hr']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Add Time-of-Day Controls (Fourier Series)\n",
    "\n",
    "Capture smooth diurnal and weekly patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time controls added\n",
      "          sin_hour      cos_hour      sin_dow      cos_dow\n",
      "count  2669.000000  2.669000e+03  2669.000000  2669.000000\n",
      "mean     -0.021592  3.263586e-02     0.019455    -0.018009\n",
      "std       0.701033  7.123174e-01     0.712164     0.701779\n",
      "min      -1.000000 -1.000000e+00    -0.974928    -0.900969\n",
      "25%      -0.707107 -7.071068e-01    -0.781831    -0.900969\n",
      "50%       0.000000  6.123234e-17     0.000000    -0.222521\n",
      "75%       0.707107  7.071068e-01     0.781831     0.623490\n",
      "max       1.000000  1.000000e+00     0.974928     1.000000\n"
     ]
    }
   ],
   "source": [
    "# Extract time components\n",
    "panel['hour'] = panel['timestamp'].dt.hour\n",
    "panel['dayofweek'] = panel['timestamp'].dt.dayofweek\n",
    "\n",
    "# Fourier series for hour of day (24-hour cycle)\n",
    "panel['sin_hour'] = np.sin(2 * np.pi * panel['hour'] / 24)\n",
    "panel['cos_hour'] = np.cos(2 * np.pi * panel['hour'] / 24)\n",
    "\n",
    "# Fourier series for day of week (7-day cycle)\n",
    "panel['sin_dow'] = np.sin(2 * np.pi * panel['dayofweek'] / 7)\n",
    "panel['cos_dow'] = np.cos(2 * np.pi * panel['dayofweek'] / 7)\n",
    "\n",
    "# Simple binary controls\n",
    "panel['is_weekend'] = (panel['dayofweek'] >= 5).astype(int)\n",
    "panel['is_evening'] = ((panel['hour'] >= 18) | (panel['hour'] <= 6)).astype(int)\n",
    "\n",
    "print('Time controls added')\n",
    "print(panel[['sin_hour', 'cos_hour', 'sin_dow', 'cos_dow']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Add Fixed Effects Identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed effect identifiers added\n",
      "  Unique users: 816\n",
      "  Unique vendors: 2406\n",
      "  Unique weeks: 26\n",
      "\n",
      "Diminishing returns features added\n",
      "  adstock_imp_1day_sq (mean): 2.400349\n",
      "  adstock_click_1hr_sq (mean): 0.194769\n"
     ]
    }
   ],
   "source": [
    "# Create week identifier for time fixed effects\n",
    "panel['week_id'] = panel['timestamp'].dt.to_period('W').astype(str)\n",
    "\n",
    "# Add diminishing returns features (squared terms for non-linear effects)\n",
    "panel['adstock_imp_1day_sq'] = panel['adstock_imp_1day'] ** 2\n",
    "panel['adstock_click_1hr_sq'] = panel['adstock_click_1hr'] ** 2\n",
    "\n",
    "# User and vendor IDs are already present\n",
    "\n",
    "print('Fixed effect identifiers added')\n",
    "print(f'  Unique users: {panel[\"user_id\"].nunique()}')\n",
    "print(f'  Unique vendors: {panel[\"vendor_id\"].nunique()}')\n",
    "print(f'  Unique weeks: {panel[\"week_id\"].nunique()}')\n",
    "print('\\nDiminishing returns features added')\n",
    "print(f'  adstock_imp_1day_sq (mean): {panel[\"adstock_imp_1day_sq\"].mean():.6f}')\n",
    "print(f'  adstock_click_1hr_sq (mean): {panel[\"adstock_click_1hr_sq\"].mean():.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Add Rolling Window Exposures\n",
    "\n",
    "Count of impressions/clicks in recent windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating rolling window features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rolling 7d: 100%|██████████| 2503/2503 [02:16<00:00, 18.38it/s]\n",
      "Rolling 14d: 100%|██████████| 2503/2503 [02:17<00:00, 18.18it/s]\n",
      "Rolling 7d: 100%|██████████| 2503/2503 [00:04<00:00, 536.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rolling window features calculated\n",
      "       impressions_7d  impressions_14d    clicks_7d\n",
      "count     2669.000000      2669.000000  2669.000000\n",
      "mean         0.410641         0.507306     0.198202\n",
      "std          1.924351         2.316998     0.653141\n",
      "min          0.000000         0.000000     0.000000\n",
      "25%          0.000000         0.000000     0.000000\n",
      "50%          0.000000         0.000000     0.000000\n",
      "75%          0.000000         0.000000     0.000000\n",
      "max         32.000000        45.000000     5.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('Calculating rolling window features...')\n",
    "\n",
    "def count_recent_exposures_optimized(panel_df, exposure_df, window_days):\n",
    "    \"\"\"\n",
    "    Count exposures in recent window - optimized version\n",
    "    \"\"\"\n",
    "    window_seconds = window_days * 24 * 3600\n",
    "    results = []\n",
    "    \n",
    "    for (user_id, vendor_id), panel_group in tqdm(\n",
    "        panel_df.groupby(['user_id', 'vendor_id']),\n",
    "        desc=f'Rolling {window_days}d'\n",
    "    ):\n",
    "        # Get exposures for this user-vendor\n",
    "        user_vendor_exp = exposure_df[\n",
    "            (exposure_df['user_id'] == user_id) &\n",
    "            (exposure_df['vendor_id'] == vendor_id)\n",
    "        ].sort_values('timestamp')\n",
    "        \n",
    "        if len(user_vendor_exp) == 0:\n",
    "            results.extend([0] * len(panel_group))\n",
    "            continue\n",
    "        \n",
    "        exposure_times = user_vendor_exp['timestamp'].values\n",
    "        \n",
    "        counts = []\n",
    "        for panel_time in panel_group['timestamp'].values:\n",
    "            # Count exposures in window\n",
    "            time_diffs_seconds = (panel_time - exposure_times).astype('timedelta64[s]').astype(float)\n",
    "            \n",
    "            # Count exposures within window (past exposures only)\n",
    "            in_window = (time_diffs_seconds > 0) & (time_diffs_seconds <= window_seconds)\n",
    "            counts.append(np.sum(in_window))\n",
    "        \n",
    "        results.extend(counts)\n",
    "    \n",
    "    return pd.Series(results, index=panel_df.index)\n",
    "\n",
    "# Calculate rolling windows\n",
    "panel['impressions_7d'] = count_recent_exposures_optimized(panel, impressions, 7)\n",
    "panel['impressions_14d'] = count_recent_exposures_optimized(panel, impressions, 14)\n",
    "panel['clicks_7d'] = count_recent_exposures_optimized(panel, clicks, 7)\n",
    "\n",
    "print('Rolling window features calculated')\n",
    "print(panel[['impressions_7d', 'impressions_14d', 'clicks_7d']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Final Panel Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "NETFLIX PANEL SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Panel Structure:\n",
      "  Total observations: 2,669\n",
      "  Positives: 157\n",
      "  Negatives: 2,355\n",
      "  Double-negatives: 157\n",
      "\n",
      "Fixed Effects:\n",
      "  Users: 816\n",
      "  Vendors: 2,406\n",
      "  Weeks: 26\n",
      "\n",
      "Outcome Variable:\n",
      "  Conversions: 157\n",
      "  Total GMV (positive samples only): $505,900.00\n",
      "  Weighted conversion rate: 0.000001\n",
      "\n",
      "Feature Summary:\n",
      "  Ad stock features: 12\n",
      "  Event stock features: 2\n",
      "  Time controls: 6\n",
      "  Rolling window features: 3\n",
      "  Diminishing returns features: 2\n",
      "\n",
      "Key Statistics:\n",
      "       adstock_imp_1day  adstock_click_1day  auction_stock_6hr           gmv\n",
      "count      2.669000e+03         2669.000000       2.669000e+03   2669.000000\n",
      "mean       2.978965e-01            0.177854       3.943215e+00    379.093293\n",
      "std        1.520682e+00            0.584582       1.023454e+01   1566.977128\n",
      "min        0.000000e+00            0.000000       0.000000e+00      0.000000\n",
      "25%        0.000000e+00            0.000000       6.431615e-13      0.000000\n",
      "50%        7.612156e-35            0.000000       4.112866e-02      0.000000\n",
      "75%        1.776555e-08            0.000000       2.558479e+00      0.000000\n",
      "max        3.010593e+01            4.989823       1.047098e+02  30000.000000\n",
      "\n",
      "Sample of panel data:\n",
      "                                     user_id  \\\n",
      "0  ext1:00822e12-3c02-4a0d-b51d-8ce7d741f2ee   \n",
      "1  ext1:00822e12-3c02-4a0d-b51d-8ce7d741f2ee   \n",
      "2  ext1:0129a983-5319-40f8-995c-6b1f04bd47b9   \n",
      "3  ext1:025b349c-2be7-4e78-964c-ab1280c541ad   \n",
      "4  ext1:025b349c-2be7-4e78-964c-ab1280c541ad   \n",
      "5  ext1:025b349c-2be7-4e78-964c-ab1280c541ad   \n",
      "6  ext1:025b349c-2be7-4e78-964c-ab1280c541ad   \n",
      "7  ext1:025b349c-2be7-4e78-964c-ab1280c541ad   \n",
      "8  ext1:025b349c-2be7-4e78-964c-ab1280c541ad   \n",
      "9  ext1:025b349c-2be7-4e78-964c-ab1280c541ad   \n",
      "\n",
      "                          vendor_id                     timestamp  outcome  \\\n",
      "0  0193a89673777fd3b8125a1acb60fe5d 2025-09-09 23:23:15.019691598        0   \n",
      "1  01974e7ce2f07bd1ae62253a0691bd77 2025-05-09 20:35:50.632705566        0   \n",
      "2  0195cae3350a7bd39cfe58bd8101f459 2025-05-23 07:35:35.118527995        0   \n",
      "3  01902bea787074b4b78660e8ea8366b5 2025-07-17 22:21:05.594534721        0   \n",
      "4  0190895e3db070c6a992fc8451aacbb5 2025-07-29 06:46:09.366978889        0   \n",
      "5  01908dc74eca7f92bb55c87e6b4a621f 2025-03-31 08:22:45.290022752        0   \n",
      "6  019273f7cad274008670a3d2aa6d9e96 2025-07-13 19:48:08.878422190        0   \n",
      "7  01938ebe84f472e1b6b2595ccba4b7ce 2025-08-08 18:36:00.583289804        0   \n",
      "8  0194226486947460acd29ee2471a5cee 2025-06-18 00:32:08.660630055        0   \n",
      "9  01942e3e732a7ac18c5d5dd11b426d14 2025-07-19 05:34:34.852830423        0   \n",
      "\n",
      "  sample_type  adstock_imp_1day  adstock_click_1hr  sample_weight  gmv  \n",
      "0    negative      1.112929e-27                0.0   45531.519321  0.0  \n",
      "1    negative      0.000000e+00                0.0   45531.519321  0.0  \n",
      "2    negative      0.000000e+00                0.0   45531.519321  0.0  \n",
      "3    negative      3.156856e-17                0.0   45531.519321  0.0  \n",
      "4    negative      3.653721e-26                0.0   45531.519321  0.0  \n",
      "5    negative      0.000000e+00                0.0   45531.519321  0.0  \n",
      "6    negative      0.000000e+00                0.0   45531.519321  0.0  \n",
      "7    negative      0.000000e+00                0.0   45531.519321  0.0  \n",
      "8    negative      4.151796e-20                0.0   45531.519321  0.0  \n",
      "9    negative      3.888358e-23                0.0   45531.519321  0.0  \n"
     ]
    }
   ],
   "source": [
    "print('='*80)\n",
    "print('NETFLIX PANEL SUMMARY')\n",
    "print('='*80)\n",
    "\n",
    "print(f'\\nPanel Structure:')\n",
    "print(f'  Total observations: {len(panel):,}')\n",
    "print(f'  Positives: {(panel[\"sample_type\"] == \"positive\").sum():,}')\n",
    "print(f'  Negatives: {(panel[\"sample_type\"] == \"negative\").sum():,}')\n",
    "print(f'  Double-negatives: {(panel[\"sample_type\"] == \"double_negative\").sum():,}')\n",
    "\n",
    "print(f'\\nFixed Effects:')\n",
    "print(f'  Users: {panel[\"user_id\"].nunique():,}')\n",
    "print(f'  Vendors: {panel[\"vendor_id\"].nunique():,}')\n",
    "print(f'  Weeks: {panel[\"week_id\"].nunique():,}')\n",
    "\n",
    "print(f'\\nOutcome Variable:')\n",
    "print(f'  Conversions: {panel[\"outcome\"].sum():,}')\n",
    "print(f'  Total GMV (positive samples only): ${panel[panel.sample_type == \"positive\"][\"gmv\"].sum():,.2f}')\n",
    "print(f'  Weighted conversion rate: {(panel[\"outcome\"] * panel[\"sample_weight\"]).sum() / panel[\"sample_weight\"].sum():.6f}')\n",
    "\n",
    "print(f'\\nFeature Summary:')\n",
    "ad_stock_cols = [col for col in panel.columns if col.startswith('adstock_')]\n",
    "print(f'  Ad stock features: {len(ad_stock_cols)}')\n",
    "print(f'  Event stock features: 2')\n",
    "print(f'  Time controls: 6')\n",
    "print(f'  Rolling window features: 3')\n",
    "print(f'  Diminishing returns features: 2')\n",
    "\n",
    "print(f'\\nKey Statistics:')\n",
    "print(panel[['adstock_imp_1day', 'adstock_click_1day', 'auction_stock_6hr', 'gmv']].describe())\n",
    "\n",
    "print(f'\\nSample of panel data:')\n",
    "display_cols = ['user_id', 'vendor_id', 'timestamp', 'outcome', 'sample_type', \n",
    "                'adstock_imp_1day', 'adstock_click_1hr', 'sample_weight', 'gmv']\n",
    "print(panel[display_cols].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Save Panel Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Panel saved to data/netflix_panel.parquet\n",
      "File size: 0.27 MB\n",
      "\n",
      "This panel is ready for three-way fixed effects estimation using pyfixest.\n"
     ]
    }
   ],
   "source": [
    "# Save to parquet\n",
    "output_path = 'data/netflix_panel.parquet'\n",
    "panel.to_parquet(output_path, index=False)\n",
    "\n",
    "import os\n",
    "file_size_mb = os.path.getsize(output_path) / (1024**2)\n",
    "\n",
    "print(f'\\nPanel saved to {output_path}')\n",
    "print(f'File size: {file_size_mb:.2f} MB')\n",
    "print(f'\\nThis panel is ready for three-way fixed effects estimation using pyfixest.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}