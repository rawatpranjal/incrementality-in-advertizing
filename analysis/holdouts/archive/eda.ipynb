{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dd9afc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connection to Snowflake successful!\n",
      "   Snowflake version: 9.29.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import snowflake.connector\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "# This command looks for the .env file in the same directory as your notebook\n",
    "load_dotenv()\n",
    "\n",
    "# --- Snowflake Connection Block ---\n",
    "conn = None  # Initialize conn to None\n",
    "try:\n",
    "    # Establish the connection using credentials from the .env file\n",
    "    conn = snowflake.connector.connect(\n",
    "        user=os.getenv('SNOWFLAKE_USER'),\n",
    "        password=os.getenv('SNOWFLAKE_PASSWORD'),\n",
    "        account=os.getenv('SNOWFLAKE_ACCOUNT'),\n",
    "        warehouse=os.getenv('SNOWFLAKE_WAREHOUSE'),\n",
    "        database='INCREMENTALITY',\n",
    "        schema='INCREMENTALITY_RESEARCH'\n",
    "    )\n",
    "    print(\"✅ Connection to Snowflake successful!\")\n",
    "\n",
    "    # Optional: Verify the connection with a simple query\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT CURRENT_VERSION()\")\n",
    "    one_row = cursor.fetchone()\n",
    "    print(f\"   Snowflake version: {one_row[0]}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ ERROR: Could not connect to Snowflake.\", file=sys.stderr)\n",
    "    print(f\"   Please check your credentials in the .env file and network connection.\", file=sys.stderr)\n",
    "    print(f\"   Details: {e}\", file=sys.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae93e2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running LATE Sensitivity Analysis for Different Holdout Probabilities ---\n",
      "\n",
      "✅ Query successful. Observable counts retrieved:\n",
      "   - N1 (Exposed Count): 738,417\n",
      "   - y11 (Exposed Purchases): 69,314\n",
      "   - d11 (Exposed Clicks): 270,925\n",
      "   - n01 (Holdout Purchases): 22,550\n",
      "\n",
      "================================================================================\n",
      "    LATE Sensitivity Analysis with Reconstructed Control Group\n",
      "================================================================================\n",
      "\n",
      "This table shows how the LATE estimate changes based on the assumed\n",
      "randomization probability for the holdout group (π₀).\n",
      "\n",
      "Constant Rates (Unaffected by π₀):\n",
      "  - a (Purchase Rate | Z=1): 9.3868%\n",
      "  - c (Click Rate | Z=1):    36.6900%\n",
      "\n",
      "+--------------------------+--------------------------+----------------------------------+-----------------+\n",
      "| Assumed π₀ (Holdout %)   | Est. N₀ (Control Size)   | Est. b̂ (Control Purchase Rate)   | LATE Estimate   |\n",
      "+==========================+==========================+==================================+=================+\n",
      "| 1%                       | 7,459                    | 302.33%                          | -798.43%        |\n",
      "+--------------------------+--------------------------+----------------------------------+-----------------+\n",
      "| 2%                       | 15,070                   | 149.64%                          | -382.26%        |\n",
      "+--------------------------+--------------------------+----------------------------------+-----------------+\n",
      "| 3%                       | 22,838                   | 98.74%                           | -243.54%        |\n",
      "+--------------------------+--------------------------+----------------------------------+-----------------+\n",
      "| 4%                       | 30,767                   | 73.29%                           | -174.18%        |\n",
      "+--------------------------+--------------------------+----------------------------------+-----------------+\n",
      "| 5%                       | 38,864                   | 58.02%                           | -132.56%        |\n",
      "+--------------------------+--------------------------+----------------------------------+-----------------+\n",
      "| 6%                       | 47,133                   | 47.84%                           | -104.81%        |\n",
      "+--------------------------+--------------------------+----------------------------------+-----------------+\n",
      "| 7%                       | 55,580                   | 40.57%                           | -85.00%         |\n",
      "+--------------------------+--------------------------+----------------------------------+-----------------+\n",
      "| 8%                       | 64,210                   | 35.12%                           | -70.13%         |\n",
      "+--------------------------+--------------------------+----------------------------------+-----------------+\n",
      "| 9%                       | 73,030                   | 30.88%                           | -58.57%         |\n",
      "+--------------------------+--------------------------+----------------------------------+-----------------+\n",
      "| 10%                      | 82,046                   | 27.48%                           | -49.33%         |\n",
      "+--------------------------+--------------------------+----------------------------------+-----------------+\n",
      "\n",
      "Interpretation:\n",
      "The LATE estimate remains strongly negative across all plausible holdout probabilities.\n",
      "This confirms the result is not an artifact of assuming π₀=5%, but is due to\n",
      "a fundamental selection bias: the holdout purchasers (n01) are a fundamentally\n",
      "different, higher-converting group than the general population (N1).\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "# Suppress the UserWarning for cleaner output\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"pandas only supports SQLAlchemy connectable.*\",\n",
    "    category=UserWarning,\n",
    ")\n",
    "\n",
    "# --- 1. Configuration ---\n",
    "ANALYSIS_START_DATE = '2025-08-20'\n",
    "ANALYSIS_END_DATE = '2025-08-21'\n",
    "\n",
    "# --- 2. SQL Query to Get Raw Counts (Unchanged) ---\n",
    "# This query is designed for maximum efficiency.\n",
    "counts_query = f\"\"\"\n",
    "WITH\n",
    "-- CTE 1: Identify the groups of users within the period\n",
    "impressed_users AS (\n",
    "    SELECT DISTINCT USER_ID FROM IMPRESSIONS\n",
    "    WHERE OCCURRED_AT BETWEEN '{ANALYSIS_START_DATE}' AND '{ANALYSIS_END_DATE}'\n",
    "),\n",
    "clicked_users AS (\n",
    "    SELECT DISTINCT USER_ID FROM CLICKS\n",
    "    WHERE OCCURRED_AT BETWEEN '{ANALYSIS_START_DATE}' AND '{ANALYSIS_END_DATE}'\n",
    "),\n",
    "purchasers AS (\n",
    "    SELECT DISTINCT USER_ID FROM PURCHASES\n",
    "    WHERE PURCHASED_AT BETWEEN '{ANALYSIS_START_DATE}' AND '{ANALYSIS_END_DATE}'\n",
    ")\n",
    "-- Final Aggregation: We only need counts related to Z=1 and the single n01 count\n",
    "SELECT\n",
    "    (SELECT COUNT(DISTINCT USER_ID) FROM impressed_users) AS N1,\n",
    "    (SELECT COUNT(DISTINCT USER_ID) FROM impressed_users WHERE USER_ID IN (SELECT USER_ID FROM purchasers)) AS y11,\n",
    "    (SELECT COUNT(DISTINCT USER_ID) FROM impressed_users WHERE USER_ID IN (SELECT USER_ID FROM clicked_users)) AS d11,\n",
    "    (SELECT COUNT(DISTINCT USER_ID) FROM purchasers WHERE USER_ID NOT IN (SELECT USER_ID FROM impressed_users)) AS n01\n",
    "\"\"\"\n",
    "\n",
    "# --- 3. Execute Query and Run Sensitivity Analysis ---\n",
    "if conn:\n",
    "    print(\"--- Running LATE Sensitivity Analysis for Different Holdout Probabilities ---\")\n",
    "    try:\n",
    "        df_counts = pd.read_sql(counts_query, conn)\n",
    "        counts = df_counts.iloc[0]\n",
    "        \n",
    "        N1 = counts['N1']\n",
    "        y11 = counts['Y11']\n",
    "        d11 = counts['D11']\n",
    "        n01 = counts['N01']\n",
    "        \n",
    "        print(\"\\n✅ Query successful. Observable counts retrieved:\")\n",
    "        print(f\"   - N1 (Exposed Count): {N1:,.0f}\")\n",
    "        print(f\"   - y11 (Exposed Purchases): {y11:,.0f}\")\n",
    "        print(f\"   - d11 (Exposed Clicks): {d11:,.0f}\")\n",
    "        print(f\"   - n01 (Holdout Purchases): {n01:,.0f}\")\n",
    "        \n",
    "        if N1 == 0 or d11 == 0:\n",
    "            raise ValueError(\"No treated users or no clicks in the treatment group. Cannot calculate LATE.\")\n",
    "\n",
    "        # Pre-calculate constant rates for the loop\n",
    "        a = y11 / N1\n",
    "        c = d11 / N1\n",
    "\n",
    "        # --- 4. Loop Through Different Values of π₀ ---\n",
    "        sensitivity_results = []\n",
    "        \n",
    "        # Define the range of holdout probabilities to test (1% to 10%)\n",
    "        holdout_probabilities = np.arange(0.01, 0.11, 0.01)\n",
    "\n",
    "        for pi_0 in holdout_probabilities:\n",
    "            pi_1 = 1 - pi_0\n",
    "            \n",
    "            # Calculate N₀ and b̂ for the current pi_0\n",
    "            N0 = (pi_0 / pi_1) * N1\n",
    "            b_hat = n01 / N0 if N0 > 0 else 0\n",
    "            \n",
    "            # Calculate the LATE estimate\n",
    "            LATE_estimate = (a - b_hat) / c\n",
    "            \n",
    "            sensitivity_results.append({\n",
    "                \"Assumed π₀ (Holdout %)\": f\"{pi_0:.0%}\",\n",
    "                \"Est. N₀ (Control Size)\": f\"{N0:,.0f}\",\n",
    "                \"Est. b̂ (Control Purchase Rate)\": f\"{b_hat:.2%}\",\n",
    "                \"LATE Estimate\": f\"{LATE_estimate:+.2%}\"\n",
    "            })\n",
    "\n",
    "        # --- 5. Generate Final Report ---\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"    LATE Sensitivity Analysis with Reconstructed Control Group\")\n",
    "        print(\"=\"*80)\n",
    "        print(\"\\nThis table shows how the LATE estimate changes based on the assumed\")\n",
    "        print(\"randomization probability for the holdout group (π₀).\\n\")\n",
    "\n",
    "        print(\"Constant Rates (Unaffected by π₀):\")\n",
    "        print(f\"  - a (Purchase Rate | Z=1): {a:.4%}\")\n",
    "        print(f\"  - c (Click Rate | Z=1):    {c:.4%}\\n\")\n",
    "\n",
    "        # Display the results in a clean table\n",
    "        results_df = pd.DataFrame(sensitivity_results)\n",
    "        print(tabulate(results_df, headers='keys', tablefmt='grid', showindex=False))\n",
    "\n",
    "        print(\"\\nInterpretation:\")\n",
    "        print(\"The LATE estimate remains strongly negative across all plausible holdout probabilities.\")\n",
    "        print(\"This confirms the result is not an artifact of assuming π₀=5%, but is due to\")\n",
    "        print(\"a fundamental selection bias: the holdout purchasers (n01) are a fundamentally\")\n",
    "        print(\"different, higher-converting group than the general population (N1).\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ ERROR executing analysis: {e}\")\n",
    "else:\n",
    "    print(\"❌ Snowflake connection ('conn') not found. Please run the connection cell first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c22bf0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "             Method of Moments Diagnosis of Causal Model\n",
      "================================================================================\n",
      "\n",
      "1. Empirical Moments (Observed Data):\n",
      "+-------------------------------------+------------------+\n",
      "| Moment                              | Observed Value   |\n",
      "+=====================================+==================+\n",
      "| Compliance Rate in Treatment (m_D1) | 36.6900%         |\n",
      "+-------------------------------------+------------------+\n",
      "| Purchase Rate in Control (m_Y0)     | 58.0228%         |\n",
      "+-------------------------------------+------------------+\n",
      "| Purchase Rate in Treatment (m_Y1)   | 9.3868%          |\n",
      "+-------------------------------------+------------------+\n",
      "\n",
      "2. Best-Fit Causal Parameters (Method of Moments Solution):\n",
      "+-------------------------------------+------------+--------------------------------------------+\n",
      "| Parameter                           | Value      | Derivation                                 |\n",
      "+=====================================+============+============================================+\n",
      "| b̂ (Best-fit Compliance Rate)        | 36.6900%   | Matches m_D1 exactly.                      |\n",
      "+-------------------------------------+------------+--------------------------------------------+\n",
      "| ĉ (Best-fit Baseline Purchase Rate) | 58.0228%   | Matches m_Y0 exactly.                      |\n",
      "+-------------------------------------+------------+--------------------------------------------+\n",
      "| d̂ (Best-fit Incrementality / LATE)  | -132.5594% | Calculated to reconcile the other moments. |\n",
      "+-------------------------------------+------------+--------------------------------------------+\n",
      "\n",
      "3. Diagnosis: The Contradiction\n",
      "The Method of Moments reveals a fundamental contradiction in the data,\n",
      "proving that a single causal model cannot explain the behavior of both groups:\n",
      "\n",
      "╒═══════════════════╤════════════════════════════════════════════════════════════════════════════════════════════╕\n",
      "│ The Problem       │ To match the observed holdout purchasers, the model's baseline purchase rate (`ĉ`) must be │\n",
      "│                   │ an incredibly high **58.02%**.                                                             │\n",
      "├───────────────────┼────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ The Consequence   │ However, the observed purchase rate for the entire treatment group (`m_Y1`) is only        │\n",
      "│                   │ **9.40%**.                                                                                 │\n",
      "├───────────────────┼────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ The Impossibility │ It is mathematically impossible for a click to have a negative enough effect (`d̂` =        │\n",
      "│                   │ -132.56%) to drag a 58.02% baseline down to 9.40%. A purchase rate cannot be negative.     │\n",
      "├───────────────────┼────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ The Conclusion    │ The model fails because the assumption of a single baseline rate (`c`) for both groups is  │\n",
      "│                   │ false. The control group (`Z=0`) and treatment group (`Z=1`) are two different populations │\n",
      "│                   │ with two different baseline purchase rates, proving severe selection bias.                 │\n",
      "╘═══════════════════╧════════════════════════════════════════════════════════════════════════════════════════════╛\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Observed Data (The Ground Truth) ---\n",
    "OBSERVED_COUNTS = {\n",
    "    'N1': 738417,\n",
    "    'N0_est': 38864, # Estimated from N1 * (0.05 / 0.95)\n",
    "    'y11': 69314,   # count(Z=1, Y=1)\n",
    "    'd11': 270925,  # count(Z=1, D=1)\n",
    "    'n01': 22550   # count(Z=0, Y=1)\n",
    "}\n",
    "\n",
    "# --- 2. Calculate Empirical Moments (m_D1, m_Y0, m_Y1) ---\n",
    "m_D1 = OBSERVED_COUNTS['d11'] / OBSERVED_COUNTS['N1']\n",
    "m_Y0 = OBSERVED_COUNTS['n01'] / OBSERVED_COUNTS['N0_est']\n",
    "m_Y1 = OBSERVED_COUNTS['y11'] / OBSERVED_COUNTS['N1']\n",
    "\n",
    "# --- 3. Solve for Best-Fit Parameters (b_hat, c_hat, d_hat) ---\n",
    "# This is the analytical solution from the Method of Moments objective function.\n",
    "b_hat = m_D1\n",
    "c_hat = m_Y0\n",
    "d_hat = (m_Y1 - c_hat) / b_hat if b_hat > 0 else 0\n",
    "\n",
    "# --- 4. Diagnosis and Report ---\n",
    "print(\"=\"*80)\n",
    "print(\"             Method of Moments Diagnosis of Causal Model\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. Empirical Moments (Observed Data):\")\n",
    "moments_data = [\n",
    "    [\"Compliance Rate in Treatment (m_D1)\", f\"{m_D1:.4%}\"],\n",
    "    [\"Purchase Rate in Control (m_Y0)\", f\"{m_Y0:.4%}\"],\n",
    "    [\"Purchase Rate in Treatment (m_Y1)\", f\"{m_Y1:.4%}\"]\n",
    "]\n",
    "print(tabulate(moments_data, headers=[\"Moment\", \"Observed Value\"], tablefmt=\"grid\"))\n",
    "\n",
    "print(\"\\n2. Best-Fit Causal Parameters (Method of Moments Solution):\")\n",
    "params_data = [\n",
    "    [\"b̂ (Best-fit Compliance Rate)\", f\"{b_hat:.4%}\", \"Matches m_D1 exactly.\"],\n",
    "    [\"ĉ (Best-fit Baseline Purchase Rate)\", f\"{c_hat:.4%}\", \"Matches m_Y0 exactly.\"],\n",
    "    [\"d̂ (Best-fit Incrementality / LATE)\", f\"{d_hat:.4%}\", \"Calculated to reconcile the other moments.\"]\n",
    "]\n",
    "print(tabulate(params_data, headers=[\"Parameter\", \"Value\", \"Derivation\"], tablefmt=\"grid\"))\n",
    "\n",
    "print(\"\\n3. Diagnosis: The Contradiction\")\n",
    "print(\"The Method of Moments reveals a fundamental contradiction in the data,\")\n",
    "print(\"proving that a single causal model cannot explain the behavior of both groups:\\n\")\n",
    "\n",
    "# The contradiction is that a baseline purchase rate this high is nonsensical for the general population.\n",
    "contradiction_table = [\n",
    "    [\"The Problem\", \"To match the observed holdout purchasers, the model's baseline purchase rate (`ĉ`) must be an incredibly high **58.02%**.\"],\n",
    "    [\"The Consequence\", \"However, the observed purchase rate for the entire treatment group (`m_Y1`) is only **9.40%**.\"],\n",
    "    [\"The Impossibility\", \"It is mathematically impossible for a click to have a negative enough effect (`d̂` = -132.56%) to drag a 58.02% baseline down to 9.40%. A purchase rate cannot be negative.\"],\n",
    "    [\"The Conclusion\", \"The model fails because the assumption of a single baseline rate (`c`) for both groups is false. The control group (`Z=0`) and treatment group (`Z=1`) are two different populations with two different baseline purchase rates, proving severe selection bias.\"]\n",
    "]\n",
    "print(tabulate(contradiction_table, tablefmt=\"fancy_grid\", maxcolwidths=[17, 90]))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6f013c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
