{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02_focused_itt_analysis.ipynb: Intent-to-Treat Effects via 97-3 Natural Experiment\n",
    "\n",
    "## Estimands\n",
    "1. **User-level ITT on purchase probability** in window [S, E)\n",
    "2. **User-level ITT on revenue per user** in the same window\n",
    "\n",
    "## Method\n",
    "- Uses only `AUCTIONS_USERS` and `PURCHASES` tables\n",
    "- Reconstructs control group size using 97-3 split on active users\n",
    "- Implements exact mathematical estimator with proper diagnostics\n",
    "\n",
    "## Key Innovation\n",
    "3% of users are randomly blocked from ads, providing a clean control group. We observe their purchases but not their browsing activity, requiring reconstruction of the denominator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "INTENT-TO-TREAT ANALYSIS USING MINIMAL DATA\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "import snowflake.connector\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"INTENT-TO-TREAT ANALYSIS USING MINIMAL DATA\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis window: [2025-08-01, 2025-09-01)\n",
      "Lookback: 30 days\n",
      "Population split: 97% / 3%\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "ANALYSIS_START = '2025-08-01'  # S\n",
    "ANALYSIS_END = '2025-09-01'    # E\n",
    "LOOKBACK_DAYS = 30              # L\n",
    "\n",
    "# Known split from platform design\n",
    "TREATMENT_PROP = 0.97\n",
    "CONTROL_PROP = 0.03\n",
    "\n",
    "print(f\"Analysis window: [{ANALYSIS_START}, {ANALYSIS_END})\")\n",
    "print(f\"Lookback: {LOOKBACK_DAYS} days\")\n",
    "print(f\"Population split: {TREATMENT_PROP:.0%} / {CONTROL_PROP:.0%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connected to Snowflake\n"
     ]
    }
   ],
   "source": [
    "# Snowflake connection\n",
    "try:\n",
    "    conn = snowflake.connector.connect(\n",
    "        user=os.getenv('SNOWFLAKE_USER'),\n",
    "        password=os.getenv('SNOWFLAKE_PASSWORD'),\n",
    "        account=os.getenv('SNOWFLAKE_ACCOUNT'),\n",
    "        warehouse=os.getenv('SNOWFLAKE_WAREHOUSE', 'COMPUTE_WH'),\n",
    "        database='INCREMENTALITY',\n",
    "        schema='INCREMENTALITY_RESEARCH'\n",
    "    )\n",
    "    print(\"✅ Connected to Snowflake\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Connection failed: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Core ITT Estimator\n",
    "\n",
    "### Mathematical Framework\n",
    "\n",
    "**Observed quantities:**\n",
    "- Observed_T = count(distinct users in AUCTIONS_USERS during [S-L, E))\n",
    "- T_p = treatment users who purchased in [S, E)\n",
    "- C_p = control users who purchased in [S, E)\n",
    "\n",
    "**Reconstruction:**\n",
    "- Observed_Ĉ = Observed_T × (0.03/0.97)\n",
    "- C_np̂ = Observed_Ĉ - C_p\n",
    "\n",
    "**ITT Effects:**\n",
    "- Rate_T = T_p / Observed_T\n",
    "- Rate_Ĉ = C_p / Observed_Ĉ\n",
    "- ITT_lift = Rate_T - Rate_Ĉ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running main ITT analysis...\n"
     ]
    }
   ],
   "source": [
    "def calculate_itt(conn, start_date, end_date, lookback_days):\n",
    "    \"\"\"\n",
    "    Calculate Intent-to-Treat effect on purchase probability.\n",
    "    Returns all counts and rates in a single query.\n",
    "    \"\"\"\n",
    "    \n",
    "    lookback_start = pd.to_datetime(start_date) - timedelta(days=lookback_days)\n",
    "    lookback_start_str = lookback_start.strftime('%Y-%m-%d')\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    WITH au AS (\n",
    "        -- Treatment group: users exposed to ads\n",
    "        SELECT DISTINCT OPAQUE_USER_ID AS user_id\n",
    "        FROM AUCTIONS_USERS\n",
    "        WHERE CREATED_AT >= '{lookback_start_str}'\n",
    "          AND CREATED_AT < '{end_date}'\n",
    "    ),\n",
    "    pu AS (\n",
    "        -- All purchasers in analysis window\n",
    "        SELECT DISTINCT USER_ID AS user_id\n",
    "        FROM PURCHASES\n",
    "        WHERE PURCHASED_AT >= '{start_date}'\n",
    "          AND PURCHASED_AT < '{end_date}'\n",
    "    ),\n",
    "    -- Calculate counts\n",
    "    t_obs AS (SELECT COUNT(*) AS observed_t FROM au),\n",
    "    t_p AS (\n",
    "        SELECT COUNT(*) AS t_p\n",
    "        FROM pu WHERE user_id IN (SELECT user_id FROM au)\n",
    "    ),\n",
    "    c_p AS (\n",
    "        SELECT COUNT(*) AS c_p\n",
    "        FROM pu WHERE user_id NOT IN (SELECT user_id FROM au)\n",
    "    )\n",
    "    \n",
    "    SELECT\n",
    "        -- Observed counts\n",
    "        t_obs.observed_t AS observed_t,\n",
    "        t_p.t_p AS t_p,\n",
    "        (t_obs.observed_t - t_p.t_p) AS t_np,\n",
    "        c_p.c_p AS c_p,\n",
    "        \n",
    "        -- Reconstructed control\n",
    "        ROUND(t_obs.observed_t * {CONTROL_PROP}/{TREATMENT_PROP}) AS observed_c_hat,\n",
    "        ROUND(t_obs.observed_t * {CONTROL_PROP}/{TREATMENT_PROP} - c_p.c_p) AS c_np_hat,\n",
    "        \n",
    "        -- Rates\n",
    "        (t_p.t_p / NULLIF(t_obs.observed_t, 0)) AS rate_t,\n",
    "        (c_p.c_p / NULLIF(t_obs.observed_t * {CONTROL_PROP}/{TREATMENT_PROP}, 0)) AS rate_c_hat,\n",
    "        \n",
    "        -- ITT lift\n",
    "        ((t_p.t_p / NULLIF(t_obs.observed_t, 0)) - \n",
    "         (c_p.c_p / NULLIF(t_obs.observed_t * {CONTROL_PROP}/{TREATMENT_PROP}, 0))) AS itt_lift,\n",
    "        \n",
    "        -- Relative lift\n",
    "        CASE WHEN c_p.c_p > 0 THEN\n",
    "            (((t_p.t_p / NULLIF(t_obs.observed_t, 0)) - \n",
    "              (c_p.c_p / NULLIF(t_obs.observed_t * {CONTROL_PROP}/{TREATMENT_PROP}, 0))) /\n",
    "             (c_p.c_p / NULLIF(t_obs.observed_t * {CONTROL_PROP}/{TREATMENT_PROP}, 0))) * 100\n",
    "        ELSE NULL END AS relative_lift_pct\n",
    "        \n",
    "    FROM t_obs \n",
    "    CROSS JOIN t_p \n",
    "    CROSS JOIN c_p\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_sql(query, conn)\n",
    "    return df.iloc[0].to_dict()\n",
    "\n",
    "# Run main analysis\n",
    "print(\"\\nRunning main ITT analysis...\")\n",
    "results = calculate_itt(conn, ANALYSIS_START, ANALYSIS_END, LOOKBACK_DAYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DIAGNOSTIC CHECKS\n",
      "================================================================================\n",
      "\n",
      "1. Feasibility Check: C_p (0) ≤ Observed_Ĉ (311,238)\n",
      "   Status: ✅ PASS\n",
      "\n",
      "2. Rate Bounds:\n",
      "   Treatment rate: 0.1392 (must be in [0,1])\n",
      "   Control rate:   0.0000 (must be in [0,1])\n",
      "   Status: ✅ PASS\n"
     ]
    }
   ],
   "source": [
    "# Display results and run diagnostics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DIAGNOSTIC CHECKS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Critical feasibility check\n",
    "feasible = results['C_P'] <= results['OBSERVED_C_HAT']\n",
    "print(f\"\\n1. Feasibility Check: C_p ({results['C_P']:,.0f}) ≤ Observed_Ĉ ({results['OBSERVED_C_HAT']:,.0f})\")\n",
    "print(f\"   Status: {'✅ PASS' if feasible else '❌ FAIL - Increase lookback or check data'}\")\n",
    "\n",
    "if not feasible:\n",
    "    print(\"\\n⚠️ WARNING: Control purchasers exceed estimated control population!\")\n",
    "    print(\"   This violates the 97-3 split assumption. Possible causes:\")\n",
    "    print(\"   - Lookback window too short (recently treated users misclassified)\")\n",
    "    print(\"   - User ID mismatch between tables\")\n",
    "    print(\"   - Platform split not exactly 97-3 this period\")\n",
    "    # Continue anyway for diagnostic purposes\n",
    "\n",
    "# Rate bounds check\n",
    "print(f\"\\n2. Rate Bounds:\")\n",
    "print(f\"   Treatment rate: {results['RATE_T']:.4f} (must be in [0,1])\")\n",
    "print(f\"   Control rate:   {results['RATE_C_HAT']:.4f} (must be in [0,1])\")\n",
    "rate_valid = 0 <= results['RATE_T'] <= 1 and 0 <= results['RATE_C_HAT'] <= 1\n",
    "print(f\"   Status: {'✅ PASS' if rate_valid else '❌ FAIL'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PRIMARY RESULTS\n",
      "================================================================================\n",
      "\n",
      "1. CONTINGENCY TABLE:\n",
      "----------------------------------------\n",
      "                   Purchased    Did Not Purchase    Total\n",
      "Treatment Group    1,400,423           8,662,941    10,063,364\n",
      "Control Group              0             311,238      311,238\n",
      "                   (observed)         (estimated)       (estimated)\n",
      "\n",
      "2. PURCHASE RATES:\n",
      "----------------------------------------\n",
      "Treatment:   0.1392 (13.92%)\n",
      "Control:     0.0000 (0.00%)\n",
      "\n",
      "3. INTENT-TO-TREAT EFFECT:\n",
      "----------------------------------------\n",
      "ITT Lift (pp):     13.92\n",
      "N/A\n",
      "\n",
      "Interpretation: Ads increase purchase probability by 13.92 percentage points\n"
     ]
    }
   ],
   "source": [
    "# Display main results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PRIMARY RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. CONTINGENCY TABLE:\")\n",
    "print(\"-\"*40)\n",
    "print(f\"                   Purchased    Did Not Purchase    Total\")\n",
    "print(f\"Treatment Group    {results['T_P']:>9,.0f}    {results['T_NP']:>16,.0f}    {results['OBSERVED_T']:>9,.0f}\")\n",
    "print(f\"Control Group      {results['C_P']:>9,.0f}    {results['C_NP_HAT']:>16,.0f}    {results['OBSERVED_C_HAT']:>9,.0f}\")\n",
    "print(f\"                   (observed)         (estimated)       (estimated)\")\n",
    "\n",
    "print(\"\\n2. PURCHASE RATES:\")\n",
    "print(\"-\"*40)\n",
    "print(f\"Treatment:   {results['RATE_T']:.4f} ({results['RATE_T']*100:.2f}%)\")\n",
    "print(f\"Control:     {results['RATE_C_HAT']:.4f} ({results['RATE_C_HAT']*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n3. INTENT-TO-TREAT EFFECT:\")\n",
    "print(\"-\"*40)\n",
    "print(f\"ITT Lift (pp):     {results['ITT_LIFT']*100:.2f}\")\n",
    "print(f\"Relative Lift:     {results['RELATIVE_LIFT_PCT']:.1f}%\" if results['RELATIVE_LIFT_PCT'] else \"N/A\")\n",
    "\n",
    "print(f\"\\nInterpretation: Ads increase purchase probability by {results['ITT_LIFT']*100:.2f} percentage points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Lookback Window Analysis\n",
    "\n",
    "Plot ATE vs L ∈ {0, 7, 14, 30, 45, 60} to find where it stabilizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "LOOKBACK WINDOW ANALYSIS\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing lookback windows: 100%|██████████| 6/6 [03:04<00:00, 30.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lookback | ITT Lift (pp) | Feasible | C_p    | Obs_Ĉ\n",
      "------------------------------------------------------------\n",
      "       0 |        19.395 |    ✓     |      0 |  222,653\n",
      "       7 |        17.452 |    ✓     |      0 |  247,764\n",
      "      14 |        16.032 |    ✓     |      0 |  269,885\n",
      "      30 |        13.916 |    ✓     |      0 |  311,238\n",
      "      45 |        12.612 |    ✓     |      0 |  343,670\n",
      "      60 |        11.633 |    ✓     |      0 |  372,862\n",
      "\n",
      "✓ Recommended lookback: 7 days (first feasible with stable ITT)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test different lookback windows\n",
    "lookback_days = [0, 7, 14, 30, 45, 60]\n",
    "lookback_results = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LOOKBACK WINDOW ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for L in tqdm(lookback_days, desc=\"Testing lookback windows\"):\n",
    "    res = calculate_itt(conn, ANALYSIS_START, ANALYSIS_END, L)\n",
    "    lookback_results.append({\n",
    "        'L': L,\n",
    "        'ITT': res['ITT_LIFT'],\n",
    "        'Feasible': res['C_P'] <= res['OBSERVED_C_HAT'],\n",
    "        'C_p': res['C_P'],\n",
    "        'Observed_C': res['OBSERVED_C_HAT']\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "print(\"\\nLookback | ITT Lift (pp) | Feasible | C_p    | Obs_Ĉ\")\n",
    "print(\"-\"*60)\n",
    "for r in lookback_results:\n",
    "    print(f\"{r['L']:>8} | {r['ITT']*100:>13.3f} | {('✓' if r['Feasible'] else '✗'):^8} | \"\n",
    "          f\"{r['C_p']:>6,.0f} | {r['Observed_C']:>8,.0f}\")\n",
    "\n",
    "# Find stabilization point\n",
    "stable_idx = None\n",
    "for i in range(1, len(lookback_results)):\n",
    "    if lookback_results[i]['Feasible']:\n",
    "        if stable_idx is None:\n",
    "            stable_idx = i\n",
    "        # Check if change is < 10% relative\n",
    "        if i > 0 and abs(lookback_results[i]['ITT'] - lookback_results[i-1]['ITT']) / abs(lookback_results[i-1]['ITT']) < 0.1:\n",
    "            break\n",
    "\n",
    "if stable_idx:\n",
    "    optimal_L = lookback_results[stable_idx]['L']\n",
    "    print(f\"\\n✓ Recommended lookback: {optimal_L} days (first feasible with stable ITT)\")\n",
    "else:\n",
    "    print(\"\\n⚠️ No feasible lookback found. Check data quality.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Revenue Analysis (ARPU)\n",
    "\n",
    "Calculate Average Revenue Per User correctly:\n",
    "- ARPU_T = (Total Treatment Revenue) / Observed_T\n",
    "- ARPU_Ĉ = (Total Control Revenue) / Observed_Ĉ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating revenue ITT...\n"
     ]
    }
   ],
   "source": [
    "def calculate_revenue_itt(conn, start_date, end_date, lookback_days, winsorize_pct=99):\n",
    "    \"\"\"\n",
    "    Calculate Intent-to-Treat effect on revenue per user.\n",
    "    Fixed for Snowflake compatibility.\n",
    "    \"\"\"\n",
    "\n",
    "    lookback_start = pd.to_datetime(start_date) - timedelta(days=lookback_days)\n",
    "    lookback_start_str = lookback_start.strftime('%Y-%m-%d')\n",
    "\n",
    "    # First get treatment user count\n",
    "    query = f\"\"\"\n",
    "    WITH au AS (\n",
    "        SELECT DISTINCT OPAQUE_USER_ID AS user_id\n",
    "        FROM AUCTIONS_USERS\n",
    "        WHERE CREATED_AT >= '{lookback_start_str}'\n",
    "          AND CREATED_AT < '{end_date}'\n",
    "    ),\n",
    "    au_count AS (\n",
    "        SELECT COUNT(*) as observed_t FROM au\n",
    "    ),\n",
    "    revenue_data AS (\n",
    "        SELECT\n",
    "            p.USER_ID as user_id,\n",
    "            SUM(p.QUANTITY * p.UNIT_PRICE) as total_revenue\n",
    "        FROM PURCHASES p\n",
    "        WHERE p.PURCHASED_AT >= '{start_date}'\n",
    "          AND p.PURCHASED_AT < '{end_date}'\n",
    "        GROUP BY p.USER_ID\n",
    "    ),\n",
    "    revenue_split AS (\n",
    "        SELECT\n",
    "            r.user_id,\n",
    "            r.total_revenue,\n",
    "            CASE WHEN EXISTS (SELECT 1 FROM au WHERE au.user_id = r.user_id)\n",
    "                 THEN 'treatment'\n",
    "                 ELSE 'control'\n",
    "            END as group_type\n",
    "        FROM revenue_data r\n",
    "    )\n",
    "    SELECT\n",
    "        (SELECT observed_t FROM au_count) as observed_t,\n",
    "        COALESCE(SUM(CASE WHEN group_type = 'treatment' THEN total_revenue END), 0) as revenue_t,\n",
    "        COALESCE(SUM(CASE WHEN group_type = 'control' THEN total_revenue END), 0) as revenue_c,\n",
    "        PERCENTILE_CONT({winsorize_pct/100}) WITHIN GROUP (ORDER BY total_revenue) as p{winsorize_pct}_revenue\n",
    "    FROM revenue_split\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_sql(query, conn)\n",
    "    row = df.iloc[0]\n",
    "\n",
    "    # Calculate ARPU\n",
    "    observed_t = row['OBSERVED_T']\n",
    "    observed_c_hat = int(observed_t * (CONTROL_PROP / TREATMENT_PROP))\n",
    "\n",
    "    arpu_t = row['REVENUE_T'] / observed_t if observed_t > 0 else 0\n",
    "    arpu_c = row['REVENUE_C'] / observed_c_hat if observed_c_hat > 0 else 0\n",
    "\n",
    "    return {\n",
    "        'observed_t': observed_t,\n",
    "        'observed_c_hat': observed_c_hat,\n",
    "        'revenue_t': row['REVENUE_T'],\n",
    "        'revenue_c': row['REVENUE_C'],\n",
    "        'arpu_t': arpu_t,\n",
    "        'arpu_c': arpu_c,\n",
    "        'itt_revenue_lift': arpu_t - arpu_c,\n",
    "        'relative_revenue_lift': ((arpu_t - arpu_c) / arpu_c * 100) if arpu_c > 0 else None,\n",
    "        'p99_cap': row[f'P{winsorize_pct}_REVENUE']\n",
    "    }\n",
    "\n",
    "# Calculate revenue ITT\n",
    "print(\"\\nCalculating revenue ITT...\")\n",
    "revenue_results = calculate_revenue_itt(conn, ANALYSIS_START, ANALYSIS_END, LOOKBACK_DAYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "REVENUE ANALYSIS (ARPU)\n",
      "================================================================================\n",
      "\n",
      "1. TOTAL REVENUE:\n",
      "----------------------------------------\n",
      "Treatment total:   $16,266,808,803.00\n",
      "Control total:     $1,101,545,750.00\n",
      "\n",
      "2. DENOMINATORS (INCLUDING ZEROS):\n",
      "----------------------------------------\n",
      "Treatment users:   10,063,364.0\n",
      "Control users:          311,238 (estimated)\n",
      "\n",
      "3. AVERAGE REVENUE PER USER (ARPU):\n",
      "----------------------------------------\n",
      "ARPU_T:            $     1616.44\n",
      "ARPU_Ĉ:           $     3539.24\n",
      "\n",
      "4. ITT REVENUE EFFECT:\n",
      "----------------------------------------\n",
      "Revenue lift/user: $    -1922.80\n",
      "Relative lift:            -54.3%\n",
      "\n",
      "Interpretation: Ads increase revenue by $-1922.80 per user\n"
     ]
    }
   ],
   "source": [
    "# Display revenue results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"REVENUE ANALYSIS (ARPU)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. TOTAL REVENUE:\")\n",
    "print(\"-\"*40)\n",
    "print(f\"Treatment total:   ${revenue_results['revenue_t']:>12,.2f}\")\n",
    "print(f\"Control total:     ${revenue_results['revenue_c']:>12,.2f}\")\n",
    "\n",
    "print(\"\\n2. DENOMINATORS (INCLUDING ZEROS):\")\n",
    "print(\"-\"*40)\n",
    "print(f\"Treatment users:   {revenue_results['observed_t']:>12,}\")\n",
    "print(f\"Control users:     {revenue_results['observed_c_hat']:>12,} (estimated)\")\n",
    "\n",
    "print(\"\\n3. AVERAGE REVENUE PER USER (ARPU):\")\n",
    "print(\"-\"*40)\n",
    "print(f\"ARPU_T:            ${revenue_results['arpu_t']:>12.2f}\")\n",
    "print(f\"ARPU_Ĉ:           ${revenue_results['arpu_c']:>12.2f}\")\n",
    "\n",
    "print(\"\\n4. ITT REVENUE EFFECT:\")\n",
    "print(\"-\"*40)\n",
    "print(f\"Revenue lift/user: ${revenue_results['itt_revenue_lift']:>12.2f}\")\n",
    "if revenue_results['relative_revenue_lift']:\n",
    "    print(f\"Relative lift:     {revenue_results['relative_revenue_lift']:>12.1f}%\")\n",
    "\n",
    "print(f\"\\nInterpretation: Ads increase revenue by ${revenue_results['itt_revenue_lift']:.2f} per user\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Sensitivity to Activity Ratio\n",
    "\n",
    "Test how results change if ads affect user activity (r = activity_T / activity_C)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SENSITIVITY TO ACTIVITY RATIO\n",
      "================================================================================\n",
      "\n",
      "r = (Treatment Activity) / (Control Activity)\n",
      "r > 1 means ads increase browsing activity\n",
      "\n",
      "r     | Obs_Ĉ(r) | Rate_Ĉ(r) | ITT(r) pp | Rel Lift(r) %\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ITT bounds across r ∈ [0.9, 1.2]:\n",
      "  Minimum: 13.92 pp (r=0.9, ads decrease activity)\n",
      "  Maximum: 13.92 pp (r=1.2, ads increase activity)\n",
      "  Range:   0.00 pp\n"
     ]
    }
   ],
   "source": [
    "def sensitivity_analysis(base_results, r_values):\n",
    "    \"\"\"\n",
    "    Adjust for different activity ratios.\n",
    "    r > 1 means ads increase platform activity.\n",
    "    \"\"\"\n",
    "    sensitivity = []\n",
    "    \n",
    "    for r in r_values:\n",
    "        # Adjust control size\n",
    "        observed_t = base_results['OBSERVED_T']\n",
    "        observed_c_adj = (observed_t / r) * (CONTROL_PROP / TREATMENT_PROP)\n",
    "        \n",
    "        # Recalculate rates\n",
    "        rate_t = base_results['RATE_T']\n",
    "        rate_c_adj = base_results['C_P'] / observed_c_adj if observed_c_adj > 0 else 0\n",
    "        \n",
    "        # New ITT\n",
    "        itt_adj = rate_t - rate_c_adj\n",
    "        rel_lift_adj = (itt_adj / rate_c_adj * 100) if rate_c_adj > 0 else None\n",
    "        \n",
    "        sensitivity.append({\n",
    "            'r': r,\n",
    "            'observed_c_adj': observed_c_adj,\n",
    "            'rate_c_adj': rate_c_adj,\n",
    "            'itt_adj': itt_adj,\n",
    "            'rel_lift_adj': rel_lift_adj\n",
    "        })\n",
    "    \n",
    "    return sensitivity\n",
    "\n",
    "# Run sensitivity analysis\n",
    "r_values = [0.9, 0.95, 1.0, 1.05, 1.1, 1.15, 1.2]\n",
    "sensitivity = sensitivity_analysis(results, r_values)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SENSITIVITY TO ACTIVITY RATIO\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nr = (Treatment Activity) / (Control Activity)\")\n",
    "print(\"r > 1 means ads increase browsing activity\\n\")\n",
    "\n",
    "print(\"r     | Obs_Ĉ(r) | Rate_Ĉ(r) | ITT(r) pp | Rel Lift(r) %\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "for s in sensitivity:\n",
    "    print(f\"{s['r']:>5.2f} | {s['observed_c_adj']:>8.0f} | {s['rate_c_adj']:>9.4f} | \"\n",
    "          f\"{s['itt_adj']*100:>9.2f} | {s['rel_lift_adj']:>13.1f}\" if s['rel_lift_adj'] else \"\")\n",
    "\n",
    "# Find bounds\n",
    "itt_min = min(s['itt_adj'] for s in sensitivity)\n",
    "itt_max = max(s['itt_adj'] for s in sensitivity)\n",
    "\n",
    "print(f\"\\nITT bounds across r ∈ [0.9, 1.2]:\")\n",
    "print(f\"  Minimum: {itt_min*100:.2f} pp (r=0.9, ads decrease activity)\")\n",
    "print(f\"  Maximum: {itt_max*100:.2f} pp (r=1.2, ads increase activity)\")\n",
    "print(f\"  Range:   {(itt_max-itt_min)*100:.2f} pp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Statistical Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STATISTICAL INFERENCE\n",
      "================================================================================\n",
      "\n",
      "1. TWO-PROPORTION Z-TEST:\n",
      "----------------------------------------\n",
      "Z-statistic:   223.765\n",
      "P-value:      0.000000\n",
      "Significant:  Yes (p < 0.01)\n",
      "\n",
      "2. 95% CONFIDENCE INTERVALS:\n",
      "----------------------------------------\n",
      "Rate_T:       0.1392 [0.1389, 0.1394]\n",
      "Rate_Ĉ:      0.0000 [0.0000, 0.0000]\n",
      "\n",
      "ITT Lift:     13.92 pp [13.89, 13.94]\n",
      "Standard Error: 0.011 pp\n"
     ]
    }
   ],
   "source": [
    "# Statistical tests\n",
    "from statsmodels.stats.proportion import proportions_ztest, proportion_confint\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STATISTICAL INFERENCE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Two-proportion z-test\n",
    "counts = [int(results['T_P']), int(results['C_P'])]\n",
    "nobs = [int(results['OBSERVED_T']), int(results['OBSERVED_C_HAT'])]\n",
    "\n",
    "if all(n > 0 for n in nobs):\n",
    "    z_stat, p_value = proportions_ztest(counts, nobs)\n",
    "    \n",
    "    print(\"\\n1. TWO-PROPORTION Z-TEST:\")\n",
    "    print(\"-\"*40)\n",
    "    print(f\"Z-statistic:  {z_stat:>8.3f}\")\n",
    "    print(f\"P-value:      {p_value:>8.6f}\")\n",
    "    print(f\"Significant:  {'Yes (p < 0.01)' if p_value < 0.01 else 'Yes (p < 0.05)' if p_value < 0.05 else 'No'}\")\n",
    "    \n",
    "    # Confidence intervals for rates\n",
    "    print(\"\\n2. 95% CONFIDENCE INTERVALS:\")\n",
    "    print(\"-\"*40)\n",
    "    \n",
    "    # Treatment rate CI\n",
    "    ci_t_low, ci_t_high = proportion_confint(\n",
    "        count=int(results['T_P']), \n",
    "        nobs=int(results['OBSERVED_T']),\n",
    "        alpha=0.05,\n",
    "        method='wilson'\n",
    "    )\n",
    "    print(f\"Rate_T:       {results['RATE_T']:.4f} [{ci_t_low:.4f}, {ci_t_high:.4f}]\")\n",
    "    \n",
    "    # Control rate CI\n",
    "    ci_c_low, ci_c_high = proportion_confint(\n",
    "        count=int(results['C_P']),\n",
    "        nobs=int(results['OBSERVED_C_HAT']),\n",
    "        alpha=0.05,\n",
    "        method='wilson'\n",
    "    )\n",
    "    print(f\"Rate_Ĉ:      {results['RATE_C_HAT']:.4f} [{ci_c_low:.4f}, {ci_c_high:.4f}]\")\n",
    "    \n",
    "    # ITT CI (delta method approximation)\n",
    "    se_diff = np.sqrt(\n",
    "        (results['RATE_T'] * (1 - results['RATE_T'])) / results['OBSERVED_T'] +\n",
    "        (results['RATE_C_HAT'] * (1 - results['RATE_C_HAT'])) / results['OBSERVED_C_HAT']\n",
    "    )\n",
    "    itt_ci_low = results['ITT_LIFT'] - 1.96 * se_diff\n",
    "    itt_ci_high = results['ITT_LIFT'] + 1.96 * se_diff\n",
    "    \n",
    "    print(f\"\\nITT Lift:     {results['ITT_LIFT']*100:.2f} pp [{itt_ci_low*100:.2f}, {itt_ci_high*100:.2f}]\")\n",
    "    print(f\"Standard Error: {se_diff*100:.3f} pp\")\n",
    "else:\n",
    "    print(\"\\n⚠️ Cannot perform statistical tests: zero observations in one group\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Summary and Caveats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Final summary\nprint(\"\\n\" + \"=\"*80)\nprint(\"SUMMARY REPORT\")\nprint(\"=\"*80)\n\n# Handle None values for display\nrel_lift_str = f\"{results['RELATIVE_LIFT_PCT']:.1f}%\" if results['RELATIVE_LIFT_PCT'] else \"N/A\"\nrev_rel_lift_str = f\"{revenue_results['relative_revenue_lift']:.1f}%\" if revenue_results.get('relative_revenue_lift') else \"N/A\"\n\nprint(f\"\"\"\nCONFIGURATION:\n--------------\nWindow:       [{ANALYSIS_START}, {ANALYSIS_END})\nLookback:     {LOOKBACK_DAYS} days\nSplit:        {TREATMENT_PROP:.0%} / {CONTROL_PROP:.0%}\n\nPRIMARY RESULTS:\n----------------\nPurchase ITT: {results['ITT_LIFT']*100:.2f} pp ({rel_lift_str} relative lift)\nRevenue ITT:  ${revenue_results['itt_revenue_lift']:.2f}/user ({rev_rel_lift_str} lift)\nStatistical significance: p < {p_value:.6f}\n\nSAMPLE SIZES:\n-------------\nTreatment:    {results['OBSERVED_T']:,} users observed\nControl:      {results['C_P']:,} purchasers observed\n              {results['OBSERVED_C_HAT']:,.0f} users estimated\n\nROBUSTNESS:\n-----------\nFeasibility:  {'✓ PASS' if feasible else '✗ FAIL'}\nITT range:    [{itt_min*100:.2f}, {itt_max*100:.2f}] pp for r ∈ [0.9, 1.2]\n\nCAVEATS:\n--------\n1. Assumes activity parity between groups (tested via sensitivity)\n2. Requires consistent user IDs across tables\n3. ITT on active users only (cannot see inactive controls)\n4. No product-level or click-level analysis possible\n5. Platform split assumed exactly {TREATMENT_PROP:.0%}/{CONTROL_PROP:.0%}\n\nINTERPRETATION:\n---------------\nBeing eligible to see ads increases purchase probability by {results['ITT_LIFT']*100:.1f} pp\nand revenue by ${revenue_results['itt_revenue_lift']:.2f} per active user.\n\"\"\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Save results to file\ntimestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\noutput_file = f\"itt_results_{timestamp}.txt\"\n\nwith open(output_file, 'w') as f:\n    f.write(\"INTENT-TO-TREAT ANALYSIS RESULTS\\n\")\n    f.write(\"=\"*80 + \"\\n\\n\")\n    f.write(f\"Generated: {datetime.now()}\\n\")\n    f.write(f\"Window: [{ANALYSIS_START}, {ANALYSIS_END})\\n\")\n    f.write(f\"Lookback: {LOOKBACK_DAYS} days\\n\\n\")\n    \n    # Write key metrics\n    f.write(\"KEY METRICS:\\n\")\n    f.write(\"-\"*40 + \"\\n\")\n    f.write(f\"Observed_T: {results['OBSERVED_T']:,}\\n\")\n    f.write(f\"T_p: {results['T_P']:,}\\n\")\n    f.write(f\"T_np: {results['T_NP']:,}\\n\")\n    f.write(f\"C_p: {results['C_P']:,}\\n\")\n    f.write(f\"C_np_hat: {results['C_NP_HAT']:,.0f}\\n\")\n    f.write(f\"Observed_C_hat: {results['OBSERVED_C_HAT']:,.0f}\\n\\n\")\n    \n    f.write(f\"Rate_T: {results['RATE_T']:.4f}\\n\")\n    f.write(f\"Rate_C_hat: {results['RATE_C_HAT']:.4f}\\n\")\n    f.write(f\"ITT_lift: {results['ITT_LIFT']:.4f} ({results['ITT_LIFT']*100:.2f} pp)\\n\")\n    \n    # Handle None values\n    if results['RELATIVE_LIFT_PCT']:\n        f.write(f\"Relative_lift: {results['RELATIVE_LIFT_PCT']:.1f}%\\n\\n\")\n    else:\n        f.write(\"Relative_lift: N/A (control rate is zero)\\n\\n\")\n    \n    f.write(f\"ARPU_T: ${revenue_results['arpu_t']:.2f}\\n\")\n    f.write(f\"ARPU_C: ${revenue_results['arpu_c']:.2f}\\n\")\n    f.write(f\"Revenue_lift: ${revenue_results['itt_revenue_lift']:.2f}\\n\\n\")\n    \n    f.write(f\"P-value: {p_value:.6f}\\n\")\n    f.write(f\"95% CI: [{itt_ci_low*100:.2f}, {itt_ci_high*100:.2f}] pp\\n\")\n\nprint(f\"\\n✅ Results saved to {output_file}\")"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Snowflake connection closed\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Close connection\n",
    "if conn:\n",
    "    conn.close()\n",
    "    print(\"\\n✅ Snowflake connection closed\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}