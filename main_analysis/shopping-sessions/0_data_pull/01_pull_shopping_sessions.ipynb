{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import snowflake.connector\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# CONFIG\n",
    "SAMPLE_FRACTION = 0.001  # 0.1% of users\n",
    "TOTAL_BUCKETS = 10000\n",
    "SELECTION_THRESHOLD = int(TOTAL_BUCKETS * SAMPLE_FRACTION)\n",
    "START_DATE = '2025-06-15'\n",
    "END_DATE = '2025-06-22'  # 7 days\n",
    "\n",
    "DATA_DIR = Path('./data')\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "load_dotenv()\n",
    "print(f\"Config: {SAMPLE_FRACTION*100}% sample, dates {START_DATE} to {END_DATE}\")\n",
    "print(f\"Selection threshold: {SELECTION_THRESHOLD} / {TOTAL_BUCKETS} buckets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = snowflake.connector.connect(\n",
    "    user=os.getenv('SNOWFLAKE_USER'),\n",
    "    password=os.getenv('SNOWFLAKE_PASSWORD'),\n",
    "    account=os.getenv('SNOWFLAKE_ACCOUNT'),\n",
    "    warehouse=os.getenv('SNOWFLAKE_WAREHOUSE'),\n",
    "    database=os.getenv('SNOWFLAKE_DATABASE'),\n",
    "    schema=os.getenv('SNOWFLAKE_SCHEMA')\n",
    ")\n",
    "print(f\"Connected to Snowflake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTE_SQL = f\"\"\"\n",
    "WITH SAMPLED_USERS AS (\n",
    "    SELECT OPAQUE_USER_ID FROM (\n",
    "        SELECT OPAQUE_USER_ID, MOD(ABS(HASH(OPAQUE_USER_ID)), {TOTAL_BUCKETS}) AS bucket\n",
    "        FROM (SELECT DISTINCT OPAQUE_USER_ID FROM AUCTIONS_USERS\n",
    "              WHERE CREATED_AT BETWEEN '{START_DATE}' AND '{END_DATE}')\n",
    "    ) WHERE bucket < {SELECTION_THRESHOLD}\n",
    ")\n",
    "\"\"\"\n",
    "print(f\"CTE defined: {SAMPLE_FRACTION*100}% sample, dates {START_DATE} to {END_DATE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUCTIONS_USERS\n",
    "print(\"Pulling AUCTIONS_USERS...\")\n",
    "auctions_users = pd.read_sql(CTE_SQL + f\"\"\"\n",
    "SELECT\n",
    "    LOWER(HEX_ENCODE(AUCTION_ID)) as auction_id,\n",
    "    TRIM(OPAQUE_USER_ID) as user_id,\n",
    "    CREATED_AT as auction_time,\n",
    "    PLACEMENT as placement\n",
    "FROM AUCTIONS_USERS au\n",
    "JOIN SAMPLED_USERS s ON au.OPAQUE_USER_ID = s.OPAQUE_USER_ID\n",
    "WHERE au.CREATED_AT BETWEEN '{START_DATE}' AND '{END_DATE}'\n",
    "\"\"\", conn)\n",
    "print(f\"  {len(auctions_users):,} rows\")\n",
    "\n",
    "# AUCTIONS_RESULTS\n",
    "print(\"Pulling AUCTIONS_RESULTS...\")\n",
    "auctions_results = pd.read_sql(CTE_SQL + f\"\"\"\n",
    "SELECT\n",
    "    LOWER(HEX_ENCODE(ar.AUCTION_ID)) as auction_id,\n",
    "    LOWER(HEX_ENCODE(ar.VENDOR_ID)) as vendor_id,\n",
    "    LOWER(HEX_ENCODE(ar.CAMPAIGN_ID)) as campaign_id,\n",
    "    TRIM(ar.PRODUCT_ID) as product_id,\n",
    "    ar.RANKING as ranking,\n",
    "    ar.IS_WINNER as is_winner,\n",
    "    ar.QUALITY as quality,\n",
    "    ar.FINAL_BID as final_bid,\n",
    "    ar.PRICE as price\n",
    "FROM AUCTIONS_RESULTS ar\n",
    "JOIN AUCTIONS_USERS au ON ar.AUCTION_ID = au.AUCTION_ID\n",
    "JOIN SAMPLED_USERS s ON au.OPAQUE_USER_ID = s.OPAQUE_USER_ID\n",
    "WHERE au.CREATED_AT BETWEEN '{START_DATE}' AND '{END_DATE}'\n",
    "\"\"\", conn)\n",
    "print(f\"  {len(auctions_results):,} rows\")\n",
    "\n",
    "# IMPRESSIONS\n",
    "print(\"Pulling IMPRESSIONS...\")\n",
    "impressions = pd.read_sql(CTE_SQL + f\"\"\"\n",
    "SELECT\n",
    "    TRIM(i.INTERACTION_ID) as interaction_id,\n",
    "    TRIM(i.AUCTION_ID) as auction_id,\n",
    "    TRIM(i.PRODUCT_ID) as product_id,\n",
    "    TRIM(i.USER_ID) as user_id,\n",
    "    LOWER(HEX_ENCODE(i.VENDOR_ID)) as vendor_id,\n",
    "    i.OCCURRED_AT as impression_time\n",
    "FROM IMPRESSIONS i\n",
    "JOIN SAMPLED_USERS s ON i.USER_ID = s.OPAQUE_USER_ID\n",
    "WHERE i.OCCURRED_AT BETWEEN '{START_DATE}' AND '{END_DATE}'\n",
    "\"\"\", conn)\n",
    "print(f\"  {len(impressions):,} rows\")\n",
    "\n",
    "# CLICKS\n",
    "print(\"Pulling CLICKS...\")\n",
    "clicks = pd.read_sql(CTE_SQL + f\"\"\"\n",
    "SELECT\n",
    "    TRIM(c.INTERACTION_ID) as interaction_id,\n",
    "    TRIM(c.AUCTION_ID) as auction_id,\n",
    "    TRIM(c.PRODUCT_ID) as product_id,\n",
    "    TRIM(c.USER_ID) as user_id,\n",
    "    LOWER(HEX_ENCODE(c.VENDOR_ID)) as vendor_id,\n",
    "    c.OCCURRED_AT as click_time\n",
    "FROM CLICKS c\n",
    "JOIN SAMPLED_USERS s ON c.USER_ID = s.OPAQUE_USER_ID\n",
    "WHERE c.OCCURRED_AT BETWEEN '{START_DATE}' AND '{END_DATE}'\n",
    "\"\"\", conn)\n",
    "print(f\"  {len(clicks):,} rows\")\n",
    "\n",
    "# PURCHASES\n",
    "print(\"Pulling PURCHASES...\")\n",
    "purchases = pd.read_sql(CTE_SQL + f\"\"\"\n",
    "SELECT\n",
    "    TRIM(p.PURCHASE_ID) as purchase_id,\n",
    "    p.PURCHASED_AT as purchase_time,\n",
    "    TRIM(p.PRODUCT_ID) as product_id,\n",
    "    p.QUANTITY as quantity,\n",
    "    p.UNIT_PRICE as unit_price,\n",
    "    TRIM(p.USER_ID) as user_id\n",
    "FROM PURCHASES p\n",
    "JOIN SAMPLED_USERS s ON p.USER_ID = s.OPAQUE_USER_ID\n",
    "WHERE p.PURCHASED_AT BETWEEN '{START_DATE}' AND '{END_DATE}'\n",
    "\"\"\", conn)\n",
    "print(f\"  {len(purchases):,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect product IDs from event tables only\n",
    "all_products = set()\n",
    "all_products.update(impressions['product_id'].dropna().unique())\n",
    "all_products.update(clicks['product_id'].dropna().unique())\n",
    "all_products.update(purchases['product_id'].dropna().unique())\n",
    "print(f\"Unique products to fetch: {len(all_products):,}\")\n",
    "\n",
    "# Pull catalog in batches\n",
    "product_list = list(all_products)\n",
    "batch_size = 10000\n",
    "catalog_dfs = []\n",
    "\n",
    "for i in tqdm(range(0, len(product_list), batch_size), desc=\"Fetching catalog\"):\n",
    "    batch = product_list[i:i+batch_size]\n",
    "    batch_str = \"','\".join(batch)\n",
    "    query = f\"\"\"\n",
    "    SELECT\n",
    "        TRIM(PRODUCT_ID) as product_id,\n",
    "        NAME as name,\n",
    "        CATEGORIES as categories,\n",
    "        PRICE as price,\n",
    "        VENDORS as vendors\n",
    "    FROM CATALOG\n",
    "    WHERE PRODUCT_ID IN ('{batch_str}')\n",
    "    \"\"\"\n",
    "    catalog_dfs.append(pd.read_sql(query, conn))\n",
    "\n",
    "catalog = pd.concat(catalog_dfs, ignore_index=True) if catalog_dfs else pd.DataFrame()\n",
    "print(f\"Catalog: {len(catalog):,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auctions_users.to_parquet(DATA_DIR / 'auctions_users.parquet', index=False)\n",
    "auctions_results.to_parquet(DATA_DIR / 'auctions_results.parquet', index=False)\n",
    "impressions.to_parquet(DATA_DIR / 'impressions.parquet', index=False)\n",
    "clicks.to_parquet(DATA_DIR / 'clicks.parquet', index=False)\n",
    "purchases.to_parquet(DATA_DIR / 'purchases.parquet', index=False)\n",
    "catalog.to_parquet(DATA_DIR / 'catalog.parquet', index=False)\n",
    "\n",
    "print(\"\\nSaved files:\")\n",
    "for f in DATA_DIR.glob('*.parquet'):\n",
    "    print(f\"  {f}: {pd.read_parquet(f).shape}\")\n",
    "\n",
    "conn.close()\n",
    "print(\"\\nData pull complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
