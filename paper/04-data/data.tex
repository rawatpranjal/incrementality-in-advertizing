\section{Data}

Our empirical analysis uses data from a large US-based online marketplace, spanning five months from March through July 2025. The data capture the lifecycle of sponsored advertising interactions: every ad auction triggered by a user search, every bid submitted by a vendor, every ad impression delivered, every click recorded, and every purchase transacted on the platform. On an average day, the platform processes over 7 million search events that generate more than 268 million bids across approximately 27 million ad impressions. These impressions yield nearly 900,000 clicks and over 110,000 purchase transactions totaling nearly \$5 million in daily revenue.

\begin{table}[htbp!]
\centering
\caption{Data Sources}
\label{tab:data_structure}
\begin{tabular}{p{0.22\textwidth} p{0.75\textwidth}}
\toprule
Table & Description \\
\midrule
Auctions (Users) & Records of every ad auction triggered by a user search or browsing action. Links users to auction instances. \\
Auctions (Results) & Bid-level records for each auction. Multiple vendors bid per auction; each observation represents one bid with its ranking and whether it won an impression slot. \\
Impressions & Log of every promoted ad displayed to a user. \\
Clicks & Log of every user click on a sponsored ad. \\
Purchases & All purchase transactions on the platform, including both promoted and organic purchases. \\
Catalog & Product metadata including names, text descriptions, categorical classifications, and listed prices. \\
\bottomrule
\end{tabular}
\end{table}

The dataset comprises six tables capturing different stages of the user journey (Table \ref{tab:data_structure}). The structure enables tracking user behavior throughout the advertising funnel. Each search or browsing event triggers an ad auction in which multiple vendors bid for their products to appear in sponsored placements. A single auction typically generates dozens of competing bids. The platform's algorithm ranks these bids, and only the highest-ranked bids win impression slots. We observe every bid submitted, its rank relative to competing bids, and whether it secured an advertising placement.

The auctions data contain additional granular information about each bid, including the quality score, final bid amount, predicted conversion rate, pacing multiplier, and product price.\footnote{Revenue and price values are recorded in cents. The pacing multiplier is typically equal to one.} The platform employs an autobidding system where final bids are computed according to the formula $\text{final\_bid} = \text{pCVR} \times \text{AOV} / \text{target\_roas}$, where pCVR is the predicted conversion rate, AOV is the average order value (approximated by product price), and target\_roas is the advertiser's target return on ad spend. Empirical analysis reveals that final bids scale approximately proportionally with price, suggesting the relationship $\text{final\_bid} \approx k_{\text{vendor}} \times \text{price}$ where $k_{\text{vendor}}$ is a vendor-specific constant capturing differences in target return on ad spend across advertisers.\footnote{A log-log regression of final bid on price, conversion rate, and pacing with vendor fixed effects yields $R^2 = 0.98$, with the price coefficient near unity (0.97) and negligible coefficients on conversion rate and pacing.}

Ad rank within each auction is determined by the product of the quality score and final bid amount. The quality score is the platform's predicted click-through rate (pCTR), derived from machine learning models that incorporate product, placement, and user features. This ranking mechanism ensures that ads appearing in higher positions exhibit both strong predicted engagement and sufficient advertiser willingness to pay.

The auctions data also record the placement context, which indicates the page type where the ad was served. Placement 1 corresponds to search result pages, characterized by high brand diversity and rapid user engagement patterns. Placement 2 represents brand pages, where auctions contain products predominantly from a single brand and users exhibit deep scrolling behavior. Placement 3 denotes product pages, where ads appear below the fold in sections such as ``More like this'' or ``Similar Items.'' Placement 5 corresponds to category pages, though this classification carries greater uncertainty.

When served, a winning bid generates an impression record. Clicks on promoted listings are captured in the clicks data. The purchases table records all transactions regardless of whether they followed a promoted or organic pathway.

The catalog data impose a measurement limitation. While product metadata—names, descriptions, categories, and prices—are available, these match only purchases from a promoted journey. Organic purchases cannot be linked to product characteristics because they lack corresponding entries in the impressions or clicks tables. This restricts our ability to characterize all transactions and creates selection issues when conditioning on product observables.

Table \ref{tab:summary_stats} presents aggregate daily statistics summarizing platform activity.

\begin{table}[htbp!]
\centering
\caption{Average Daily Platform Statistics}
\label{tab:summary_stats}
\begin{tabular}{lr}
\toprule
Metric & Value \\
\midrule
Total Search Events & 7,420,764 \\
Total Bids Submitted & 268,105,571 \\
Total Impressions Delivered & 27,692,988 \\
Total Clicks on Ads & 891,817 \\
Total Unique Purchase Transactions & 111,910 \\
Total Revenue & \$4,925,990 \\
Click-Through Rate (CTR) & 3.22\% \\
Conversion Rate (from Click to Purchase) & 12.55\% \\
\bottomrule
\end{tabular}
\end{table}

This dataset creates both opportunities and constraints for causal inference. We observe the complete sponsored advertising funnel from auction mechanics through final purchase outcomes, with millisecond-precise timestamps. Persistent user and vendor identifiers enable longitudinal panel constructions at multiple levels of aggregation. However, several data characteristics impose important limitations. Most importantly, the asymmetry between promoted and organic pathways: we observe all advertising interactions—impressions, clicks, and ad-exposed purchases—but no organic browsing behavior. A user's non-sponsored product views, wishlist additions, or social interactions with sellers are unrecorded. This creates a selection problem: users in our impression and click data are a non-random subset of all users who ultimately purchase. Any analysis comparing promoted users to "control" users must account for algorithmic targeting.

The purchase data present another challenge. The Purchases table includes all transactions but contains no flag indicating whether a purchase followed an ad click or occurred organically. Reconstructing each user's advertising exposure history requires linking back through the clicks and impressions tables. The absence of campaign-level metadata further limits analysis. We observe campaign identifiers but not budgets, duration, or targeting rules. This prevents studying how advertisers adjust spending in response to performance signals or how budget constraints bind vendor behavior.
