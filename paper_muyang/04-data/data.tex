\section{Data}

Our empirical analysis uses data from a large US-based online marketplace, spanning five months from March through July 2025. The data capture the lifecycle of sponsored advertising interactions: every ad auction triggered by a user search, every bid submitted by a vendor, every ad impression delivered, every click recorded, and every purchase transacted on the platform. On an average day, the platform processes over 7 million search events that generate more than 268 million bids across approximately 27 million ad impressions. These impressions yield nearly 900,000 clicks and over 110,000 purchase transactions totaling nearly \$5 million in daily revenue.

\begin{table}[htbp!]
\centering
\caption{Data Sources}
\label{tab:data_structure}
\begin{tabular}{p{0.22\textwidth} p{0.75\textwidth}}
\toprule
Table & Description \\
\midrule
Auctions (Users) & Records of every ad auction triggered by a user search or browsing action. Links users to auction instances. \\
Auctions (Results) & Bid-level records for each auction. Multiple vendors bid per auction; each observation represents one bid with its ranking and whether it won an impression slot. \\
Impressions & Log of every promoted ad displayed to a user. \\
Clicks & Log of every user click on a sponsored ad. \\
Purchases & All purchase transactions on the platform, including both promoted and organic purchases. \\
Catalog & Product metadata including names, text descriptions, categorical classifications, and listed prices. \\
\bottomrule
\end{tabular}
\end{table}

The dataset comprises six tables capturing different stages of the user journey (Table \ref{tab:data_structure}). The structure enables tracking user behavior throughout the advertising funnel. Each search or browsing event triggers an ad auction in which multiple vendors bid for their products to appear in sponsored placements. A single auction typically generates dozens of competing bids. The platform's algorithm ranks these bids, and only the highest-ranked bids win impression slots. We observe every bid submitted, its rank relative to competing bids, and whether it secured an advertising placement.

The auctions data contain additional granular information about each bid, including the quality score, final bid amount, predicted conversion rate, pacing multiplier, and product price.\footnote{Revenue and price values are recorded in cents. The pacing multiplier is typically equal to one.} The platform employs an autobidding system where final bids are computed according to the formula $\text{final\_bid} = \text{pCVR} \times \text{AOV} / \text{target\_roas}$, where pCVR is the predicted conversion rate, AOV is the average order value (approximated by product price), and target\_roas is the advertiser's target return on ad spend. Empirical analysis reveals that final bids scale approximately proportionally with price, suggesting the relationship $\text{final\_bid} \approx k_{\text{vendor}} \times \text{price}$ where $k_{\text{vendor}}$ is a vendor-specific constant capturing differences in target return on ad spend across advertisers.\footnote{A log-log regression of final bid on price, conversion rate, and pacing with vendor fixed effects yields $R^2 = 0.98$, with the price coefficient near unity (0.97) and negligible coefficients on conversion rate and pacing.}

Ad rank within each auction is determined by the product of the quality score and final bid amount. The quality score is the platform's predicted click-through rate (pCTR), derived from machine learning models that incorporate product, placement, and user features. This ranking mechanism ensures that ads appearing in higher positions exhibit both strong predicted engagement and sufficient advertiser willingness to pay.

The auctions data also record the placement context, which indicates the page type where the ad was served. Placement 1 corresponds to search results pages, characterized by high brand diversity and rapid user engagement patterns. Placement 2 represents brand browse pages, where auctions contain products predominantly from a single brand and users exhibit deeper scrolling behavior. Placement 3 denotes product detail pages, where ads appear within related‑product or cross‑sell modules. Placement 5 corresponds to category browse pages.\footnote{Sponsored listings deliver in three primary contexts on the marketplace: interleaved with organic results on search results pages; inserted within product grids on category and brand browse pages; and rendered within horizontally scrollable related‑product or cross‑sell carousels on product detail and certain browse surfaces. The marketplace does not operate a distinct "swimlane" placement separate from these carousel modules; horizontal rows are implemented as carousels on the surfaces noted above.}

When served, a winning bid generates an impression record. Clicks on promoted listings are captured in the clicks data. The purchases table records all transactions regardless of whether they followed a promoted or organic pathway.\footnote{An impression is recorded when a sponsored product renders on screen, a click when the user selects it, and a purchase when the order is confirmed. Auctions, bids, impressions, and clicks can be linked internally (for example, by identifiers that associate the winning ad to subsequent clicks). Purchases are not directly mapped to any auction; they are associated with prior ad interactions only via attribution windows or other accounting logic, which does not by itself identify the causal effect of any specific ad.}

The catalog data impose a measurement limitation. While product metadata—names, descriptions, categories, and prices—are available, these match only purchases from a promoted journey. Organic purchases cannot be linked to product characteristics because they lack corresponding entries in the impressions or clicks tables. This restricts our ability to characterize all transactions and creates selection issues when conditioning on product observables.

Table \ref{tab:summary_stats} presents aggregate daily statistics summarizing platform activity.\footnote{Accounting metrics used in reporting are defined as follows. Spend is the total advertising cost in the platform's currency. Impressions are ad render events; Clicks are user selections of ads. The click‑through rate (CTR) is clicks divided by impressions. Cost per click (CPC) is spend divided by clicks, and cost per mille (CPM) is one thousand times spend divided by impressions. Purchases (orders) count distinct transactions, and Sales or gross merchandise value (GMV) is revenue credited under the reporting policy. The conversion rate (CVR) is purchases divided by clicks. Return on advertising spend (ROAS) is sales divided by spend. These are accounting measures for monitoring and do not, by themselves, identify the incremental causal effect of advertising. For illustration, consider a day on which there would have been 100 purchases at $\$100$ each even without advertising (\$10{,}000 in revenue). If advertising runs and spends \$200 while the attribution model credits those same 100 purchases to ads, the reported ROAS is $\$10{,}000/\$200 = 50$, yet the incremental effect is zero because purchases did not increase relative to the no‑ad baseline.}

\begin{table}[htbp!]
\centering
\caption{Average Daily Platform Statistics}
\label{tab:summary_stats}
\begin{tabular}{lr}
\toprule
Metric & Value \\
\midrule
Total Search Events & 7,420,764 \\
Total Bids Submitted & 268,105,571 \\
Total Impressions Delivered & 27,692,988 \\
Total Clicks on Ads & 891,817 \\
Total Unique Purchase Transactions & 111,910 \\
Total Revenue & \$4,925,990 \\
Click-Through Rate (CTR) & 3.22\% \\
Conversion Rate (from Click to Purchase) & 12.55\% \\
\bottomrule
\end{tabular}
\end{table}

This dataset creates both opportunities and constraints for causal inference. We observe the complete sponsored advertising funnel from auction mechanics through final purchase outcomes, with millisecond-precise timestamps. Persistent user and vendor identifiers enable longitudinal panel constructions at multiple levels of aggregation. However, several data characteristics impose important limitations. Most importantly, the asymmetry between promoted and organic pathways: we observe all advertising interactions—impressions, clicks, and ad-exposed purchases—but no organic browsing behavior. A user's non-sponsored product views, wishlist additions, or social interactions with sellers are unrecorded. This creates a selection problem: users in our impression and click data are a non-random subset of all users who ultimately purchase. Any analysis comparing promoted users to "control" users must account for algorithmic targeting.

The purchase data present another challenge. The Purchases table includes all transactions but contains no flag indicating whether a purchase followed an ad click or occurred organically. Reconstructing each user's advertising exposure history requires linking back through the clicks and impressions tables. The absence of campaign-level metadata further limits analysis. We observe campaign identifiers but not budgets, duration, or targeting rules. This prevents studying how advertisers adjust spending in response to performance signals or how budget constraints bind vendor behavior.
