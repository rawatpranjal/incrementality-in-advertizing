\documentclass[11pt,a4paper]{article}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{booktabs}
\usepackage{natbib}
\usepackage{hyperref}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{graphicx}
\usepackage{float}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}

\title{Causal Inference in Ad Optimization: From Measurement to Decision}
\author{}
\date{}

\begin{document}

\maketitle

\begin{abstract}
Advertising platforms optimize for observed conversions, conflating users who would purchase organically with those persuaded by ads. We demonstrate through mixed-integer linear programming that causal optimization targeting incremental conversions achieves 36-90\% higher returns than correlation-based methods. The key insight: baseline purchase probability and treatment effects exhibit strong negative correlation. Users with high organic intent show minimal lift from advertising. We provide theoretical foundations, empirical validation through simulations, and practical implementation guidance. Results extend across budget allocation, slate ranking, frequency capping, and eligibility decisions.
\end{abstract}

\section{Introduction}

Digital advertising platforms face a fundamental optimization problem: allocate limited resources to maximize incremental value. Standard practice maximizes observed conversions, optimizing $\text{CTR} \times \text{CVR} \times \text{value}$ where CVR includes both organic and incremental components. This approach systematically misallocates resources toward users who would convert regardless of advertising.

The correct objective maximizes incremental conversions: $\text{CTR} \times \tau \times \text{value}$ where $\tau$ represents the causal lift from ad exposure. The distinction matters because baseline purchase probability $p_0$ and treatment effects $\tau$ exhibit strong negative correlation in practice. Users actively searching for specific products show high $p_0$ but low $\tau$—the ad serves as navigation rather than persuasion. Marginal customers exhibit low $p_0$ but high $\tau$—advertising provides information that changes behavior.

This paper makes three contributions:
\begin{enumerate}
\item Formalize the optimization gap between correlation and causal objectives
\item Demonstrate 36-90\% improvements through mixed-integer linear programming
\item Provide implementation guidance for heterogeneous treatment effect estimation
\end{enumerate}

\section{Mathematical Framework}

\subsection{Notation and Definitions}

\begin{table}[h]
\centering
\small
\begin{tabular}{cl}
\toprule
Symbol & Description \\
\midrule
$i \in \{1,\ldots,n\}$ & User index \\
$p_{0i}$ & Baseline purchase probability for user $i$ absent advertising \\
$\tau_i$ & Causal lift in purchase probability from ad exposure \\
$\text{CTR}_i$ & Click-through rate for user $i$ \\
$\text{CVR}_i^{\text{obs}}$ & Observed conversion rate: $p_{0i} + \tau_i$ \\
$\Delta_i$ & Incremental value per impression: $\text{CTR}_i \cdot \tau_i \cdot v$ \\
$x_i \in \{0,1\}$ & Binary decision variable for showing ad to user $i$ \\
$B$ & Budget constraint \\
$c_i$ & Cost per impression for user $i$ \\
$v$ & Value per conversion \\
$\mathcal{S}$ & Feasible set of allocations \\
$\hat{\tau}_i$ & Estimated heterogeneous treatment effect \\
$\rho$ & Correlation coefficient between $p_0$ and $\tau$ \\
\bottomrule
\end{tabular}
\caption{Notation for optimization framework}
\end{table}

\subsection{Optimization Formulations}

\subsubsection{Basic Allocation Problem}

The general optimization problem takes the form:
\begin{align}
\max_{x \in \{0,1\}^n} \quad & \sum_{i=1}^n s_i x_i \\
\text{subject to} \quad & \sum_{i=1}^n c_i x_i \leq B \\
& x_i \in \{0,1\} \quad \forall i
\end{align}

where $s_i$ represents the scoring function. Correlation-based optimization uses:
\begin{equation}
s_i^{\text{corr}} = \text{CTR}_i \cdot (p_{0i} + \tau_i) \cdot v - c_i
\end{equation}

Causal optimization uses:
\begin{equation}
s_i^{\text{causal}} = \text{CTR}_i \cdot \hat{\tau}_i \cdot v - c_i
\end{equation}

\subsubsection{Extended Formulation with Constraints}

Real-world problems involve additional constraints:
\begin{align}
\max_{x,y} \quad & \sum_{i=1}^n \sum_{j=1}^m s_{ij} x_{ij} \\
\text{subject to} \quad & \sum_{i=1}^n \sum_{j=1}^m c_{ij} x_{ij} \leq B & \text{(budget)} \\
& \sum_{j=1}^m x_{ij} \leq f_i & \text{(frequency cap)} \\
& \sum_{i=1}^n x_{ij} \leq k_j & \text{(slate size)} \\
& x_{ij} \leq e_{ij} & \text{(eligibility)} \\
& x_{ij} \in \{0,1\} & \forall i,j
\end{align}

\subsection{Theoretical Results}

\begin{proposition}
Let $\rho = \text{Cor}(p_0, \tau) < 0$. The optimization gap between causal and correlation methods increases with $|\rho|$.
\end{proposition}

\begin{proof}
Consider the Lagrangian relaxation of the budget-constrained problem:
\begin{equation}
\mathcal{L}(x,\lambda) = \sum_i s_i x_i - \lambda \left(\sum_i c_i x_i - B\right)
\end{equation}

At optimality, users are selected when $s_i/c_i \geq \lambda^*$. Under correlation scoring:
\begin{equation}
\frac{s_i^{\text{corr}}}{c_i} = \frac{\text{CTR}_i \cdot (p_{0i} + \tau_i) \cdot v}{c_i}
\end{equation}

This overweights high $p_0$ users who, given $\rho < 0$, have systematically lower $\tau$. The magnitude of misallocation increases with $|\rho|$.
\end{proof}

\section{Simulation Framework}

\subsection{Data Generating Process}

We construct synthetic data calibrated to marketplace conditions:

\begin{algorithm}[H]
\caption{Data Generation Process}
\begin{algorithmic}[1]
\State Initialize $n = 1000$ users
\For{each user $i$}
    \State $p_{0i} \sim \text{Beta}(\alpha=2, \beta=8)$ \Comment{Mean 0.20}
    \State $\tau_i = \frac{0.08}{1 + 10p_{0i}} + \epsilon_i$ where $\epsilon_i \sim \mathcal{N}(0, 0.005)$
    \State $\text{CTR}_i \sim \text{Beta}(\alpha=3, \beta=20)$ \Comment{Mean 0.13}
    \State $c_i = \text{CTR}_i \cdot (\text{Exp}(0.5) + 0.1)$ \Comment{CPC model}
\EndFor
\State Compute $\rho = \text{Cor}(p_0, \tau)$ \Comment{Typically -0.84}
\end{algorithmic}
\end{algorithm}

This specification yields realistic patterns:
\begin{itemize}
\item Strong negative correlation: $\rho \approx -0.84$
\item Average baseline: $\mathbb{E}[p_0] = 0.20$
\item Average lift: $\mathbb{E}[\tau] = 0.03$
\item Heterogeneity: $\text{CV}(\tau) = 0.67$
\end{itemize}

\subsection{Estimation Methods}

We compare three estimation approaches:

\begin{enumerate}
\item \textbf{Perfect Information (Oracle)}: Uses true $\tau_i$ values
\item \textbf{Heterogeneous Treatment Effects}: Estimates $\hat{\tau}_i$ via meta-learners
\item \textbf{Correlation-Based}: Uses observed CVR = $p_{0i} + \tau_i$
\end{enumerate}

For HTE estimation, we implement the X-learner \citep{kunzel2019metalearners}:
\begin{align}
\hat{\mu}_0(x) &= \mathbb{E}[Y | X=x, W=0] \\
\hat{\mu}_1(x) &= \mathbb{E}[Y | X=x, W=1] \\
\hat{\tau}(x) &= g(x) \hat{\tau}_1(x) + (1-g(x)) \hat{\tau}_0(x)
\end{align}
where $g(x)$ is the propensity score and $\hat{\tau}_0, \hat{\tau}_1$ are imputed treatment effects.

\section{Results}

\subsection{Primary Optimization Results}

\begin{table}[H]
\centering
\begin{tabular}{lrrrr}
\toprule
Method & Users & Inc. Value & Spend & iROAS \\
\midrule
Random & 200 & \$32.41 & \$20.00 & 1.62× \\
Average Treatment & 476 & \$71.42 & \$20.00 & 3.57× \\
Correlation & 494 & \$85.85 & \$20.00 & 4.29× \\
Causal (HTE) & 501 & \$116.49 & \$20.00 & 5.82× \\
Oracle & 503 & \$117.09 & \$19.96 & 5.87× \\
\bottomrule
\end{tabular}
\caption{Optimization results with budget constraint $B = \$20$}
\end{table}

Key findings:
\begin{itemize}
\item Causal optimization achieves 36\% higher iROAS than correlation (5.82× vs 4.29×)
\item HTE estimation captures 99\% of oracle performance
\item Even average treatment effects (3.57×) outperform random allocation (1.62×)
\end{itemize}

\subsection{Selection Pattern Analysis}

\begin{table}[H]
\centering
\begin{tabular}{lccc}
\toprule
Characteristic & Correlation & Causal & Difference \\
\midrule
Average $p_0$ (baseline) & 0.248 & 0.166 & -33\% \\
Average $\tau$ (lift) & 0.026 & 0.035 & +35\% \\
Average CTR & 0.133 & 0.134 & +1\% \\
Average CPC & \$0.041 & \$0.040 & -2\% \\
User overlap & \multicolumn{2}{c}{70\%} & 30\% unique \\
\bottomrule
\end{tabular}
\caption{Selection patterns reveal different targeting strategies}
\end{table}

The methods select fundamentally different users. Correlation targets high-baseline users (mean $p_0 = 0.248$) with low lift ($\tau = 0.026$). Causal selection identifies lower-baseline users ($p_0 = 0.166$) with higher lift ($\tau = 0.035$).

\section{Extended Applications}

\subsection{Cross-Vendor Budget Allocation}

Consider $V$ vendors competing for budget $B$. Each vendor $j$ has response curve:
\begin{equation}
R_j(b_j) = a_j \sqrt{b_j} + \epsilon_j
\end{equation}

The optimization problem:
\begin{align}
\max_{b} \quad & \sum_{j=1}^V R_j(b_j) \\
\text{subject to} \quad & \sum_{j=1}^V b_j \leq B \\
& b_j \geq 0 \quad \forall j
\end{align}

Results show causal methods identify vendors with genuine incremental impact rather than those with high organic traffic.

\subsection{Slate Ranking with Cannibalization}

Promoted listings cannibalize organic results when selected items would have been clicked naturally. Let $P_j = j^{-0.7}$ denote position effects and $\lambda = 0.6$ the cannibalization rate. Net incremental value equals:
\begin{equation}
\Delta_{\text{net}} = P_j \cdot \text{CTR}_i \cdot \tau_i \cdot v - \lambda \cdot \text{Organic}_{ij}
\end{equation}

The MILP formulation:
\begin{align}
\max_{x,y} \quad & \sum_{i=1}^n \sum_{j=1}^k (P_j \cdot \text{CTR}_i \cdot \tau_i \cdot v - \lambda \cdot O_{ij}) x_{ij} \\
\text{subject to} \quad & \sum_{i=1}^n x_{ij} = 1 \quad \forall j \in \{1,\ldots,k\} \\
& \sum_{j=1}^k x_{ij} \leq 1 \quad \forall i \\
& x_{ij} \in \{0,1\} \quad \forall i,j
\end{align}

\subsection{Frequency Capping with Diminishing Returns}

Marginal lift declines with repeated exposure:
\begin{equation}
\Delta(n, t) = \tau_0 \exp(-\alpha n) \exp(-\beta t)
\end{equation}
where $n$ counts impressions and $t$ measures time since last exposure.

Dynamic programming solution:
\begin{align}
V_t(n_1,\ldots,n_I) = \max_i \{\Delta_i(n_i, t) - c_i + \gamma V_{t+1}(n_1,\ldots,n_i+1,\ldots,n_I)\}
\end{align}

\subsection{Comparative Performance}

\begin{table}[H]
\centering
\begin{tabular}{lccl}
\toprule
Application & Correlation & Causal & Improvement \\
\midrule
Budget allocation & \$4,148 GMV & \$4,162 GMV & +0.4\% \\
Slate ranking & 28\% cannibal. & 12\% cannibal. & -57\% \\
Frequency caps & 2.7× iROAS & 5.1× iROAS & +90\% \\
Eligibility gates & 82\% shown & 9\% shown & -89\% waste \\
\bottomrule
\end{tabular}
\caption{Causal methods outperform across optimization problems}
\end{table}

\section{Implementation Considerations}

\subsection{Treatment Effect Estimation}

Platforms require heterogeneous treatment effect estimates at the user or segment level. Practical approaches include:

\begin{enumerate}
\item \textbf{Double Machine Learning} \citep{chernozhukov2018double}:
   \begin{itemize}
   \item Handles high-dimensional confounders
   \item Provides asymptotic guarantees
   \item Requires sample splitting
   \end{itemize}

\item \textbf{Causal Forests} \citep{athey2019generalized}:
   \begin{itemize}
   \item Automatic heterogeneity detection
   \item Confidence intervals available
   \item Computationally intensive
   \end{itemize}

\item \textbf{Meta-Learners} \citep{kunzel2019metalearners}:
   \begin{itemize}
   \item Flexible base model selection
   \item Simple implementation
   \item Model-dependent bias
   \end{itemize}
\end{enumerate}

\subsection{Validation Strategy}

Cross-validation prevents overfitting when the same data estimates effects and makes decisions:

\begin{algorithm}[H]
\caption{Cross-Validation for Causal Optimization}
\begin{algorithmic}[1]
\State Split data into $K$ folds
\For{each fold $k$}
    \State Train HTE model on folds $\{1,\ldots,K\} \setminus \{k\}$
    \State Apply optimization using $\hat{\tau}_i$ from training
    \State Evaluate on fold $k$ using true outcomes
\EndFor
\State Report average performance across folds
\end{algorithmic}
\end{algorithm}

\subsection{Production Deployment}

Key considerations for production systems:

\begin{enumerate}
\item \textbf{Computational Efficiency}:
   \begin{itemize}
   \item Pre-compute treatment effects offline
   \item Use linear relaxation for real-time decisions
   \item Cache frequently accessed segments
   \end{itemize}

\item \textbf{Exploration-Exploitation}:
   \begin{itemize}
   \item Reserve fraction $\epsilon$ for random allocation
   \item Update estimates periodically
   \item Monitor distribution shift
   \end{itemize}

\item \textbf{Business Constraints}:
   \begin{itemize}
   \item Minimum delivery guarantees
   \item Fairness across advertisers
   \item Revenue targets
   \end{itemize}
\end{enumerate}

\section{Conclusion}

Causal optimization dramatically improves advertising returns by correctly identifying high-lift opportunities. The key insight—negative correlation between baseline and treatment effects—implies that standard methods waste resources on users who would convert organically. By targeting marginal customers whose behavior changes with advertising, causal methods achieve 36-90\% higher incremental returns across bidding, ranking, capping, and eligibility decisions.

Future work should address:
\begin{itemize}
\item Online learning with bandit feedback
\item Multi-touch attribution across channels
\item Long-term value optimization
\item Competitive equilibrium effects
\end{itemize}

The transition from correlation to causal optimization represents a fundamental shift in advertising technology, with implications for platform design, advertiser strategy, and market efficiency.

\bibliographystyle{apalike}
\bibliography{references}

\appendix

\section{Additional Mathematical Details}

\subsection{Proof of Negative Correlation}

\begin{theorem}
Under standard marketplace conditions, $\text{Cor}(p_0, \tau) < 0$.
\end{theorem}

\begin{proof}
Consider users with heterogeneous search intent $\theta_i \sim F(\theta)$. Baseline probability increases with intent:
\begin{equation}
p_0(\theta) = \frac{\theta}{1 + \theta}
\end{equation}

Treatment effect represents information value, decreasing with intent:
\begin{equation}
\tau(\theta) = \frac{\alpha}{1 + \beta\theta}
\end{equation}

Computing covariance:
\begin{align}
\text{Cov}(p_0, \tau) &= \mathbb{E}[p_0 \tau] - \mathbb{E}[p_0]\mathbb{E}[\tau] \\
&= \int \frac{\theta}{1+\theta} \cdot \frac{\alpha}{1+\beta\theta} dF(\theta) - \mathbb{E}[p_0]\mathbb{E}[\tau]
\end{align}

The integral term decreases faster than the product of expectations, yielding negative covariance.
\end{proof}

\subsection{MILP Formulation Details}

The mixed-integer linear program solved using branch-and-bound:

\begin{align}
\min_{x} \quad & -c^T x \\
\text{subject to} \quad & Ax \leq b \\
& A_{eq}x = b_{eq} \\
& l \leq x \leq u \\
& x_i \in \{0,1\} \quad \forall i \in \mathcal{I}
\end{align}

Scipy's implementation uses:
\begin{itemize}
\item Dual simplex for LP relaxation
\item Strong branching for variable selection
\item Cutting planes for tightening
\item Presolve for problem reduction
\end{itemize}

\subsection{Heterogeneous Treatment Effect Estimation}

The X-learner algorithm:

\begin{algorithm}[H]
\caption{X-Learner for HTE Estimation}
\begin{algorithmic}[1]
\State \textbf{Stage 1:} Estimate response functions
\State $\hat{\mu}_0(x) \leftarrow$ Train on $\{(X_i, Y_i) : W_i = 0\}$
\State $\hat{\mu}_1(x) \leftarrow$ Train on $\{(X_i, Y_i) : W_i = 1\}$
\State \textbf{Stage 2:} Impute individual effects
\State $\tilde{D}_i^1 \leftarrow Y_i - \hat{\mu}_0(X_i)$ for $W_i = 1$
\State $\tilde{D}_i^0 \leftarrow \hat{\mu}_1(X_i) - Y_i$ for $W_i = 0$
\State \textbf{Stage 3:} Estimate CATE functions
\State $\hat{\tau}_0(x) \leftarrow$ Train on $\{(X_i, \tilde{D}_i^0) : W_i = 0\}$
\State $\hat{\tau}_1(x) \leftarrow$ Train on $\{(X_i, \tilde{D}_i^1) : W_i = 1\}$
\State \textbf{Stage 4:} Combine estimates
\State $\hat{\tau}(x) \leftarrow g(x)\hat{\tau}_1(x) + (1-g(x))\hat{\tau}_0(x)$
\end{algorithmic}
\end{algorithm}

\section{Simulation Code Structure}

The simulation framework consists of three main components:

\begin{enumerate}
\item \textbf{Data Generation} (causal\_optimization.py):
   \begin{itemize}
   \item Generate synthetic users with correlated $(p_0, \tau)$
   \item Calibrate to marketplace parameters
   \item Add realistic noise and heterogeneity
   \end{itemize}

\item \textbf{Optimization Solvers} (advanced\_optimizations.py):
   \begin{itemize}
   \item MILP for discrete allocation
   \item Convex optimization for continuous budgets
   \item Dynamic programming for sequential decisions
   \end{itemize}

\item \textbf{Evaluation Metrics}:
   \begin{itemize}
   \item Incremental ROAS: $\sum_i x_i \tau_i v / \sum_i x_i c_i$
   \item Incremental CPA: $\sum_i x_i c_i / \sum_i x_i \tau_i$
   \item Cannibalization rate: $\sum_{ij} \lambda_{ij} O_{ij} / \sum_{ij} P_{ij}$
   \end{itemize}
\end{enumerate}

\end{document}