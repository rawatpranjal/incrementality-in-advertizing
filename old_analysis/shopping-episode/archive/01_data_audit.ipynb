{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 Data Audit\n",
    "\n",
    "**Purpose:** Validate data integrity, join rates, and purchase mappability before panel construction.\n",
    "\n",
    "**Data Source:** `eda/data/` 365-day files\n",
    "\n",
    "**Outputs:**\n",
    "- Row counts, date ranges, unique entities\n",
    "- Join rate diagnostics (composite key validation)\n",
    "- Purchase mappability to promoted journey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DATA_DIR = Path('../eda/data')\n",
    "print(f\"Data directory: {DATA_DIR.resolve()}\")\n",
    "print(f\"Exists: {DATA_DIR.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load All Source Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading source tables...\")\n",
    "\n",
    "tables = {}\n",
    "files = [\n",
    "    ('auctions_users', 'auctions_users_365d.parquet'),\n",
    "    ('auctions_results', 'auctions_results_365d.parquet'),\n",
    "    ('impressions', 'impressions_365d.parquet'),\n",
    "    ('clicks', 'clicks_365d.parquet'),\n",
    "    ('purchases', 'purchases_365d.parquet'),\n",
    "    ('catalog', 'catalog_365d.parquet'),\n",
    "]\n",
    "\n",
    "for name, filename in tqdm(files, desc=\"Loading tables\"):\n",
    "    path = DATA_DIR / filename\n",
    "    if path.exists():\n",
    "        tables[name] = pd.read_parquet(path)\n",
    "        print(f\"  {name}: {len(tables[name]):,} rows, {tables[name].shape[1]} cols\")\n",
    "    else:\n",
    "        print(f\"  {name}: FILE NOT FOUND at {path}\")\n",
    "\n",
    "print(f\"\\nLoaded {len(tables)} tables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"TABLE SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for name, df in tables.items():\n",
    "    print(f\"\\n--- {name.upper()} ---\")\n",
    "    print(f\"Rows: {len(df):,}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    print(f\"Memory: {df.memory_usage(deep=True).sum() / 1e6:.1f} MB\")\n",
    "    \n",
    "    # Date range for timestamp columns\n",
    "    ts_cols = [c for c in df.columns if 'AT' in c.upper() or 'TIME' in c.upper() or 'DATE' in c.upper()]\n",
    "    for col in ts_cols:\n",
    "        try:\n",
    "            df[col] = pd.to_datetime(df[col])\n",
    "            print(f\"{col}: {df[col].min()} to {df[col].max()}\")\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Unique Entity Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\" * 80)\nprint(\"UNIQUE ENTITY COUNTS\")\nprint(\"=\" * 80)\n\n# Users\nuser_cols = {'auctions_users': 'OPAQUE_USER_ID', 'impressions': 'USER_ID', \n             'clicks': 'USER_ID', 'purchases': 'USER_ID'}\nprint(\"\\nUnique Users by Table:\")\nfor name, col in user_cols.items():\n    if name in tables and col in tables[name].columns:\n        n = tables[name][col].nunique()\n        print(f\"  {name}: {n:,} unique users\")\n\n# Vendors\nprint(\"\\nUnique Vendors by Table:\")\nfor name in ['auctions_results', 'impressions', 'clicks']:\n    if name in tables and 'VENDOR_ID' in tables[name].columns:\n        n = tables[name]['VENDOR_ID'].nunique()\n        print(f\"  {name}: {n:,} unique vendors\")\n\n# Products\nprint(\"\\nUnique Products by Table:\")\nfor name in ['auctions_results', 'impressions', 'clicks', 'purchases', 'catalog']:\n    if name in tables and 'PRODUCT_ID' in tables[name].columns:\n        n = tables[name]['PRODUCT_ID'].nunique()\n        print(f\"  {name}: {n:,} unique products\")\n\n# Auctions\nprint(\"\\nUnique Auctions by Table:\")\nfor name in ['auctions_users', 'auctions_results', 'impressions', 'clicks']:\n    if name in tables and 'AUCTION_ID' in tables[name].columns:\n        n = tables[name]['AUCTION_ID'].nunique()\n        print(f\"  {name}: {n:,} unique auctions\")"
  },
  {
   "cell_type": "code",
   "source": "# CRITICAL BLOCKER CHECK: User ID Coherence\nprint(\"\\n\" + \"=\" * 80)\nprint(\"BLOCKER A: USER ID COHERENCE CHECK\")\nprint(\"=\" * 80)\nprint(\"\\nAUCTIONS_USERS uses OPAQUE_USER_ID; CLICKS/IMPRESSIONS/PURCHASES use USER_ID\")\nprint(\"Must verify: Are these the same identifier or is mapping needed?\\n\")\n\nif 'auctions_users' in tables and 'clicks' in tables:\n    auctions = tables['auctions_users']\n    clicks = tables['clicks']\n    \n    opaque_users = set(auctions['OPAQUE_USER_ID'].unique())\n    click_users = set(clicks['USER_ID'].unique())\n    \n    # Check overlap\n    overlap = opaque_users & click_users\n    only_opaque = opaque_users - click_users\n    only_click = click_users - opaque_users\n    \n    print(f\"OPAQUE_USER_ID unique values: {len(opaque_users):,}\")\n    print(f\"USER_ID unique values: {len(click_users):,}\")\n    print(f\"Overlap (same IDs in both): {len(overlap):,}\")\n    print(f\"Only in OPAQUE_USER_ID: {len(only_opaque):,}\")\n    print(f\"Only in USER_ID: {len(only_click):,}\")\n    \n    overlap_rate = len(overlap) / min(len(opaque_users), len(click_users)) * 100\n    print(f\"\\nOverlap rate: {overlap_rate:.1f}%\")\n    \n    if overlap_rate > 90:\n        print(\"STATUS: IDs appear to be THE SAME identifier\")\n    elif overlap_rate > 50:\n        print(\"STATUS: PARTIAL overlap - may need investigation\")\n    else:\n        print(\"STATUS: LOW overlap - IDs may be DIFFERENT identifiers, need mapping\")\n    \n    # Check format similarity\n    print(\"\\n--- Sample ID Formats ---\")\n    print(f\"OPAQUE_USER_ID samples: {list(auctions['OPAQUE_USER_ID'].head(3))}\")\n    print(f\"USER_ID samples: {list(clicks['USER_ID'].head(3))}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# CRITICAL BLOCKER CHECK: Auction Scope\nprint(\"\\n\" + \"=\" * 80)\nprint(\"BLOCKER B: AUCTION SCOPE CHECK\")\nprint(\"=\" * 80)\nprint(\"\\nDoes AUCTIONS_USERS represent ALL searches/queries, or only when ads are served?\")\nprint(\"If only promoted, sessions built from AUCTIONS_USERS miss organic browsing.\\n\")\n\nif 'auctions_users' in tables and 'impressions' in tables:\n    auctions = tables['auctions_users']\n    impressions = tables['impressions']\n    \n    auction_ids_from_auctions = set(auctions['AUCTION_ID'].unique())\n    auction_ids_from_impressions = set(impressions['AUCTION_ID'].unique())\n    \n    # Every impression should have a parent auction\n    impressions_with_auction = len(auction_ids_from_impressions & auction_ids_from_auctions)\n    impressions_without_auction = len(auction_ids_from_impressions - auction_ids_from_auctions)\n    \n    print(f\"Auctions in AUCTIONS_USERS: {len(auction_ids_from_auctions):,}\")\n    print(f\"Auctions in IMPRESSIONS: {len(auction_ids_from_impressions):,}\")\n    print(f\"Impression auctions found in AUCTIONS_USERS: {impressions_with_auction:,}\")\n    print(f\"Impression auctions NOT in AUCTIONS_USERS: {impressions_without_auction:,}\")\n    \n    # Check if auctions >> impressions (suggests auctions without ads)\n    ratio = len(auction_ids_from_auctions) / len(auction_ids_from_impressions)\n    print(f\"\\nAuctions / Impressions ratio: {ratio:.2f}\")\n    \n    if ratio > 2:\n        print(\"STATUS: AUCTIONS_USERS likely includes searches WITHOUT promoted results\")\n        print(\"        (Good for session construction - captures organic browsing)\")\n    else:\n        print(\"STATUS: AUCTIONS_USERS may only include auctions WITH promoted results\")\n        print(\"        (Sessions will miss organic-only browsing activity)\")\n\nif 'auctions_results' in tables:\n    bids = tables['auctions_results']\n    auction_ids_from_bids = set(bids['AUCTION_ID'].unique())\n    \n    # How many auctions have bids but no impressions?\n    bids_without_impressions = len(auction_ids_from_bids - auction_ids_from_impressions)\n    print(f\"\\nAuctions with bids but no impressions: {bids_without_impressions:,}\")\n    print(\"(These are auctions where ads were bid but not shown)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Join Rate Diagnostics\n",
    "\n",
    "Test composite key joins: `AUCTION_ID + PRODUCT_ID + VENDOR_ID + CAMPAIGN_ID`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"JOIN RATE DIAGNOSTICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Define join keys\n",
    "COMPOSITE_KEYS = ['AUCTION_ID', 'PRODUCT_ID', 'VENDOR_ID', 'CAMPAIGN_ID']\n",
    "MINIMAL_KEYS = ['AUCTION_ID', 'PRODUCT_ID']\n",
    "\n",
    "# Check which tables have which keys\n",
    "print(\"\\nKey availability by table:\")\n",
    "for name, df in tables.items():\n",
    "    available = [k for k in COMPOSITE_KEYS if k in df.columns]\n",
    "    print(f\"  {name}: {available}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join clicks to auctions_results (bids)\n",
    "print(\"\\n--- CLICKS -> AUCTIONS_RESULTS (bids) ---\")\n",
    "if 'clicks' in tables and 'auctions_results' in tables:\n",
    "    clicks = tables['clicks']\n",
    "    bids = tables['auctions_results']\n",
    "    \n",
    "    # Find common keys\n",
    "    common_keys = [k for k in COMPOSITE_KEYS if k in clicks.columns and k in bids.columns]\n",
    "    print(f\"Common keys: {common_keys}\")\n",
    "    \n",
    "    # Create composite keys\n",
    "    clicks_keys = clicks[common_keys].drop_duplicates()\n",
    "    bids_keys = bids[common_keys].drop_duplicates()\n",
    "    \n",
    "    # Forward join (clicks that have matching bids)\n",
    "    merged = clicks_keys.merge(bids_keys, on=common_keys, how='inner')\n",
    "    forward_rate = len(merged) / len(clicks_keys) * 100\n",
    "    print(f\"Clicks with matching bids: {len(merged):,} / {len(clicks_keys):,} ({forward_rate:.1f}%)\")\n",
    "    \n",
    "    # Backward join (bids that have matching clicks)\n",
    "    backward_rate = len(merged) / len(bids_keys) * 100\n",
    "    print(f\"Bids with matching clicks: {len(merged):,} / {len(bids_keys):,} ({backward_rate:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join impressions to auctions_results\n",
    "print(\"\\n--- IMPRESSIONS -> AUCTIONS_RESULTS (bids) ---\")\n",
    "if 'impressions' in tables and 'auctions_results' in tables:\n",
    "    impressions = tables['impressions']\n",
    "    bids = tables['auctions_results']\n",
    "    \n",
    "    common_keys = [k for k in COMPOSITE_KEYS if k in impressions.columns and k in bids.columns]\n",
    "    print(f\"Common keys: {common_keys}\")\n",
    "    \n",
    "    imp_keys = impressions[common_keys].drop_duplicates()\n",
    "    bids_keys = bids[common_keys].drop_duplicates()\n",
    "    \n",
    "    merged = imp_keys.merge(bids_keys, on=common_keys, how='inner')\n",
    "    forward_rate = len(merged) / len(imp_keys) * 100\n",
    "    print(f\"Impressions with matching bids: {len(merged):,} / {len(imp_keys):,} ({forward_rate:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join clicks to impressions\n",
    "print(\"\\n--- CLICKS -> IMPRESSIONS ---\")\n",
    "if 'clicks' in tables and 'impressions' in tables:\n",
    "    clicks = tables['clicks']\n",
    "    impressions = tables['impressions']\n",
    "    \n",
    "    common_keys = [k for k in COMPOSITE_KEYS if k in clicks.columns and k in impressions.columns]\n",
    "    print(f\"Common keys: {common_keys}\")\n",
    "    \n",
    "    clicks_keys = clicks[common_keys].drop_duplicates()\n",
    "    imp_keys = impressions[common_keys].drop_duplicates()\n",
    "    \n",
    "    merged = clicks_keys.merge(imp_keys, on=common_keys, how='inner')\n",
    "    forward_rate = len(merged) / len(clicks_keys) * 100\n",
    "    print(f\"Clicks with matching impressions: {len(merged):,} / {len(clicks_keys):,} ({forward_rate:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join auctions_results to auctions_users\n",
    "print(\"\\n--- AUCTIONS_RESULTS -> AUCTIONS_USERS ---\")\n",
    "if 'auctions_results' in tables and 'auctions_users' in tables:\n",
    "    bids = tables['auctions_results']\n",
    "    auctions = tables['auctions_users']\n",
    "    \n",
    "    bids_auctions = bids['AUCTION_ID'].unique()\n",
    "    auctions_ids = set(auctions['AUCTION_ID'].unique())\n",
    "    \n",
    "    matched = sum(1 for a in bids_auctions if a in auctions_ids)\n",
    "    rate = matched / len(bids_auctions) * 100\n",
    "    print(f\"Bid auctions with user info: {matched:,} / {len(bids_auctions):,} ({rate:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Purchase Mappability to Promoted Journey\n",
    "\n",
    "How many purchases can we reliably link to a promoted click?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"PURCHASE MAPPABILITY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if 'purchases' in tables and 'clicks' in tables:\n",
    "    purchases = tables['purchases'].copy()\n",
    "    clicks = tables['clicks'].copy()\n",
    "    \n",
    "    print(f\"\\nTotal purchases: {len(purchases):,}\")\n",
    "    print(f\"Total clicks: {len(clicks):,}\")\n",
    "    \n",
    "    # Parse timestamps\n",
    "    purchases['PURCHASED_AT'] = pd.to_datetime(purchases['PURCHASED_AT'])\n",
    "    clicks['OCCURRED_AT'] = pd.to_datetime(clicks['OCCURRED_AT'])\n",
    "    \n",
    "    # Calculate spend\n",
    "    purchases['spend'] = purchases['QUANTITY'] * purchases['UNIT_PRICE'] / 100  # cents to dollars\n",
    "    total_spend = purchases['spend'].sum()\n",
    "    print(f\"Total spend: ${total_spend:,.2f}\")\n",
    "    \n",
    "    # Get unique (user, product) pairs from clicks with vendor info\n",
    "    click_user_product = clicks[['USER_ID', 'PRODUCT_ID', 'VENDOR_ID', 'CAMPAIGN_ID']].drop_duplicates()\n",
    "    print(f\"\\nUnique (user, product) pairs in clicks: {len(click_user_product):,}\")\n",
    "    \n",
    "    # Join purchases to clicks on (user, product)\n",
    "    purchases_with_click = purchases.merge(\n",
    "        click_user_product,\n",
    "        left_on=['USER_ID', 'PRODUCT_ID'],\n",
    "        right_on=['USER_ID', 'PRODUCT_ID'],\n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    n_mapped = len(purchases_with_click)\n",
    "    spend_mapped = purchases_with_click['spend'].sum()\n",
    "    \n",
    "    print(f\"\\n--- Mappability (user + product match) ---\")\n",
    "    print(f\"Purchases mappable: {n_mapped:,} / {len(purchases):,} ({n_mapped/len(purchases)*100:.1f}%)\")\n",
    "    print(f\"Spend mappable: ${spend_mapped:,.2f} / ${total_spend:,.2f} ({spend_mapped/total_spend*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More strict: same-day or within-window purchase after click\n",
    "print(\"\\n--- Mappability with time constraint ---\")\n",
    "\n",
    "if 'purchases' in tables and 'clicks' in tables:\n",
    "    # For each user-product pair, get earliest click time\n",
    "    first_clicks = clicks.groupby(['USER_ID', 'PRODUCT_ID'])['OCCURRED_AT'].min().reset_index()\n",
    "    first_clicks.columns = ['USER_ID', 'PRODUCT_ID', 'first_click_time']\n",
    "    \n",
    "    # Join to purchases\n",
    "    purchases_timed = purchases.merge(first_clicks, on=['USER_ID', 'PRODUCT_ID'], how='left')\n",
    "    \n",
    "    # Check different windows\n",
    "    for window_days in [0, 1, 7, 14, 30]:\n",
    "        if window_days == 0:\n",
    "            mask = purchases_timed['first_click_time'].notna() & \\\n",
    "                   (purchases_timed['PURCHASED_AT'].dt.date == purchases_timed['first_click_time'].dt.date)\n",
    "            label = \"Same day\"\n",
    "        else:\n",
    "            mask = purchases_timed['first_click_time'].notna() & \\\n",
    "                   (purchases_timed['PURCHASED_AT'] >= purchases_timed['first_click_time']) & \\\n",
    "                   (purchases_timed['PURCHASED_AT'] <= purchases_timed['first_click_time'] + pd.Timedelta(days=window_days))\n",
    "            label = f\"Within {window_days}d\"\n",
    "        \n",
    "        n = mask.sum()\n",
    "        spend = purchases_timed.loc[mask, 'spend'].sum()\n",
    "        print(f\"  {label}: {n:,} purchases ({n/len(purchases)*100:.1f}%), ${spend:,.2f} ({spend/total_spend*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click-to-purchase lag distribution\n",
    "print(\"\\n--- Click-to-Purchase Lag Distribution ---\")\n",
    "\n",
    "if 'purchases_timed' in dir():\n",
    "    # Only for mapped purchases\n",
    "    mapped = purchases_timed[purchases_timed['first_click_time'].notna()].copy()\n",
    "    mapped['lag_hours'] = (mapped['PURCHASED_AT'] - mapped['first_click_time']).dt.total_seconds() / 3600\n",
    "    \n",
    "    # Only positive lags (purchase after click)\n",
    "    positive_lag = mapped[mapped['lag_hours'] >= 0]\n",
    "    \n",
    "    print(f\"Purchases with positive lag: {len(positive_lag):,}\")\n",
    "    print(f\"\\nLag (hours) statistics:\")\n",
    "    print(positive_lag['lag_hours'].describe())\n",
    "    \n",
    "    # Percentiles\n",
    "    print(f\"\\nLag percentiles:\")\n",
    "    for p in [10, 25, 50, 75, 90, 95, 99]:\n",
    "        val = positive_lag['lag_hours'].quantile(p/100)\n",
    "        print(f\"  P{p}: {val:.1f} hours ({val/24:.1f} days)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Vendor Coverage in Purchases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"VENDOR COVERAGE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if 'purchases_with_click' in dir():\n",
    "    # Vendors in mapped purchases\n",
    "    vendors_in_purchases = purchases_with_click['VENDOR_ID'].nunique()\n",
    "    vendors_in_clicks = clicks['VENDOR_ID'].nunique()\n",
    "    \n",
    "    print(f\"\\nVendors with mapped purchases: {vendors_in_purchases:,}\")\n",
    "    print(f\"Vendors in clicks: {vendors_in_clicks:,}\")\n",
    "    print(f\"Coverage: {vendors_in_purchases/vendors_in_clicks*100:.1f}%\")\n",
    "    \n",
    "    # Top vendors by mapped spend\n",
    "    print(f\"\\nTop 10 vendors by mapped spend:\")\n",
    "    top_vendors = purchases_with_click.groupby('VENDOR_ID')['spend'].sum().sort_values(ascending=False).head(10)\n",
    "    for i, (vendor, spend) in enumerate(top_vendors.items(), 1):\n",
    "        print(f\"  {i}. {vendor[:20]}...: ${spend:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary Statistics for Panel Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"SUMMARY FOR PANEL CONSTRUCTION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "summary = {\n",
    "    'n_users_clicks': clicks['USER_ID'].nunique() if 'clicks' in tables else 0,\n",
    "    'n_users_purchases': purchases['USER_ID'].nunique() if 'purchases' in tables else 0,\n",
    "    'n_vendors': bids['VENDOR_ID'].nunique() if 'auctions_results' in tables else 0,\n",
    "    'n_products_clicks': clicks['PRODUCT_ID'].nunique() if 'clicks' in tables else 0,\n",
    "    'n_clicks': len(clicks) if 'clicks' in tables else 0,\n",
    "    'n_impressions': len(impressions) if 'impressions' in tables else 0,\n",
    "    'n_purchases': len(purchases) if 'purchases' in tables else 0,\n",
    "    'total_spend': total_spend if 'total_spend' in dir() else 0,\n",
    "    'mappable_spend': spend_mapped if 'spend_mapped' in dir() else 0,\n",
    "    'mappable_rate': spend_mapped/total_spend*100 if 'spend_mapped' in dir() else 0,\n",
    "}\n",
    "\n",
    "print(\"\\nKey Metrics:\")\n",
    "for k, v in summary.items():\n",
    "    if 'rate' in k:\n",
    "        print(f\"  {k}: {v:.1f}%\")\n",
    "    elif 'spend' in k:\n",
    "        print(f\"  {k}: ${v:,.2f}\")\n",
    "    else:\n",
    "        print(f\"  {k}: {v:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date range for analysis\n",
    "print(\"\\n--- Date Range ---\")\n",
    "if 'clicks' in tables:\n",
    "    print(f\"Clicks: {clicks['OCCURRED_AT'].min()} to {clicks['OCCURRED_AT'].max()}\")\n",
    "if 'purchases' in tables:\n",
    "    print(f\"Purchases: {purchases['PURCHASED_AT'].min()} to {purchases['PURCHASED_AT'].max()}\")\n",
    "\n",
    "# Weeks available\n",
    "if 'clicks' in tables:\n",
    "    clicks['week'] = clicks['OCCURRED_AT'].dt.isocalendar().week\n",
    "    clicks['year'] = clicks['OCCURRED_AT'].dt.year\n",
    "    n_weeks = clicks.groupby(['year', 'week']).size().shape[0]\n",
    "    print(f\"\\nWeeks with click data: {n_weeks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"AUDIT COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nReady for 02_canonical_tables.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}