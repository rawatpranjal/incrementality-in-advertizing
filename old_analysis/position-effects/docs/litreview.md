# Statistical Click Models for Search and Advertising: A Comprehensive Literature Review

The examination hypothesis—that clicks occur if and only if users both examine and find results attractive—forms the unifying foundation of statistical click models in information retrieval. This framework, articulated by **Craswell et al. (2008)** and systematized in the definitive survey by **Chuklin, Markov, and de Rijke (2015)**, enables researchers to decompose observed click behavior into separable position effects (examination probability) and item-level relevance (attractiveness), without requiring explicit utility specifications. The key models emerged primarily from 2008-2009, with Microsoft, Yahoo, and academic researchers contributing foundational papers, followed by a rich literature on estimation, identification, and applications to e-commerce and advertising contexts.

## The examination hypothesis and core model families

All major click models share a common structure: the probability of clicking result $u$ at position $r$ decomposes as P(Click) = P(Examine | position) × P(Attractive | query-document). What distinguishes models is how they specify examination probability—whether it depends only on position, on previous clicks, or on document-specific satisfaction.

The **Position-Based Model (PBM)**, introduced by Craswell et al. (2008) at WSDM, represents the simplest implementation: examination probability $\gamma_r$ depends only on rank, while attractiveness $\alpha_{uq}$ depends on the query-document pair. This independence assumption makes estimation straightforward but ignores sequential dependencies in browsing behavior. PBM serves as the workhorse model for position bias correction in practical systems due to its simplicity and interpretability.

The **Cascade Model**, also from Craswell et al. (2008), captures sequential top-to-bottom browsing with an important behavioral constraint: users stop examining after their first click. This deterministic examination structure—where examination at position $r$ requires examination but no click at position $r-1$—means examination states are observable from click data, enabling maximum likelihood estimation rather than EM. The cascade assumption remains foundational but restricts the model to single-click sessions.

**Chapelle and Zhang (2009)** at Yahoo introduced the **Dynamic Bayesian Network (DBN) model** to address multi-click sessions. DBN adds a satisfaction probability $\sigma_{uq}$ representing whether a clicked document actually satisfies the user's need. Users continue examining with probability $\gamma$ only if unsatisfied after clicking. The graphical model structure—with observed click nodes and latent examination, attractiveness, and satisfaction nodes—enables principled inference via forward-backward algorithms. The Simplified DBN (SDBN) variant with $\gamma = 1$ reduces to tractable MLE.

**Dupret and Piwowarski (2008)** proposed the **User Browsing Model (UBM)** at SIGIR, which generalizes PBM by making examination probability $\gamma_{r,r'}$ depend on both current position $r$ and the position $r'$ of the previous click. This captures the intuition that users may return to lower results after clicking, with examination decaying differently depending on where the previous click occurred. UBM requires $M(M+1)/2$ examination parameters versus $M-1$ for cascade-based models, representing a bias-variance tradeoff.

**Guo et al. (2009)** contributed two important extensions. The **Dependent Click Model (DCM)** at WSDM adds position-dependent continuation probabilities $\lambda_r$ after clicks, allowing multi-click sessions while maintaining cascade structure. The **Click Chain Model (CCM)** at WWW distinguishes three continuation scenarios: continuing after skipping a result ($\tau_1$), after an unsatisfying click ($\tau_2$), and after a satisfying click ($\tau_3$). CCM uniquely models user abandonment without clicking, using Bayesian inference for relevance estimation at scale.

## Identification and estimation strategies

The fundamental identification challenge is that examination is unobserved—we see clicks but not whether users looked at each result. **Identification relies on observing the same items at different positions** (to identify position effects) and **the same positions with different items** (to identify relevance effects). This variation can come from natural rank changes over time or controlled randomization.

EM algorithms form the primary estimation approach for models with latent variables. The E-step computes expected sufficient statistics for examination given observed clicks and current parameters; the M-step updates attractiveness and examination parameters to maximize expected log-likelihood. For UBM, **Dupret and Piwowarski (2008)** derived update rules involving P(A=1|C) and P(E=1|C) conditioned on click observations. For DBN, **Chapelle and Zhang (2009)** used forward-backward propagation to efficiently compute posteriors over the latent satisfaction variable.

**Wang et al. (2018)** at WSDM developed a regression-based EM approach for position bias estimation in personal search (Gmail, Drive) that handles highly sparse clicks without result randomization. Their method extracts position bias from regular click logs by exploiting natural query-document rank variation over time. **Agarwal et al. (2019)** at WSDM proposed an "AllPairs" extremum estimator that harvests intervention data from historical logs where ranking algorithm updates caused the same items to appear at different positions—effectively creating natural experiments without degrading user experience.

Bayesian alternatives offer advantages for rare queries. **Liu et al. (2009)** introduced the Bayesian Browsing Model (BBM) at KDD, placing uniform priors on attractiveness to derive posterior distributions rather than point estimates. **Zhang et al. (2010)** developed hierarchical versions (H-UBM, H-CCM, H-DBN) with normal priors enabling Gaussian density filtering for online updates. These approaches provide uncertainty quantification and better small-sample behavior.

For identification from scroll depth, cascade-based models assume examination is deterministic given clicks—all results above the last click were examined. When viewport data is available, **Liu et al. (2021)** proposed the Comparison-based Click Model (CBCM) incorporating explicit examination viewports. Mobile-specific models like the **Mobile Click Model (MCM)** from **Mao et al. (2018)** at SIGIR address click necessity bias (some results provide utility without clicks) and examination satisfaction bias particular to small-screen contexts.

## Position randomization experiments and the survival analysis connection

**Craswell et al. (2008)** established the experimental paradigm by deliberately "flipping" document pairs on a major search engine, comparing click distributions in orderings AB versus BA. This revealed that the cascade model best explains position bias in early ranks—users view top-to-bottom and leave when finding worthwhile documents.

**Joachims et al. (2005, 2007)** combined eye-tracking with click analysis to demonstrate that while clicks cannot serve as absolute relevance judgments, relative preferences derived from clicks are reasonably accurate on average. Their work established the trust bias phenomenon: users trust higher-ranked results independent of actual relevance. The seminal **Joachims, Swaminathan, and Schnabel (2017)** WSDM paper formalized the counterfactual inference framework for unbiased learning-to-rank, introducing propensity-weighted ranking SVM and demonstrating robustness to propensity misspecification.

Randomization methods span a spectrum of intrusiveness. **Full randomization** provides cleanest identification but worst user experience. **RandTopN** shuffles only top positions. **RandPair/FairPairs** swaps adjacent items with minimal disruption—Thumbtack allocated 50% of traffic to adjacent pair swapping at positions 1-2 through 10-11. **Demsyn-Jones (2024)** documented that marketplace search shows distinct patterns from web search: **30% of two-contact sessions** in their data showed reverse order browsing (lower-ranked professional contacted first), suggesting cascade assumptions may be too restrictive for C2C platforms.

The cascade model has deep structural parallels to survival analysis. Position functions as "time," with users progressing sequentially through ranks. Clicks represent the "failure event"—users "survive" (continue browsing) until clicking. The hazard rate interpretation frames click probability as h(k) = P(click at position k | survived to position k). The DBN satisfaction parameter mirrors cure fractions in survival models—satisfied users exit the hazard set. These connections relate click modeling to **Weitzman (1979)** optimal search theory and Pandora's box problems, where sequential inspection with stopping rules trades inspection costs against expected gains.

## Inverse propensity weighting and unbiased learning to rank

The IPW framework treats clicks as biased observations of relevance, reweighting by inverse examination probability. If propensity θ_k = P(Examine | position k), the IPW loss weights each click by 1/θ_k, theoretically debiasing the training signal. **Joachims et al. (2017)** showed that with correctly specified propensities, models trained on click data converge to those trained on true relevance.

**Ai et al. (2018)** at SIGIR introduced the **Dual Learning Algorithm (DLA)**, jointly learning propensity and ranking models by treating propensity estimation as the dual problem of unbiased LTR. This eliminates separate randomization experiments and adapts to changing bias distributions—critical for online learning. DLA outperformed both result-randomization methods and click model baselines.

**Wang et al. (2021)** proposed Propensity Ratio Scoring (PRS) to address that standard IPS ignores bias from treating non-clicks as irrelevant, providing treatments on both clicks and non-clicks with lower variance. **Oosterhuis (2023)** in ACM TOIS developed doubly-robust estimation for position bias correction, combining IPS with regression predictions. Because examination is unobservable, standard DR is inapplicable; the solution uses expected treatment per rank, achieving orders of magnitude variance reduction compared to IPS alone.

Advanced methods include **Vardasbi et al. (2020)** on affine corrections for trust bias, user-aware ULTR with personalized propensities, and cascade-based IPS adapting propensity estimation to sequential click behavior. The **CLAX framework (Hager et al., 2025)** implements 10 classic click models with gradient-based optimization, scaling to billions of sessions on single GPUs—orders of magnitude faster than EM.

## E-commerce and marketplace applications

Click models developed for web search require adaptation for e-commerce contexts. **Product search** involves purchase intent rather than information seeking, with price and images affecting clicks alongside relevance. **Zhou et al. (2018)** at KDD introduced the **Deep Interest Network (DIN)** for Alibaba's display advertising, using local activation units to adaptively learn user interest representations, achieving **9.2% AUC improvement** in Taobao's advertising system. The subsequent **Deep Interest Evolution Network (DIEN)** added temporal interest evolution, yielding **20.7% CTR improvement** in online deployment.

**Wang et al. (2023)** at SIGIR developed Position-Aware Click-Conversion (PACC) models for Walmart sponsored ads, jointly mitigating position bias in both CTR and conversion rate prediction. Their key assumptions—that viewing depends only on position while purchase decisions are position-independent after viewing—generalize examination hypothesis to purchase behavior.

Marketplace search presents distinct challenges. **Aslanyan and Porwal (2019)** at SPIRE developed position bias estimation for eBay that exploits natural rank changes over time (item popularity shifts, time-dependent features) without live search intervention. **Aryafar and Guillory (2017)** at KDD described Etsy's CTR prediction system, using ensemble approaches combining historical signals for established listings with content-based deep learning for new listings lacking behavioral data.

**Fu et al. (2023)** at WSDM addressed mobile app store search with the **F-shape Click Model (FSCM)**, handling multi-block page layouts where users browse both vertically and horizontally. Their analysis showed dramatic position effects: the same app receives **30% fewer clicks at position 2 versus 1** and **75% fewer at position 4**. DAG-structured GRUs capture browsing across vertical and horizontal blocks, with users preferring vertical blocks even at lower ranks due to richer descriptions.

## Organic versus sponsored result competition

The interaction between organic and sponsored clicks creates identification challenges and economic consequences. **Danescu-Niculescu-Mizil et al. (2010)** at WWW demonstrated that for navigational queries, organic and sponsored results compete directly, while for non-navigational queries, competition becomes synergy. They distinguished responsive ads (directly addressing user needs, seen as duplicative alongside organic results) from incidental ads (tangentially related, providing complementary value).

**Yang and Ghose (2010)** in Marketing Science developed simultaneous models of search, click, and purchase behavior using autologistic models with MCMC estimation. Their key finding: **organic clicks' impact on paid utility is 3.5× stronger than vice versa**, with interdependence increasing expected profits by 4.2-6.15%. Google's ad pause studies across 400+ accounts found **89% of paid clicks are incremental**—not replaced by organic clicks when ads pause.

**Simonov, Nosko, and Rao (2018)** in Marketing Science ran large-scale Bing experiments on brand keyword competition. Without competitors, brand ads show 1-4% positive impact (larger brands showing smaller effects). Competitors in positions 2-4 can "steal" 1-5% of focal brand clicks, demonstrating substitution patterns between organic and sponsored listings.

Recent Amazon marketplace studies reveal concerning patterns. **Dash et al. (2024)** analyzed 4,800 search operations across 4 countries, finding items with poor organic ranks (beyond position 100) appearing as sponsored results before top organic results, with sponsored items typically costlier and lower quality. **Rock et al. (2024)** found the top-3 most clicked ads are **17% more expensive and one-third less relevant** than organic counterparts, with users showing decreased price and relevance sensitivity within the top 5 positions (typically 4 are ads).

## User heterogeneity and mixture models

Users exhibit distinct browsing patterns—some scan all results (explorers), others satisfice after finding acceptable results. **Zhang et al. (2011)** at KDD proposed the Task-Centric Click Model (TCM), identifying two key biases: users express information needs incrementally across multiple queries, and prefer fresh documents not seen previously. **Nottorf (2014)** used Bayesian mixture of normals to identify distinct consumer types with different click propensities (resistant versus susceptible users).

The Multi-gate Mixture-of-Experts (MMoE) architecture from **Ma et al. (2018)** uses gate networks to weight expert representations based on input context, capturing heterogeneous user populations in CTR prediction. **Borisov et al. (2016)** at WWW proposed neural click models using distributed representations to capture diverse browsing behaviors without manual dependency specification—representing a shift from explicit probabilistic graphical models to learned representations.

## Model validation and testable implications

**Grotov et al. (2015)** systematically compared 10 click models (GCTR, RCTR, DCTR, PBM, CM, UBM, DCM, CCM, DBN, SDBN) across metrics including log-likelihood, perplexity, CTR prediction RMSE, relevance AUC, and ranking NDCG. **No single model excels on all metrics**: UBM achieves highest log-likelihood, DBN/SDBN best perplexity, CCM best ranking performance. Relevance prediction remains challenging (AUC 0.50-0.58 range).

**Deffayet et al. (2023)** in ACM TOIS evaluated robustness to policy distributional shift, showing click models are sensitive to ranking policy changes and conventional metrics don't guarantee generalization. They proposed CMIP (Conditional Mutual Information with Logging Policy) to test whether relevance estimates are independent of the logging policy. **Mao et al. (2019)** used variational Bayesian inference to obtain posterior distributions, defining reliability measures affected by training data size, average ranking position, and search engine strategy.

Calibration testing via reliability diagrams reveals systematic biases: models tend to underestimate clicks at rank 1 and overestimate at lower ranks. **Borisov et al. (2018)** showed isotonic regression improves calibration. Notably, the **Baidu-ULTR benchmark (Zou et al., 2022)** found standard ULTR methods (IPS, DLA, RegressionEM, PairD) did not significantly outperform naive BERT trained on raw clicks—suggesting the field requires better benchmarks and methods.

## Conclusion: methodological landscape and research directions

Statistical click models have evolved from simple position-based corrections through sophisticated Bayesian networks to neural architectures, unified by the examination hypothesis framework. The field's key contributions include the separation of position effects from relevance through the examination-attractiveness decomposition, EM algorithms exploiting variation in item-position assignments, IPW-based unbiased learning to rank, and careful experimental designs balancing identification strength against user experience.

For marketplace and advertising applications, critical considerations include organic-sponsored competition effects, heterogeneous browsing behavior across user types, and the distinct examination patterns on mobile devices with multi-block layouts. The survival analysis connection—viewing position as time and clicks as hazard events—provides both mathematical elegance and intuition for model structure.

Open challenges remain in model validation under policy shift, extending to richer feedback signals beyond binary clicks, handling settings where only partial observations (e.g., only sponsored clicks) are logged, and developing computationally efficient methods that scale to billions of sessions while maintaining principled uncertainty quantification. The emergence of learned representations alongside traditional graphical models suggests productive synthesis between statistical click models and deep learning approaches lies ahead.
