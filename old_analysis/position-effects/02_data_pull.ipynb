{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SUCCESS] Connected to Snowflake\n"
     ]
    }
   ],
   "source": [
    "# CELL 1: IMPORTS + CONNECTION (run once, handles duo)\n",
    "import os\n",
    "import textwrap\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import snowflake.connector\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "load_dotenv()\n",
    "\n",
    "OUTPUT_DIR = Path(\"./data_r2\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "conn = snowflake.connector.connect(\n",
    "    user=os.getenv('SNOWFLAKE_USER'),\n",
    "    password=os.getenv('SNOWFLAKE_PASSWORD'),\n",
    "    account=os.getenv('SNOWFLAKE_ACCOUNT'),\n",
    "    warehouse=os.getenv('SNOWFLAKE_WAREHOUSE', 'COMPUTE_WH'),\n",
    "    database='INCREMENTALITY',\n",
    "    schema='INCREMENTALITY_RESEARCH'\n",
    ")\n",
    "print(\"[SUCCESS] Connected to Snowflake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Round 2] Pulling 60min, ALL placements, 1% users...\n",
      "Expected yield: ~80K auctions, ~7K users, ~24K clicks, ~770K impressions\n",
      "\n",
      "1/6 AUCTIONS_USERS...\n",
      "  91,802 rows, 7,709 users\n",
      "  Placements: {'3': 55201, '1': 17358, '5': 9740, '2': 9503}\n",
      "\n",
      "2/6 AUCTIONS_RESULTS...\n",
      "  4,337,598 rows\n",
      "\n",
      "3/6 IMPRESSIONS...\n",
      "  226,939 rows\n",
      "\n",
      "4/6 CLICKS...\n",
      "  7,151 rows\n",
      "\n",
      "5/6 PURCHASES...\n",
      "  882 rows, 593 users\n",
      "  Total revenue: $3,995,900\n",
      "\n",
      "6/6 CATALOG...\n",
      "  Products to fetch: 160,381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Catalog: 100%|██████████| 17/17 [18:04<00:00, 63.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  159,888 rows\n",
      "\n",
      "Saving parquet files...\n",
      "\n",
      "==================================================\n",
      "DONE - Round 2\n",
      "==================================================\n",
      "auctions_users:   91,802 (7,709 users)\n",
      "auctions_results: 4,337,598\n",
      "impressions:      226,939\n",
      "clicks:           7,151\n",
      "purchases:        882\n",
      "catalog:          159,888\n"
     ]
    }
   ],
   "source": [
    "# CELL 2: DATA PULL (Round 2 - expanded parameters)\n",
    "# CONFIG\n",
    "MINUTES_WINDOW = 60  # 60 minutes (was 15 in R1)\n",
    "SAMPLE_FRACTION = 0.01  # 1% of users (same as R1)\n",
    "TOTAL_BUCKETS = 10000\n",
    "SELECTION_THRESHOLD = int(TOTAL_BUCKETS * SAMPLE_FRACTION)\n",
    "\n",
    "print(f\"[Round 2] Pulling {MINUTES_WINDOW}min, ALL placements, {SAMPLE_FRACTION:.0%} users...\")\n",
    "print(f\"Expected yield: ~80K auctions, ~7K users, ~24K clicks, ~770K impressions\")\n",
    "\n",
    "# CTE for deterministic user sampling (all placements)\n",
    "CTE_SQL = f\"\"\"\n",
    "WITH SAMPLED_USERS AS (\n",
    "    SELECT OPAQUE_USER_ID FROM (\n",
    "        SELECT OPAQUE_USER_ID, MOD(ABS(HASH(OPAQUE_USER_ID)), {TOTAL_BUCKETS}) AS bucket\n",
    "        FROM (SELECT DISTINCT OPAQUE_USER_ID FROM AUCTIONS_USERS \n",
    "              WHERE CREATED_AT >= DATEADD(minute, -{MINUTES_WINDOW}, CURRENT_TIMESTAMP()))\n",
    "    ) WHERE bucket < {SELECTION_THRESHOLD}\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# 1. AUCTIONS_USERS\n",
    "print(\"\\n1/6 AUCTIONS_USERS...\")\n",
    "auctions_users = pd.read_sql(CTE_SQL + f\"\"\"\n",
    "SELECT LOWER(TO_VARCHAR(au.AUCTION_ID, 'HEX')) AS AUCTION_ID,\n",
    "       au.OPAQUE_USER_ID AS USER_ID, au.PLACEMENT, au.CREATED_AT\n",
    "FROM AUCTIONS_USERS au\n",
    "JOIN SAMPLED_USERS s ON au.OPAQUE_USER_ID = s.OPAQUE_USER_ID\n",
    "WHERE au.CREATED_AT >= DATEADD(minute, -{MINUTES_WINDOW}, CURRENT_TIMESTAMP())\n",
    "\"\"\", conn)\n",
    "print(f\"  {len(auctions_users):,} rows, {auctions_users['USER_ID'].nunique():,} users\")\n",
    "print(f\"  Placements: {auctions_users['PLACEMENT'].value_counts().to_dict()}\")\n",
    "\n",
    "# 2. AUCTIONS_RESULTS\n",
    "print(\"\\n2/6 AUCTIONS_RESULTS...\")\n",
    "auctions_results = pd.read_sql(CTE_SQL + f\"\"\"\n",
    "SELECT LOWER(TO_VARCHAR(ar.AUCTION_ID, 'HEX')) AS AUCTION_ID,\n",
    "       LOWER(TO_VARCHAR(ar.VENDOR_ID, 'HEX')) AS VENDOR_ID,\n",
    "       LOWER(TO_VARCHAR(ar.CAMPAIGN_ID, 'HEX')) AS CAMPAIGN_ID,\n",
    "       LOWER(TRIM(ar.PRODUCT_ID)) AS PRODUCT_ID,\n",
    "       ar.RANKING, ar.IS_WINNER, ar.FINAL_BID, ar.QUALITY,\n",
    "       ar.CONVERSION_RATE, ar.PACING, ar.PRICE, ar.CREATED_AT\n",
    "FROM AUCTIONS_RESULTS ar\n",
    "JOIN AUCTIONS_USERS au ON ar.AUCTION_ID = au.AUCTION_ID\n",
    "JOIN SAMPLED_USERS s ON au.OPAQUE_USER_ID = s.OPAQUE_USER_ID\n",
    "WHERE ar.CREATED_AT >= DATEADD(minute, -{MINUTES_WINDOW}, CURRENT_TIMESTAMP())\n",
    "\"\"\", conn)\n",
    "print(f\"  {len(auctions_results):,} rows\")\n",
    "\n",
    "# 3. IMPRESSIONS\n",
    "print(\"\\n3/6 IMPRESSIONS...\")\n",
    "impressions = pd.read_sql(CTE_SQL + f\"\"\"\n",
    "SELECT i.INTERACTION_ID, LOWER(REPLACE(i.AUCTION_ID, '-', '')) AS AUCTION_ID,\n",
    "       LOWER(TRIM(i.PRODUCT_ID)) AS PRODUCT_ID, i.USER_ID,\n",
    "       LOWER(REPLACE(i.CAMPAIGN_ID, '-', '')) AS CAMPAIGN_ID,\n",
    "       LOWER(REPLACE(i.VENDOR_ID, '-', '')) AS VENDOR_ID, i.OCCURRED_AT\n",
    "FROM IMPRESSIONS i\n",
    "JOIN SAMPLED_USERS s ON i.USER_ID = s.OPAQUE_USER_ID\n",
    "WHERE i.OCCURRED_AT >= DATEADD(minute, -{MINUTES_WINDOW}, CURRENT_TIMESTAMP())\n",
    "\"\"\", conn)\n",
    "print(f\"  {len(impressions):,} rows\")\n",
    "\n",
    "# 4. CLICKS\n",
    "print(\"\\n4/6 CLICKS...\")\n",
    "clicks = pd.read_sql(CTE_SQL + f\"\"\"\n",
    "SELECT c.INTERACTION_ID, LOWER(REPLACE(c.AUCTION_ID, '-', '')) AS AUCTION_ID,\n",
    "       LOWER(TRIM(c.PRODUCT_ID)) AS PRODUCT_ID, c.USER_ID,\n",
    "       LOWER(REPLACE(c.CAMPAIGN_ID, '-', '')) AS CAMPAIGN_ID,\n",
    "       LOWER(REPLACE(c.VENDOR_ID, '-', '')) AS VENDOR_ID, c.OCCURRED_AT\n",
    "FROM CLICKS c\n",
    "JOIN SAMPLED_USERS s ON c.USER_ID = s.OPAQUE_USER_ID\n",
    "WHERE c.OCCURRED_AT >= DATEADD(minute, -{MINUTES_WINDOW}, CURRENT_TIMESTAMP())\n",
    "\"\"\", conn)\n",
    "print(f\"  {len(clicks):,} rows\")\n",
    "\n",
    "# 5. PURCHASES (new in R2)\n",
    "print(\"\\n5/6 PURCHASES...\")\n",
    "purchases = pd.read_sql(CTE_SQL + f\"\"\"\n",
    "SELECT p.PURCHASE_ID,\n",
    "       LOWER(TRIM(p.PRODUCT_ID)) AS PRODUCT_ID,\n",
    "       p.USER_ID,\n",
    "       p.PURCHASED_AT,\n",
    "       p.QUANTITY,\n",
    "       p.UNIT_PRICE,\n",
    "       p.PURCHASE_LINE\n",
    "FROM PURCHASES p\n",
    "JOIN SAMPLED_USERS s ON p.USER_ID = s.OPAQUE_USER_ID\n",
    "WHERE p.PURCHASED_AT >= DATEADD(minute, -{MINUTES_WINDOW}, CURRENT_TIMESTAMP())\n",
    "\"\"\", conn)\n",
    "print(f\"  {len(purchases):,} rows, {purchases['USER_ID'].nunique():,} users\")\n",
    "print(f\"  Total revenue: ${(purchases['QUANTITY'] * purchases['UNIT_PRICE']).sum():,.0f}\")\n",
    "\n",
    "# 6. CATALOG (only products that received impressions)\n",
    "print(\"\\n6/6 CATALOG...\")\n",
    "product_ids = impressions['PRODUCT_ID'].dropna().unique().tolist()\n",
    "print(f\"  Products to fetch: {len(product_ids):,}\")\n",
    "if len(product_ids) > 0:\n",
    "    batch_size = 10000\n",
    "    catalog_dfs = []\n",
    "    for i in tqdm(range(0, len(product_ids), batch_size), desc=\"Catalog\"):\n",
    "        batch = product_ids[i:i+batch_size]\n",
    "        placeholders = ', '.join(['%s'] * len(batch))\n",
    "        batch_df = pd.read_sql(f\"\"\"\n",
    "        SELECT LOWER(TRIM(PRODUCT_ID)) AS PRODUCT_ID, NAME, PRICE AS CATALOG_PRICE,\n",
    "               ACTIVE, IS_DELETED, CATEGORIES, DESCRIPTION\n",
    "        FROM CATALOG WHERE LOWER(TRIM(PRODUCT_ID)) IN ({placeholders})\n",
    "        \"\"\", conn, params=batch)\n",
    "        catalog_dfs.append(batch_df)\n",
    "    catalog = pd.concat(catalog_dfs, ignore_index=True) if catalog_dfs else pd.DataFrame()\n",
    "else:\n",
    "    catalog = pd.DataFrame()\n",
    "print(f\"  {len(catalog):,} rows\")\n",
    "\n",
    "# SAVE\n",
    "print(\"\\nSaving parquet files...\")\n",
    "auctions_results.to_parquet(OUTPUT_DIR / \"auctions_results_r2.parquet\", index=False)\n",
    "auctions_users.to_parquet(OUTPUT_DIR / \"auctions_users_r2.parquet\", index=False)\n",
    "impressions.to_parquet(OUTPUT_DIR / \"impressions_r2.parquet\", index=False)\n",
    "clicks.to_parquet(OUTPUT_DIR / \"clicks_r2.parquet\", index=False)\n",
    "purchases.to_parquet(OUTPUT_DIR / \"purchases_r2.parquet\", index=False)\n",
    "catalog.to_parquet(OUTPUT_DIR / \"catalog_r2.parquet\", index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DONE - Round 2\")\n",
    "print(\"=\"*50)\n",
    "print(f\"auctions_users:   {len(auctions_users):,} ({auctions_users['USER_ID'].nunique():,} users)\")\n",
    "print(f\"auctions_results: {len(auctions_results):,}\")\n",
    "print(f\"impressions:      {len(impressions):,}\")\n",
    "print(f\"clicks:           {len(clicks):,}\")\n",
    "print(f\"purchases:        {len(purchases):,}\")\n",
    "print(f\"catalog:          {len(catalog):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA QUALITY CHECKS\n",
      "============================================================\n",
      "\n",
      "--- Q1: Impression timestamp uniqueness within auction ---\n",
      "Auctions with >1 impression: 30,773\n",
      "Among those, unique timestamps: {'count': 30773.0, 'mean': 3.5153543690897866, 'std': 4.288102136805449, 'min': 1.0, '25%': 1.0, '50%': 2.0, '75%': 4.0, 'max': 49.0}\n",
      "Batched (all same timestamp): 14,804 / 31,996\n",
      "\n",
      "--- Q2: Positions per auction ---\n",
      "count    31996.000000\n",
      "mean         7.057507\n",
      "std          8.464866\n",
      "min          1.000000\n",
      "25%          2.000000\n",
      "50%          4.000000\n",
      "75%          8.000000\n",
      "max         64.000000\n",
      "Name: PRODUCT_ID, dtype: float64\n",
      "\n",
      "--- Q3: Max rank receiving impression ---\n",
      "Impressions with ranking: 224,009 / 226,939\n",
      "Ranking distribution for impressions:\n",
      "count    224009.000000\n",
      "mean         12.439121\n",
      "std          11.885172\n",
      "min           1.000000\n",
      "25%           3.000000\n",
      "50%           9.000000\n",
      "75%          18.000000\n",
      "max          64.000000\n",
      "Name: RANKING, dtype: float64\n",
      "\n",
      "Max rank shown: 64.0\n",
      "\n",
      "--- Q4: Product position variation across auctions ---\n",
      "Products with 5+ auctions: 199,460\n",
      "Avg unique positions per product: 7.5\n",
      "Products with position variation (nunique > 1): 199,135\n",
      "\n",
      "--- Q5: User-level auction frequency ---\n",
      "Auctions per user:\n",
      "count    7709.000000\n",
      "mean       11.908419\n",
      "std        79.022455\n",
      "min         1.000000\n",
      "25%         2.000000\n",
      "50%         4.000000\n",
      "75%        11.000000\n",
      "max      5431.000000\n",
      "dtype: float64\n",
      "\n",
      "Users with 10+ auctions: 2,156\n",
      "\n",
      "--- Q6: Time between auctions (session gaps) ---\n",
      "Gap between auctions (seconds):\n",
      "count    84093.000000\n",
      "mean       418.306785\n",
      "std       2052.878867\n",
      "min          0.000000\n",
      "25%          0.046000\n",
      "50%         11.606000\n",
      "75%         66.368000\n",
      "max      31682.245000\n",
      "Name: time_gap, dtype: float64\n",
      "\n",
      "Median gap: 11.6s = 0.2min\n",
      "75th percentile: 66.4s = 1.1min\n",
      "\n",
      "--- Purchase-to-impression linkage ---\n",
      "Unique products in purchases: 861\n",
      "Unique products in impressions: 160,381\n",
      "Overlap (promoted purchases): 25\n",
      "Organic-only purchases: 836\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# CELL 3: DATA QUALITY CHECKS (from notes.md Q1-Q6)\n",
    "print(\"=\"*60)\n",
    "print(\"DATA QUALITY CHECKS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Q1: Are impression timestamps unique within auction, or batched?\n",
    "print(\"\\n--- Q1: Impression timestamp uniqueness within auction ---\")\n",
    "imp_ts = impressions.groupby('AUCTION_ID')['OCCURRED_AT'].agg(['nunique', 'count'])\n",
    "print(f\"Auctions with >1 impression: {(imp_ts['count'] > 1).sum():,}\")\n",
    "print(f\"Among those, unique timestamps: {imp_ts[imp_ts['count'] > 1]['nunique'].describe().to_dict()}\")\n",
    "print(f\"Batched (all same timestamp): {(imp_ts['nunique'] == 1).sum():,} / {len(imp_ts):,}\")\n",
    "\n",
    "# Q2: Distribution of positions per auction\n",
    "print(\"\\n--- Q2: Positions per auction ---\")\n",
    "positions_per_auction = impressions.groupby('AUCTION_ID')['PRODUCT_ID'].nunique()\n",
    "print(positions_per_auction.describe())\n",
    "\n",
    "# Q3: Maximum rank that receives impression\n",
    "print(\"\\n--- Q3: Max rank receiving impression ---\")\n",
    "# Join impressions to auctions_results to get ranking\n",
    "imp_with_rank = impressions.merge(\n",
    "    auctions_results[['AUCTION_ID', 'PRODUCT_ID', 'RANKING']],\n",
    "    on=['AUCTION_ID', 'PRODUCT_ID'],\n",
    "    how='left'\n",
    ")\n",
    "print(f\"Impressions with ranking: {imp_with_rank['RANKING'].notna().sum():,} / {len(imp_with_rank):,}\")\n",
    "print(f\"Ranking distribution for impressions:\")\n",
    "print(imp_with_rank['RANKING'].describe())\n",
    "print(f\"\\nMax rank shown: {imp_with_rank['RANKING'].max()}\")\n",
    "\n",
    "# Q4: Products appearing at multiple positions\n",
    "print(\"\\n--- Q4: Product position variation across auctions ---\")\n",
    "prod_pos = auctions_results.groupby('PRODUCT_ID')['RANKING'].agg(['mean', 'std', 'count', 'nunique'])\n",
    "prod_pos = prod_pos[prod_pos['count'] >= 5]  # Products with 5+ appearances\n",
    "print(f\"Products with 5+ auctions: {len(prod_pos):,}\")\n",
    "print(f\"Avg unique positions per product: {prod_pos['nunique'].mean():.1f}\")\n",
    "print(f\"Products with position variation (nunique > 1): {(prod_pos['nunique'] > 1).sum():,}\")\n",
    "\n",
    "# Q5: User auction frequency and position variation\n",
    "print(\"\\n--- Q5: User-level auction frequency ---\")\n",
    "user_auctions = auctions_users.groupby('USER_ID').size()\n",
    "print(f\"Auctions per user:\")\n",
    "print(user_auctions.describe())\n",
    "print(f\"\\nUsers with 10+ auctions: {(user_auctions >= 10).sum():,}\")\n",
    "\n",
    "# Q6: Time between auctions for same user (session definition)\n",
    "print(\"\\n--- Q6: Time between auctions (session gaps) ---\")\n",
    "auctions_users_sorted = auctions_users.sort_values(['USER_ID', 'CREATED_AT'])\n",
    "auctions_users_sorted['time_gap'] = auctions_users_sorted.groupby('USER_ID')['CREATED_AT'].diff()\n",
    "gaps = auctions_users_sorted['time_gap'].dropna().dt.total_seconds()\n",
    "print(f\"Gap between auctions (seconds):\")\n",
    "print(gaps.describe())\n",
    "print(f\"\\nMedian gap: {gaps.median():.1f}s = {gaps.median()/60:.1f}min\")\n",
    "print(f\"75th percentile: {gaps.quantile(0.75):.1f}s = {gaps.quantile(0.75)/60:.1f}min\")\n",
    "\n",
    "# Additional: Purchase linkage check\n",
    "print(\"\\n--- Purchase-to-impression linkage ---\")\n",
    "purchase_products = set(purchases['PRODUCT_ID'].unique())\n",
    "impression_products = set(impressions['PRODUCT_ID'].unique())\n",
    "overlap = purchase_products & impression_products\n",
    "print(f\"Unique products in purchases: {len(purchase_products):,}\")\n",
    "print(f\"Unique products in impressions: {len(impression_products):,}\")\n",
    "print(f\"Overlap (promoted purchases): {len(overlap):,}\")\n",
    "print(f\"Organic-only purchases: {len(purchase_products - impression_products):,}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
